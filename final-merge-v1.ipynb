{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDS503 - Machine Learning Final Project\n",
    "\n",
    "Semester 2, Academic Session 2019/2020\n",
    "\n",
    "Group 6 - **Data Masters**\n",
    "\n",
    "Members:\n",
    "- Lee Yong Meng\n",
    "- Lee Kar Choon\n",
    "- Tan Wei Chean\n",
    "- Yee Hoong Yip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- [Data Preparation](#Data-Preparation)\n",
    "- [Experiment Set 1: Machine Learning Algorithm](#Experiment-Set-1:-Comparing-Machine-Learning-Algorithms)\n",
    "- [Experiment Set 2: Feature Selection](#Experiment-Set-2:-Feature-Selection)\n",
    "- [Experiment Set 3: Ensemble Learning](#Experiment-Set-3:-Ensemble-Learning)\n",
    "  - [3.0 Default Classifiers](#3.0-Default-Classifiers)\n",
    "  - [3.1 Bagging](#3.1-Bagging)\n",
    "  - [3.2 Boosting](#3.2-Boosting)\n",
    "  - [3.3 Voting](#3.3-Voting)\n",
    "- [Experiment Set 4: Training Sample Size](#Experiment-Set-4:-Vary-Training-Sample-Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Before working on the experiment sets, we need to import some necessary libraries for working on data pre-processing and conducting experiment sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python libraries\n",
    "import pandas as pd                  # Use pandas.DataFrame to manipulate data\n",
    "import matplotlib.pyplot as plt      # Standard plotting library\n",
    "import numpy as np                   # Standard Python library for numerical operations\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn import preprocessing    # Data preprocessing\n",
    "\n",
    "# Model selection - split data, cv, model evaluation\n",
    "from sklearn.model_selection import train_test_split    # Split dataset into training and test sets\n",
    "from sklearn.model_selection import cross_val_score     # k-fold cross-validation\n",
    "from sklearn.model_selection import GridSearchCV        # search for best parameters\n",
    "from sklearn import metrics                             # metrics to evaluate the model performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix    # analyze prediction made by the classification model\n",
    "\n",
    "# Machine learning algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Feature extraction - Decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "# Ensemble learning methods\n",
    "# --- Bagging\n",
    "from sklearn.ensemble import BaggingClassifier            # Bagging - (B)ootstrap (AGG)regat(ING)\n",
    "from sklearn.ensemble import RandomForestClassifier       # Random Forest\n",
    "# --- Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier           # (ADA)ptive (BOOST)ing\n",
    "from sklearn.ensemble import GradientBoostingClassifier   # Gradient Boosting\n",
    "# --- Voting\n",
    "from sklearn.ensemble import VotingClassifier             # Voting\n",
    "\n",
    "# Itertools - here, used to generate combinations of base classifiers for voting\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV file\n",
    "\n",
    "Next, we read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>281656475</td>\n",
       "      <td>PAC-MAN Premium</td>\n",
       "      <td>100788224</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>281796108</td>\n",
       "      <td>Evernote - stay organized</td>\n",
       "      <td>158578688</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>281940292</td>\n",
       "      <td>WeatherBug - Local Weather, Radar, Maps, Alerts</td>\n",
       "      <td>100524032</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>282614216</td>\n",
       "      <td>eBay: Best App to Buy, Sell, Save! Online Shop...</td>\n",
       "      <td>128512000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>282935706</td>\n",
       "      <td>Bible</td>\n",
       "      <td>92774400</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                                         track_name  \\\n",
       "0           1  281656475                                    PAC-MAN Premium   \n",
       "1           2  281796108                          Evernote - stay organized   \n",
       "2           3  281940292    WeatherBug - Local Weather, Radar, Maps, Alerts   \n",
       "3           4  282614216  eBay: Best App to Buy, Sell, Save! Online Shop...   \n",
       "4           5  282935706                                              Bible   \n",
       "\n",
       "   size_bytes currency  price  rating_count_tot  rating_count_ver  \\\n",
       "0   100788224      USD   3.99             21292                26   \n",
       "1   158578688      USD   0.00            161065                26   \n",
       "2   100524032      USD   0.00            188583              2822   \n",
       "3   128512000      USD   0.00            262241               649   \n",
       "4    92774400      USD   0.00            985920              5320   \n",
       "\n",
       "   user_rating  user_rating_ver     ver cont_rating   prime_genre  \\\n",
       "0          4.0              4.5   6.3.5          4+         Games   \n",
       "1          4.0              3.5   8.2.2          4+  Productivity   \n",
       "2          3.5              4.5   5.0.0          4+       Weather   \n",
       "3          4.0              4.5  5.10.0         12+      Shopping   \n",
       "4          4.5              5.0   7.5.1          4+     Reference   \n",
       "\n",
       "   sup_devices.num  ipadSc_urls.num  lang.num  vpp_lic  \n",
       "0               38                5        10        1  \n",
       "1               37                5        23        1  \n",
       "2               37                5         3        1  \n",
       "3               37                5         9        1  \n",
       "4               37                5        45        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('AppleStore.csv')\n",
    "\n",
    "# Quick view on the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several columns in the datasets are not helpful in our work. Therefore, we will remove these columns.\n",
    "\n",
    "- `Id`: App ID\n",
    "- `track_name`: App name\n",
    "- Unnamed: the first column, which is the count of the record.\n",
    "\n",
    "We use the method `.drop()` to remove the specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes currency  price  rating_count_tot  rating_count_ver  \\\n",
       "0   100788224      USD   3.99             21292                26   \n",
       "1   158578688      USD   0.00            161065                26   \n",
       "2   100524032      USD   0.00            188583              2822   \n",
       "3   128512000      USD   0.00            262241               649   \n",
       "4    92774400      USD   0.00            985920              5320   \n",
       "\n",
       "   user_rating  user_rating_ver     ver cont_rating   prime_genre  \\\n",
       "0          4.0              4.5   6.3.5          4+         Games   \n",
       "1          4.0              3.5   8.2.2          4+  Productivity   \n",
       "2          3.5              4.5   5.0.0          4+       Weather   \n",
       "3          4.0              4.5  5.10.0         12+      Shopping   \n",
       "4          4.5              5.0   7.5.1          4+     Reference   \n",
       "\n",
       "   sup_devices.num  ipadSc_urls.num  lang.num  vpp_lic  \n",
       "0               38                5        10        1  \n",
       "1               37                5        23        1  \n",
       "2               37                5         3        1  \n",
       "3               37                5         9        1  \n",
       "4               37                5        45        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define columns to drop\n",
    "columns_drop = ['id', 'track_name']\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns_drop, axis = 1, inplace = True)\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed', case = False)], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping `user_rating` using `pd.cut()` \n",
    "\n",
    "For our business problem, we would like to group the column `user_rating` (i.e. our target column) into three groups, namely \"Low\", \"Medium\" and \"High\". We use the function `pd.cut()` to perform the binning. Then, we add a new column `user_rating_label` into the data frame, which will be shown at the very end when the data frame preview is scrolling horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes currency  price  rating_count_tot  rating_count_ver  \\\n",
       "0   100788224      USD   3.99             21292                26   \n",
       "1   158578688      USD   0.00            161065                26   \n",
       "2   100524032      USD   0.00            188583              2822   \n",
       "3   128512000      USD   0.00            262241               649   \n",
       "4    92774400      USD   0.00            985920              5320   \n",
       "\n",
       "   user_rating  user_rating_ver     ver cont_rating   prime_genre  \\\n",
       "0          4.0              4.5   6.3.5          4+         Games   \n",
       "1          4.0              3.5   8.2.2          4+  Productivity   \n",
       "2          3.5              4.5   5.0.0          4+       Weather   \n",
       "3          4.0              4.5  5.10.0         12+      Shopping   \n",
       "4          4.5              5.0   7.5.1          4+     Reference   \n",
       "\n",
       "   sup_devices.num  ipadSc_urls.num  lang.num  vpp_lic user_rating_label  \n",
       "0               38                5        10        1              High  \n",
       "1               37                5        23        1              High  \n",
       "2               37                5         3        1              High  \n",
       "3               37                5         9        1              High  \n",
       "4               37                5        45        1              High  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_rating_label'] = pd.cut(df['user_rating'], bins = 3, labels = ['Low', 'Medium', 'High'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will drop two other columns:\n",
    "- `user_rating`: no longer needed because we will be using the new column `user_rating_label` as the target of classification.\n",
    "- `currency`: not helpful because it only has one unique value \"USD\" for all examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "0   100788224   3.99             21292                26              4.5   \n",
       "1   158578688   0.00            161065                26              3.5   \n",
       "2   100524032   0.00            188583              2822              4.5   \n",
       "3   128512000   0.00            262241               649              4.5   \n",
       "4    92774400   0.00            985920              5320              5.0   \n",
       "\n",
       "      ver cont_rating   prime_genre  sup_devices.num  ipadSc_urls.num  \\\n",
       "0   6.3.5          4+         Games               38                5   \n",
       "1   8.2.2          4+  Productivity               37                5   \n",
       "2   5.0.0          4+       Weather               37                5   \n",
       "3  5.10.0         12+      Shopping               37                5   \n",
       "4   7.5.1          4+     Reference               37                5   \n",
       "\n",
       "   lang.num  vpp_lic user_rating_label  \n",
       "0        10        1              High  \n",
       "1        23        1              High  \n",
       "2         3        1              High  \n",
       "3         9        1              High  \n",
       "4        45        1              High  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define columns to drop\n",
    "columns_drop = ['user_rating', 'currency']\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns_drop, axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further inspect the data by calling the method `.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7197 entries, 0 to 7196\n",
      "Data columns (total 13 columns):\n",
      "size_bytes           7197 non-null int64\n",
      "price                7197 non-null float64\n",
      "rating_count_tot     7197 non-null int64\n",
      "rating_count_ver     7197 non-null int64\n",
      "user_rating_ver      7197 non-null float64\n",
      "ver                  7197 non-null object\n",
      "cont_rating          7197 non-null object\n",
      "prime_genre          7197 non-null object\n",
      "sup_devices.num      7197 non-null int64\n",
      "ipadSc_urls.num      7197 non-null int64\n",
      "lang.num             7197 non-null int64\n",
      "vpp_lic              7197 non-null int64\n",
      "user_rating_label    7197 non-null category\n",
      "dtypes: category(1), float64(2), int64(7), object(3)\n",
      "memory usage: 682.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is no missing values in our data.\n",
    "\n",
    "Some of the columns contain `String` values which might not be compatible to certain machine learning algorithms that will be implemented in the subsequent sections. Therefore, we need to transform the data into labels encoded by numeric values (i.e., 0, 1, 2, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding - Categorical Attributes\n",
    "\n",
    "We use `sklearn.preprocessing.LabelEncoder()` to transform the following columns into numeric labels:\n",
    "- `prime_genre`: contains 22 unique `String` values.\n",
    "- `user_rating_label`: contains 3 unique `String` values (\"Low\", \"Medium\", \"High\")\n",
    "- `cont_rating`: app content rating, contains 4 unique `String` values.\n",
    "- `ver`: app version, contains 1590 unique `String` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 unique values of cont_rating.\n",
      "There are 23 unique values of prime_genre.\n",
      "There are 3 unique values of user_rating_label.\n",
      "There are 1590 unique values of ver.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7197 entries, 0 to 7196\n",
      "Data columns (total 13 columns):\n",
      "size_bytes           7197 non-null int64\n",
      "price                7197 non-null float64\n",
      "rating_count_tot     7197 non-null int64\n",
      "rating_count_ver     7197 non-null int64\n",
      "user_rating_ver      7197 non-null float64\n",
      "ver                  7197 non-null object\n",
      "cont_rating          7197 non-null object\n",
      "prime_genre          7197 non-null object\n",
      "sup_devices.num      7197 non-null int64\n",
      "ipadSc_urls.num      7197 non-null int64\n",
      "lang.num             7197 non-null int64\n",
      "vpp_lic              7197 non-null int64\n",
      "user_rating_label    7197 non-null object\n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 731.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Define names of columns selected for label encoding\n",
    "col_categories = [\"cont_rating\", \"prime_genre\", \"user_rating_label\", \"ver\"]\n",
    "col_num_unique_values = dict()\n",
    "\n",
    "for col_name in col_categories:\n",
    "    count = len(df[col_name].unique())\n",
    "    col_num_unique_values[col_name] = count\n",
    "    \n",
    "#     print(\"Column name: {}\\n>>> There are {} unique values.\".format(col_name, count))    \n",
    "    print(\"There are {} unique values of {}.\".format(count, col_name))\n",
    "    \n",
    "    df[col_name] = le.fit_transform(df[col_name])\n",
    "    df[col_name] = df[col_name].astype(str)\n",
    "\n",
    "print()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1379</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1514</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1210</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1236</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1472</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "0   100788224   3.99             21292                26              4.5   \n",
       "1   158578688   0.00            161065                26              3.5   \n",
       "2   100524032   0.00            188583              2822              4.5   \n",
       "3   128512000   0.00            262241               649              4.5   \n",
       "4    92774400   0.00            985920              5320              5.0   \n",
       "\n",
       "    ver cont_rating prime_genre  sup_devices.num  ipadSc_urls.num  lang.num  \\\n",
       "0  1379           2           7               38                5        10   \n",
       "1  1514           2          15               37                5        23   \n",
       "2  1210           2          22               37                5         3   \n",
       "3  1236           0          17               37                5         9   \n",
       "4  1472           2          16               37                5        45   \n",
       "\n",
       "   vpp_lic user_rating_label  \n",
       "0        1                 0  \n",
       "1        1                 0  \n",
       "2        1                 0  \n",
       "3        1                 0  \n",
       "4        1                 0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the data after data preprocessing is saved into a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r'AppleStore_preprocessed.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Target and Features and Splitting Dataset\n",
    "\n",
    "The attribute `user_rating_label` is chosen as the target throught the experiment sets. At this stage, all the other attributes are selected as the features used for predicting the `user_rating_label` to this classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target - `user_rating_label`\n",
    "target = df['user_rating_label']\n",
    "\n",
    "# Feature - all other attributes\n",
    "features = df.drop('user_rating_label', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the dataset is split into training and test sets, with proportions of 80% and 20% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split    # Split dataset into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function - to evaluate model performance. \n",
    "def test_model(estimator, x_train, x_test, y_train, y_test, score=\"accuracy\", average=None, clf_report=False):\n",
    "    # Function within function #1\n",
    "    # ---\n",
    "    # Print model performance based on user-specified metric and average\n",
    "    def test_scoring(y_test, y_pred, score=\"accuracy\", average=None):\n",
    "        score_lower = score.lower()\n",
    "        score_metric = 0\n",
    "\n",
    "        if average is None:\n",
    "            average = \"weighted\"\n",
    "            \n",
    "        if score_lower == \"accuracy\":\n",
    "            score_metric = metrics.accuracy_score(y_test, y_pred)\n",
    "        elif score_lower == \"precision\":\n",
    "            score_metric = metrics.precision_score(y_test, y_pred, average=average)\n",
    "        elif score_lower == \"recall\":\n",
    "            score_metric = metrics.recall_score(y_test, y_pred, average=average)\n",
    "        elif score_lower == \"f1_score\":\n",
    "            score_metric = metrics.f1_score(y_test, y_pred, average=average)\n",
    "            \n",
    "        score_name = \"\"\n",
    "        \n",
    "        if score_lower != \"accuracy\":\n",
    "            score_name += average.capitalize() + \" \"\n",
    "        \n",
    "        score_name += score.capitalize()\n",
    "\n",
    "        print(\"{} (Test):\".format(score_name), end=' ')\n",
    "        print(\"{:.4f}\".format(score_metric))\n",
    "        \n",
    "        return {\"name\": score_name, \"score\": score_metric}\n",
    "        \n",
    "    \n",
    "    # Function within function #2\n",
    "    # ---\n",
    "    # Print model performance report - confusion matrix and classification report\n",
    "    def test_clf_report(y_test, y_pred):\n",
    "        print(\"Confusion matrix:\\n---\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"\\nClassification report:\\n---\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # ---\n",
    "    \n",
    "    # Training - fit training set into the estimator\n",
    "    estimator.fit(x_train, y_train)\n",
    "    \n",
    "    # Testing - Predict the outcome/label\n",
    "    y_predict = estimator.predict(x_test)\n",
    "    \n",
    "    # Print model performance - single metric\n",
    "    dict_scoring = test_scoring(y_test, y_predict, score, average)\n",
    "    \n",
    "    # Print model performance report (optional)\n",
    "    if clf_report:\n",
    "        print()\n",
    "        test_clf_report(y_test, y_predict)\n",
    "        \n",
    "    return dict_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to deal with repetitive processes\n",
    "def train_and_evaluate(estimators, X_train, X_test, Y_train, Y_test):\n",
    "    def get_scoring_metric():\n",
    "#         return ['f1_macro', 'f1_weighted', 'accuracy']\n",
    "        return ['f1_macro']\n",
    "    \n",
    "    # K-fold cross validation\n",
    "    def print_validation_performance(estimator, X_train, Y_train, name=None, cv=10):\n",
    "        for metric in get_scoring_metric():\n",
    "            scores = cross_val_score(estimator, X_train, Y_train, cv=cv, scoring=metric)\n",
    "            estimator_name = \"\"\n",
    "            \n",
    "            if name is not None:\n",
    "                estimator_name = \" {}\".format(name)\n",
    "                \n",
    "            print(\"{} (Validation{}) = \".format(metric, estimator_name), end=\"\")\n",
    "            print(\"{:.4f}\".format(scores.mean()))\n",
    "    \n",
    "    # Training and testing\n",
    "    def print_test_performance(estimator, X_train, X_test, Y_train, Y_test, name=None):\n",
    "        estimator.fit(X_train, Y_train)\n",
    "        test_predict = estimator.predict(X_test)\n",
    "        \n",
    "        dict_score = {}\n",
    "        \n",
    "        for metric in get_scoring_metric():\n",
    "            estimator_name = \"\"\n",
    "            score = 0.0\n",
    "            \n",
    "            if name is not None:\n",
    "                estimator_name = \" {}\".format(name) \n",
    "            \n",
    "            average = None\n",
    "            acc_flag = True\n",
    "            \n",
    "            if \"macro\" in metric:\n",
    "                average = \"macro\"\n",
    "                acc_flag = False\n",
    "            elif \"weighted\" in metric:\n",
    "                average = \"weighted\"\n",
    "                acc_flag = False\n",
    "            \n",
    "            print(\"{} (Test{}) = \".format(metric, estimator_name), end=\"\")\n",
    "            \n",
    "            if acc_flag:\n",
    "                score = metrics.accuracy_score(Y_test, test_predict)\n",
    "#                 print(\"{:.4f}\".format(metrics.accuracy_score(Y_test, test_predict)))\n",
    "            else:\n",
    "                score = metrics.f1_score(Y_test, test_predict, average=average)\n",
    "#                 print(\"{:.4f}\".format(metrics.f1_score(Y_test, test_predict, average=average)))\n",
    "            \n",
    "            print(\"{:.4f}\".format(score))\n",
    "            \n",
    "            dict_score[metric] = score\n",
    "        \n",
    "        print(confusion_matrix(Y_test, test_predict))\n",
    "        print(classification_report(Y_test, test_predict))\n",
    "        \n",
    "        return dict_score\n",
    "    \n",
    "#     # Define estimators\n",
    "#     estimators = {\n",
    "#         \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "#         \"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "#         \"SVM\": SVC(kernel = 'poly', degree = 2, gamma = 'scale', max_iter=10000)\n",
    "#     }\n",
    "    \n",
    "    dict_est_score = {}\n",
    "    \n",
    "    for key_est in estimators:\n",
    "        print_validation_performance(estimators[key_est], X_train, Y_train, name=key_est)\n",
    "        dict_est_score[key_est] = print_test_performance(estimators[key_est], \n",
    "                                                         X_train, X_test, Y_train, Y_test, \n",
    "                                                         name=key_est)\n",
    "        print()\n",
    "        \n",
    "    return dict_est_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are ready to conduct the experiment sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Step - Standard Scaling\n",
    "\n",
    "This step is to standardize the features of the original dataset so that the values of each attribute has a mean, $\\mu = 0$, and standard deviation, $\\sigma = 1$.\n",
    "\n",
    "**Note that the same step is performed on training and test features (i.e., `x_train` and `x_test`) separately to prevent _\"data leakage\"_. We do not want the information from the test set (e.g., outliers) to _leak_ into the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Obsolete ===\n",
    "\n",
    "# Define helper function\n",
    "def standardize_features(df):\n",
    "    \"\"\"\n",
    "    Helper function to standardize the values of df so that the values of each attribute (column)\n",
    "    has a mean value of 0 and standard deviation value of 1.\n",
    "    \n",
    "    Parameters\n",
    "    ---\n",
    "    df: specify a data frame which requires standardization on the values on each column.\n",
    "    \n",
    "    Return\n",
    "    ---\n",
    "    A data frame with standardized column values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Names of the features\n",
    "    names = df.columns\n",
    "    \n",
    "    # Create the Scaler object\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    df_scaled = pd.DataFrame(df_scaled, columns=names)\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test helper function docstring (optional) :D\n",
    "# help(standardize_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling on training features\n",
    "scaled_x_train = standardize_features(x_train)\n",
    "\n",
    "# Standard scaling on test features\n",
    "scaled_x_test = standardize_features(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set 1: Comparing Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function - get the best parameter set for a classifier\n",
    "def get_best_parameter_set(estimator, param_grid, scoring):\n",
    "    # Fit on the dataset on all parameter combinations in param_grid\n",
    "    # Retain the best combination\n",
    "    grid_search = GridSearchCV(estimator, param_grid, cv=10, scoring=scoring) #f1_macro\n",
    "    grid_result = grid_search.fit(x_train, y_train)\n",
    "    \n",
    "    return grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN - baseline) = 0.3262\n",
      "f1_macro (Test KNN - baseline) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline KNN classifier\n",
    "estimator = {\"KNN - baseline\": KNeighborsClassifier()}\n",
    "\n",
    "_ = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': range(2, 20)}\n",
    "\n",
    "best_param_set = get_best_parameter_set(KNeighborsClassifier(), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN - best parameter) = 0.3395\n",
      "f1_weighted (Validation KNN - best parameter) = 0.6567\n",
      "accuracy (Validation KNN - best parameter) = 0.7089\n",
      "\n",
      "f1_macro (Test KNN - best parameter) = 0.3424\n",
      "f1_weighted (Test KNN - best parameter) = 0.6667\n",
      "accuracy (Test KNN - best parameter) = 0.7222\n",
      "[[1017   54   31]\n",
      " [ 162   18    9]\n",
      " [ 137    7    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1102\n",
      "           1       0.23      0.10      0.13       189\n",
      "           2       0.11      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.72      1440\n",
      "   macro avg       0.37      0.35      0.34      1440\n",
      "weighted avg       0.63      0.72      0.67      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a KNN classifier with the best parameter set\n",
    "estimator = {\"KNN - best parameter\": KNeighborsClassifier(**best_param_set)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Decision Tree - baseline) = 0.7764\n",
      "f1_weighted (Validation Decision Tree - baseline) = 0.8871\n",
      "accuracy (Validation Decision Tree - baseline) = 0.8841\n",
      "\n",
      "f1_macro (Test Decision Tree - baseline) = 0.7732\n",
      "f1_weighted (Test Decision Tree - baseline) = 0.8801\n",
      "accuracy (Test Decision Tree - baseline) = 0.8826\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline Decision Tree classifier\n",
    "estimator = {\"Decision Tree - baseline\": DecisionTreeClassifier(random_state=0)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'splitter': 'best'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'criterion': ['gini','entropy'],\n",
    "              'splitter': ['best','random']}\n",
    "\n",
    "best_param_set = get_best_parameter_set(DecisionTreeClassifier(random_state=0), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Decision Tree - best parameter) = 0.7764\n",
      "f1_weighted (Validation Decision Tree - best parameter) = 0.8871\n",
      "accuracy (Validation Decision Tree - best parameter) = 0.8841\n",
      "\n",
      "f1_macro (Test Decision Tree - best parameter) = 0.7732\n",
      "f1_weighted (Test Decision Tree - best parameter) = 0.8801\n",
      "accuracy (Test Decision Tree - best parameter) = 0.8826\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a Decision Tree classifier with the best parameter set\n",
    "estimator = {\"Decision Tree - best parameter\": DecisionTreeClassifier(**best_param_set, random_state=0)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Linear SVM - baseline) = 0.1785\n",
      "f1_weighted (Validation Linear SVM - baseline) = 0.3241\n",
      "accuracy (Validation Linear SVM - baseline) = 0.3819\n",
      "\n",
      "f1_macro (Test Linear SVM - baseline) = 0.1019\n",
      "f1_weighted (Test Linear SVM - baseline) = 0.1081\n",
      "accuracy (Test Linear SVM - baseline) = 0.1472\n",
      "[[  68    0 1034]\n",
      " [   2    0  187]\n",
      " [   5    0  144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.06      0.12      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.11      0.97      0.19       149\n",
      "\n",
      "    accuracy                           0.15      1440\n",
      "   macro avg       0.34      0.34      0.10      1440\n",
      "weighted avg       0.70      0.15      0.11      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline linear SVM classifier\n",
    "estimator = {\"Linear SVM - baseline\": SVC(kernel='linear', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "best_param_set = get_best_parameter_set(SVC(kernel='linear', max_iter=10000), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Linear SVM - best parameter) = 0.1785\n",
      "f1_weighted (Validation Linear SVM - best parameter) = 0.3241\n",
      "accuracy (Validation Linear SVM - best parameter) = 0.3819\n",
      "\n",
      "f1_macro (Test Linear SVM - best parameter) = 0.1019\n",
      "f1_weighted (Test Linear SVM - best parameter) = 0.1081\n",
      "accuracy (Test Linear SVM - best parameter) = 0.1472\n",
      "[[  68    0 1034]\n",
      " [   2    0  187]\n",
      " [   5    0  144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.06      0.12      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.11      0.97      0.19       149\n",
      "\n",
      "    accuracy                           0.15      1440\n",
      "   macro avg       0.34      0.34      0.10      1440\n",
      "weighted avg       0.70      0.15      0.11      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a linear SVM classifier with the best parameter set\n",
    "estimator = {\"Linear SVM - best parameter\": SVC(**best_param_set, kernel='linear', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Polynomial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Polynomial SVM - baseline) = 0.2017\n",
      "f1_weighted (Validation Polynomial SVM - baseline) = 0.4047\n",
      "accuracy (Validation Polynomial SVM - baseline) = 0.4991\n",
      "\n",
      "f1_macro (Test Polynomial SVM - baseline) = 0.2890\n",
      "f1_weighted (Test Polynomial SVM - baseline) = 0.6634\n",
      "accuracy (Test Polynomial SVM - baseline) = 0.7646\n",
      "[[1101    0    1]\n",
      " [ 188    0    1]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.76      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline linear SVM classifier\n",
    "estimator = {\"Polynomial SVM - baseline\": SVC(kernel='poly', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'degree': 4, 'gamma': 'scale'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'degree': [2, 3, 4], \n",
    "              'gamma': ['scale', 'auto', 0.001, 0.1, 1, 10, 100]}\n",
    "\n",
    "best_param_set = get_best_parameter_set(SVC(kernel='poly', max_iter=10000), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Polynomial SVM - best parameter) = 0.2887\n",
      "f1_weighted (Validation Polynomial SVM - best parameter) = 0.6576\n",
      "accuracy (Validation Polynomial SVM - best parameter) = 0.7598\n",
      "\n",
      "f1_macro (Test Polynomial SVM - best parameter) = 0.0776\n",
      "f1_weighted (Test Polynomial SVM - best parameter) = 0.0317\n",
      "accuracy (Test Polynomial SVM - best parameter) = 0.1313\n",
      "[[   1 1101    0]\n",
      " [   0  188    1]\n",
      " [   0  149    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1102\n",
      "           1       0.13      0.99      0.23       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.13      1440\n",
      "   macro avg       0.38      0.33      0.08      1440\n",
      "weighted avg       0.78      0.13      0.03      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a polynomial SVM classifier with the best parameter set\n",
    "estimator = {\"Polynomial SVM - best parameter\": SVC(**best_param_set, kernel='poly', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation RBF SVM - baseline) = 0.2881\n",
      "f1_weighted (Validation RBF SVM - baseline) = 0.6577\n",
      "accuracy (Validation RBF SVM - baseline) = 0.7610\n",
      "\n",
      "f1_macro (Test RBF SVM - baseline) = 0.2890\n",
      "f1_weighted (Test RBF SVM - baseline) = 0.6635\n",
      "accuracy (Test RBF SVM - baseline) = 0.7653\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline linear SVM classifier\n",
    "estimator = {\"RBF SVM - baseline\": SVC(kernel='rbf', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'gamma': 'scale'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': ['scale', 'auto', 0.001, 0.1, 1, 10, 100]}\n",
    "\n",
    "best_param_set = get_best_parameter_set(SVC(kernel='rbf', max_iter=100), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation RBF SVM - best parameter) = 0.2881\n",
      "f1_weighted (Validation RBF SVM - best parameter) = 0.6577\n",
      "accuracy (Validation RBF SVM - best parameter) = 0.7610\n",
      "\n",
      "f1_macro (Test RBF SVM - best parameter) = 0.2890\n",
      "f1_weighted (Test RBF SVM - best parameter) = 0.6635\n",
      "accuracy (Test RBF SVM - best parameter) = 0.7653\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a polynomial SVM classifier with the best parameter set\n",
    "estimator = {\"RBF SVM - best parameter\": SVC(**best_param_set, kernel='rbf', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Sigmoid SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Sigmoid SVM - baseline) = 0.2881\n",
      "f1_weighted (Validation Sigmoid SVM - baseline) = 0.6577\n",
      "accuracy (Validation Sigmoid SVM - baseline) = 0.7610\n",
      "\n",
      "f1_macro (Test Sigmoid SVM - baseline) = 0.2890\n",
      "f1_weighted (Test Sigmoid SVM - baseline) = 0.6635\n",
      "accuracy (Test Sigmoid SVM - baseline) = 0.7653\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline linear SVM classifier\n",
    "estimator = {\"Sigmoid SVM - baseline\": SVC(kernel='sigmoid', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 'scale'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': ['scale', 'auto', 0.001, 0.1, 1, 10, 100]}\n",
    "\n",
    "best_param_set = get_best_parameter_set(SVC(kernel='sigmoid', max_iter=100), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Sigmoid SVM - best parameter) = 0.2881\n",
      "f1_weighted (Validation Sigmoid SVM - best parameter) = 0.6577\n",
      "accuracy (Validation Sigmoid SVM - best parameter) = 0.7610\n",
      "\n",
      "f1_macro (Test Sigmoid SVM - best parameter) = 0.2890\n",
      "f1_weighted (Test Sigmoid SVM - best parameter) = 0.6635\n",
      "accuracy (Test Sigmoid SVM - best parameter) = 0.7653\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate test performance of a polynomial SVM classifier with the best parameter set\n",
    "estimator = {\"Sigmoid SVM - best parameter\": SVC(**best_param_set, kernel='sigmoid', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set 2: Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 3 different estimators\n",
    "estimators = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"SVM\": SVC(kernel = 'poly', degree = 2, gamma = 'scale', max_iter=10000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_features(df, columns):\n",
    "    df_num = df.copy()\n",
    "    \n",
    "    # Convert columns to type: int\n",
    "    col_to_int = columns\n",
    "\n",
    "    for col in col_to_int:\n",
    "        df_num[col] = df_num[col].astype(int)\n",
    "    \n",
    "    return df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5757 entries, 5452 to 2732\n",
      "Data columns (total 12 columns):\n",
      "size_bytes          5757 non-null int64\n",
      "price               5757 non-null float64\n",
      "rating_count_tot    5757 non-null int64\n",
      "rating_count_ver    5757 non-null int64\n",
      "user_rating_ver     5757 non-null float64\n",
      "ver                 5757 non-null int32\n",
      "cont_rating         5757 non-null int32\n",
      "prime_genre         5757 non-null int32\n",
      "sup_devices.num     5757 non-null int64\n",
      "ipadSc_urls.num     5757 non-null int64\n",
      "lang.num            5757 non-null int64\n",
      "vpp_lic             5757 non-null int64\n",
      "dtypes: float64(2), int32(3), int64(7)\n",
      "memory usage: 517.2 KB\n"
     ]
    }
   ],
   "source": [
    "columns = ['ver', 'cont_rating', 'prime_genre']\n",
    "x_train_num = get_numeric_features(x_train, columns=columns)\n",
    "x_test_num = get_numeric_features(x_test, columns=columns)\n",
    "x_train_num.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Variance Threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size_bytes          1.387115e+17\n",
       "rating_count_tot    5.946792e+09\n",
       "rating_count_ver    1.727523e+07\n",
       "ver                 1.926676e+05\n",
       "lang.num            6.354421e+01\n",
       "price               3.789444e+01\n",
       "prime_genre         2.388685e+01\n",
       "sup_devices.num     1.434726e+01\n",
       "ipadSc_urls.num     3.967491e+00\n",
       "user_rating_ver     3.287716e+00\n",
       "cont_rating         7.888607e-01\n",
       "vpp_lic             7.072274e-03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the variance of each column\n",
    "x_train_num.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>298</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>649</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1115</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>2.99</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>725</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  price  rating_count_tot  rating_count_ver   ver  \\\n",
       "5452    79053824   0.00                14                 3   298   \n",
       "3788    12320768   0.00                 0                 0    29   \n",
       "4381   539088896   0.00                89                 2   649   \n",
       "3874   223020032   0.00                 0                 0  1115   \n",
       "3131    14583808   2.99               859                52   725   \n",
       "\n",
       "      prime_genre  sup_devices.num  lang.num  \n",
       "5452            7               38         1  \n",
       "3788            9               38         1  \n",
       "4381            7               38        11  \n",
       "3874            7               38         1  \n",
       "3131            8               13         1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define columns with Least variance\n",
    "col_drop = ['vpp_lic', 'cont_rating', 'user_rating_ver', 'ipadSc_urls.num']\n",
    "\n",
    "# Use 8 features with the highest variances\n",
    "# - Drop columns with least variances from x_train_norm and x_test_norm\n",
    "x_train_num.drop(col_drop, axis = 1, inplace = True)\n",
    "x_test_num.drop(col_drop, axis = 1, inplace = True)\n",
    "\n",
    "x_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7764\n",
      "f1_macro (Test Decision Tree) = 0.7732\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1: All features\n",
    "train_and_evaluate(estimators, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.6608\n",
      "f1_macro (Test Decision Tree) = 0.6726\n",
      "[[979  16 107]\n",
      " [ 14 169   6]\n",
      " [110   4  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      1102\n",
      "           1       0.89      0.89      0.89       189\n",
      "           2       0.24      0.23      0.24       149\n",
      "\n",
      "    accuracy                           0.82      1440\n",
      "   macro avg       0.67      0.67      0.67      1440\n",
      "weighted avg       0.82      0.82      0.82      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2: 8 features\n",
    "train_and_evaluate(estimators, x_train_num, x_test_num, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.6608\n",
      "f1_macro (Test Decision Tree) = 0.6726\n",
      "[[979  16 107]\n",
      " [ 14 169   6]\n",
      " [110   4  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      1102\n",
      "           1       0.89      0.89      0.89       189\n",
      "           2       0.24      0.23      0.24       149\n",
      "\n",
      "    accuracy                           0.82      1440\n",
      "   macro avg       0.67      0.67      0.67      1440\n",
      "weighted avg       0.82      0.82      0.82      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2: 8 features\n",
    "train_and_evaluate(estimators, x_train_num, x_test_num, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size_bytes          1.387115e+17\n",
       "rating_count_tot    5.946792e+09\n",
       "rating_count_ver    1.727523e+07\n",
       "ver                 1.926676e+05\n",
       "lang.num            6.354421e+01\n",
       "price               3.789444e+01\n",
       "prime_genre         2.388685e+01\n",
       "sup_devices.num     1.434726e+01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the variance of each column\n",
    "x_train_num.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  rating_count_ver   ver\n",
       "5452    79053824                14                 3   298\n",
       "3788    12320768                 0                 0    29\n",
       "4381   539088896                89                 2   649\n",
       "3874   223020032                 0                 0  1115\n",
       "3131    14583808               859                52   725"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_drop = ['sup_devices.num', 'prime_genre', 'price', 'lang.num']\n",
    "\n",
    "x_train_num.drop(col_drop, axis=1, inplace=True)\n",
    "x_test_num.drop(col_drop, axis=1, inplace=True)\n",
    "\n",
    "x_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.6591\n",
      "f1_macro (Test Decision Tree) = 0.6473\n",
      "[[980  15 107]\n",
      " [ 17 167   5]\n",
      " [121   4  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1102\n",
      "           1       0.90      0.88      0.89       189\n",
      "           2       0.18      0.16      0.17       149\n",
      "\n",
      "    accuracy                           0.81      1440\n",
      "   macro avg       0.65      0.64      0.65      1440\n",
      "weighted avg       0.81      0.81      0.81      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 3: 4 features\n",
    "train_and_evaluate(estimators, x_train_num, x_test_num, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>size_bytes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182392</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.086075</td>\n",
       "      <td>-0.139159</td>\n",
       "      <td>-0.044634</td>\n",
       "      <td>-0.134438</td>\n",
       "      <td>-0.118347</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>-0.150418</td>\n",
       "      <td>-0.078687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.182392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039044</td>\n",
       "      <td>-0.018012</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>-0.017413</td>\n",
       "      <td>-0.115361</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>-0.006713</td>\n",
       "      <td>-0.029942</td>\n",
       "      <td>-0.048999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_count_tot</th>\n",
       "      <td>0.004486</td>\n",
       "      <td>-0.039044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163645</td>\n",
       "      <td>0.088744</td>\n",
       "      <td>0.142502</td>\n",
       "      <td>-0.016398</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.137675</td>\n",
       "      <td>-0.000982</td>\n",
       "      <td>-0.064099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_count_ver</th>\n",
       "      <td>0.006337</td>\n",
       "      <td>-0.018012</td>\n",
       "      <td>0.163645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077840</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.016948</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>0.037951</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>-0.049083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating_ver</th>\n",
       "      <td>0.086075</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>0.088744</td>\n",
       "      <td>0.077840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>0.090602</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>-0.018901</td>\n",
       "      <td>0.275737</td>\n",
       "      <td>0.175580</td>\n",
       "      <td>0.050094</td>\n",
       "      <td>-0.519424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ver</th>\n",
       "      <td>-0.139159</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>0.142502</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.110565</td>\n",
       "      <td>0.274150</td>\n",
       "      <td>-0.102288</td>\n",
       "      <td>-0.070954</td>\n",
       "      <td>0.137482</td>\n",
       "      <td>0.031991</td>\n",
       "      <td>-0.041580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont_rating</th>\n",
       "      <td>-0.044634</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>-0.016398</td>\n",
       "      <td>-0.016948</td>\n",
       "      <td>0.090602</td>\n",
       "      <td>-0.110565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052295</td>\n",
       "      <td>-0.047829</td>\n",
       "      <td>0.084674</td>\n",
       "      <td>0.024418</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>-0.045117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prime_genre</th>\n",
       "      <td>-0.134438</td>\n",
       "      <td>-0.017413</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>0.274150</td>\n",
       "      <td>-0.052295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.073675</td>\n",
       "      <td>-0.198290</td>\n",
       "      <td>0.104579</td>\n",
       "      <td>-0.028522</td>\n",
       "      <td>0.038696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup_devices.num</th>\n",
       "      <td>-0.118347</td>\n",
       "      <td>-0.115361</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.037951</td>\n",
       "      <td>-0.018901</td>\n",
       "      <td>-0.102288</td>\n",
       "      <td>-0.047829</td>\n",
       "      <td>-0.073675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037728</td>\n",
       "      <td>-0.041681</td>\n",
       "      <td>-0.037109</td>\n",
       "      <td>-0.013138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.275737</td>\n",
       "      <td>-0.070954</td>\n",
       "      <td>0.084674</td>\n",
       "      <td>-0.198290</td>\n",
       "      <td>-0.037728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088378</td>\n",
       "      <td>0.071901</td>\n",
       "      <td>-0.228352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang.num</th>\n",
       "      <td>0.004614</td>\n",
       "      <td>-0.006713</td>\n",
       "      <td>0.137675</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>0.175580</td>\n",
       "      <td>0.137482</td>\n",
       "      <td>0.024418</td>\n",
       "      <td>0.104579</td>\n",
       "      <td>-0.041681</td>\n",
       "      <td>0.088378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032477</td>\n",
       "      <td>-0.139049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vpp_lic</th>\n",
       "      <td>-0.150418</td>\n",
       "      <td>-0.029942</td>\n",
       "      <td>-0.000982</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.050094</td>\n",
       "      <td>0.031991</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>-0.028522</td>\n",
       "      <td>-0.037109</td>\n",
       "      <td>0.071901</td>\n",
       "      <td>0.032477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating_label</th>\n",
       "      <td>-0.078687</td>\n",
       "      <td>-0.048999</td>\n",
       "      <td>-0.064099</td>\n",
       "      <td>-0.049083</td>\n",
       "      <td>-0.519424</td>\n",
       "      <td>-0.041580</td>\n",
       "      <td>-0.045117</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>-0.013138</td>\n",
       "      <td>-0.228352</td>\n",
       "      <td>-0.139049</td>\n",
       "      <td>-0.055559</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   size_bytes     price  rating_count_tot  rating_count_ver  \\\n",
       "size_bytes           1.000000  0.182392          0.004486          0.006337   \n",
       "price                0.182392  1.000000         -0.039044         -0.018012   \n",
       "rating_count_tot     0.004486 -0.039044          1.000000          0.163645   \n",
       "rating_count_ver     0.006337 -0.018012          0.163645          1.000000   \n",
       "user_rating_ver      0.086075  0.025173          0.088744          0.077840   \n",
       "ver                 -0.139159 -0.010842          0.142502         -0.000678   \n",
       "cont_rating         -0.044634  0.033551         -0.016398         -0.016948   \n",
       "prime_genre         -0.134438 -0.017413          0.039188          0.011090   \n",
       "sup_devices.num     -0.118347 -0.115361          0.008832          0.037951   \n",
       "ipadSc_urls.num      0.152697  0.066100          0.015734          0.024333   \n",
       "lang.num             0.004614 -0.006713          0.137675          0.013287   \n",
       "vpp_lic             -0.150418 -0.029942         -0.000982          0.006460   \n",
       "user_rating_label   -0.078687 -0.048999         -0.064099         -0.049083   \n",
       "\n",
       "                   user_rating_ver       ver  cont_rating  prime_genre  \\\n",
       "size_bytes                0.086075 -0.139159    -0.044634    -0.134438   \n",
       "price                     0.025173 -0.010842     0.033551    -0.017413   \n",
       "rating_count_tot          0.088744  0.142502    -0.016398     0.039188   \n",
       "rating_count_ver          0.077840 -0.000678    -0.016948     0.011090   \n",
       "user_rating_ver           1.000000 -0.003986     0.090602    -0.033246   \n",
       "ver                      -0.003986  1.000000    -0.110565     0.274150   \n",
       "cont_rating               0.090602 -0.110565     1.000000    -0.052295   \n",
       "prime_genre              -0.033246  0.274150    -0.052295     1.000000   \n",
       "sup_devices.num          -0.018901 -0.102288    -0.047829    -0.073675   \n",
       "ipadSc_urls.num           0.275737 -0.070954     0.084674    -0.198290   \n",
       "lang.num                  0.175580  0.137482     0.024418     0.104579   \n",
       "vpp_lic                   0.050094  0.031991     0.055412    -0.028522   \n",
       "user_rating_label        -0.519424 -0.041580    -0.045117     0.038696   \n",
       "\n",
       "                   sup_devices.num  ipadSc_urls.num  lang.num   vpp_lic  \\\n",
       "size_bytes               -0.118347         0.152697  0.004614 -0.150418   \n",
       "price                    -0.115361         0.066100 -0.006713 -0.029942   \n",
       "rating_count_tot          0.008832         0.015734  0.137675 -0.000982   \n",
       "rating_count_ver          0.037951         0.024333  0.013287  0.006460   \n",
       "user_rating_ver          -0.018901         0.275737  0.175580  0.050094   \n",
       "ver                      -0.102288        -0.070954  0.137482  0.031991   \n",
       "cont_rating              -0.047829         0.084674  0.024418  0.055412   \n",
       "prime_genre              -0.073675        -0.198290  0.104579 -0.028522   \n",
       "sup_devices.num           1.000000        -0.037728 -0.041681 -0.037109   \n",
       "ipadSc_urls.num          -0.037728         1.000000  0.088378  0.071901   \n",
       "lang.num                 -0.041681         0.088378  1.000000  0.032477   \n",
       "vpp_lic                  -0.037109         0.071901  0.032477  1.000000   \n",
       "user_rating_label        -0.013138        -0.228352 -0.139049 -0.055559   \n",
       "\n",
       "                   user_rating_label  \n",
       "size_bytes                 -0.078687  \n",
       "price                      -0.048999  \n",
       "rating_count_tot           -0.064099  \n",
       "rating_count_ver           -0.049083  \n",
       "user_rating_ver            -0.519424  \n",
       "ver                        -0.041580  \n",
       "cont_rating                -0.045117  \n",
       "prime_genre                 0.038696  \n",
       "sup_devices.num            -0.013138  \n",
       "ipadSc_urls.num            -0.228352  \n",
       "lang.num                   -0.139049  \n",
       "vpp_lic                    -0.055559  \n",
       "user_rating_label           1.000000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['ver', 'cont_rating', 'prime_genre', 'user_rating_label']\n",
    "col_target = 'user_rating_label'\n",
    "\n",
    "df_cor = df.copy()\n",
    "df_cor = get_numeric_features(df_cor, columns=columns)\n",
    "\n",
    "# Display correlation matrix\n",
    "df_cor.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_features(df, col_target, threshold):\n",
    "    # Generate correlation matrix\n",
    "    cor = df.corr()\n",
    "    \n",
    "    # Correlation with target\n",
    "    # Apply abs() to get the absolute value so no need to deal with negative correlations\n",
    "    cor_target = abs(cor[col_target])\n",
    "    \n",
    "    # Select highly correlated features, with threshold\n",
    "    relevant_features = cor_target[cor_target > threshold]\n",
    "    \n",
    "    # Get names of the features which are highly correlated to the target. \n",
    "    cols = [col for col in relevant_features.index if col.lower() != col_target.lower()]\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>2.99</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>82688000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7518</td>\n",
       "      <td>643</td>\n",
       "      <td>4.5</td>\n",
       "      <td>760</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>70754304</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1147</td>\n",
       "      <td>1147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>72671232</td>\n",
       "      <td>0.99</td>\n",
       "      <td>11000</td>\n",
       "      <td>935</td>\n",
       "      <td>4.5</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>118107136</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4126</td>\n",
       "      <td>10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>177651712</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4278</td>\n",
       "      <td>911</td>\n",
       "      <td>4.5</td>\n",
       "      <td>308</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5757 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "5452    79053824   0.00                14                 3              2.5   \n",
       "3788    12320768   0.00                 0                 0              0.0   \n",
       "4381   539088896   0.00                89                 2              5.0   \n",
       "3874   223020032   0.00                 0                 0              0.0   \n",
       "3131    14583808   2.99               859                52              3.0   \n",
       "...          ...    ...               ...               ...              ...   \n",
       "4931    82688000   0.00              7518               643              4.5   \n",
       "3264    70754304   0.00              1147              1147              4.5   \n",
       "1653    72671232   0.99             11000               935              4.5   \n",
       "2607   118107136   0.00              4126                10              4.5   \n",
       "2732   177651712   0.00              4278               911              4.5   \n",
       "\n",
       "       ver cont_rating  ipadSc_urls.num  lang.num  vpp_lic  \n",
       "5452   298           2                4         1        1  \n",
       "3788    29           2                5         1        1  \n",
       "4381   649           2                5        11        1  \n",
       "3874  1115           2                5         1        1  \n",
       "3131   725           2                0         1        1  \n",
       "...    ...         ...              ...       ...      ...  \n",
       "4931   760           0                5         2        1  \n",
       "3264    80           0                5         1        1  \n",
       "1653   260           2                5        13        1  \n",
       "2607  1079           0                0        25        1  \n",
       "2732   308           2                5         8        1  \n",
       "\n",
       "[5757 rows x 10 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1: Threshold = 0.04\n",
    "cols = get_correlated_features(df_cor, col_target, threshold=0.04)\n",
    "\n",
    "x_train_cor = x_train[cols]\n",
    "x_test_cor = x_test[cols]\n",
    "\n",
    "x_train_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7750\n",
      "f1_macro (Test Decision Tree) = 0.7636\n",
      "[[1025    9   68]\n",
      " [   4  180    5]\n",
      " [  80    8   61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1102\n",
      "           1       0.91      0.95      0.93       189\n",
      "           2       0.46      0.41      0.43       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.76      0.76      0.76      1440\n",
      "weighted avg       0.87      0.88      0.88      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using 10 features with correlation with target > 0.04\n",
    "train_and_evaluate(estimators, x_train_cor, x_test_cor, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>82688000</td>\n",
       "      <td>7518</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>70754304</td>\n",
       "      <td>1147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>72671232</td>\n",
       "      <td>11000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>118107136</td>\n",
       "      <td>4126</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>177651712</td>\n",
       "      <td>4278</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5757 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  user_rating_ver  ipadSc_urls.num  \\\n",
       "5452    79053824                14              2.5                4   \n",
       "3788    12320768                 0              0.0                5   \n",
       "4381   539088896                89              5.0                5   \n",
       "3874   223020032                 0              0.0                5   \n",
       "3131    14583808               859              3.0                0   \n",
       "...          ...               ...              ...              ...   \n",
       "4931    82688000              7518              4.5                5   \n",
       "3264    70754304              1147              4.5                5   \n",
       "1653    72671232             11000              4.5                5   \n",
       "2607   118107136              4126              4.5                0   \n",
       "2732   177651712              4278              4.5                5   \n",
       "\n",
       "      lang.num  vpp_lic  \n",
       "5452         1        1  \n",
       "3788         1        1  \n",
       "4381        11        1  \n",
       "3874         1        1  \n",
       "3131         1        1  \n",
       "...        ...      ...  \n",
       "4931         2        1  \n",
       "3264         1        1  \n",
       "1653        13        1  \n",
       "2607        25        1  \n",
       "2732         8        1  \n",
       "\n",
       "[5757 rows x 6 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: threshold = 0.05\n",
    "cols = get_correlated_features(df_cor, col_target, threshold=0.05)\n",
    "\n",
    "x_train_cor = x_train[cols]\n",
    "x_test_cor = x_test[cols]\n",
    "\n",
    "x_train_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3268\n",
      "f1_macro (Test KNN) = 0.3300\n",
      "[[1062   30   10]\n",
      " [ 177   10    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.23      0.05      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.64      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7601\n",
      "f1_macro (Test Decision Tree) = 0.7525\n",
      "[[1021    5   76]\n",
      " [   4  178    7]\n",
      " [  93    1   55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1102\n",
      "           1       0.97      0.94      0.95       189\n",
      "           2       0.40      0.37      0.38       149\n",
      "\n",
      "    accuracy                           0.87      1440\n",
      "   macro avg       0.76      0.75      0.75      1440\n",
      "weighted avg       0.87      0.87      0.87      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using 10 features with correlation with target > 0.05\n",
    "train_and_evaluate(estimators, x_train_cor, x_test_cor, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5757 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_rating_ver  ipadSc_urls.num  lang.num\n",
       "5452              2.5                4         1\n",
       "3788              0.0                5         1\n",
       "4381              5.0                5        11\n",
       "3874              0.0                5         1\n",
       "3131              3.0                0         1\n",
       "...               ...              ...       ...\n",
       "4931              4.5                5         2\n",
       "3264              4.5                5         1\n",
       "1653              4.5                5        13\n",
       "2607              4.5                0        25\n",
       "2732              4.5                5         8\n",
       "\n",
       "[5757 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3: threshold = 0.1\n",
    "cols = get_correlated_features(df_cor, col_target, threshold=0.1)\n",
    "\n",
    "x_train_cor = x_train[cols]\n",
    "x_test_cor = x_test[cols]\n",
    "\n",
    "x_train_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.6846\n",
      "f1_macro (Test KNN) = 0.6373\n",
      "[[1014   46   42]\n",
      " [  74  113    2]\n",
      " [  86   15   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      1102\n",
      "           1       0.65      0.60      0.62       189\n",
      "           2       0.52      0.32      0.40       149\n",
      "\n",
      "    accuracy                           0.82      1440\n",
      "   macro avg       0.68      0.61      0.64      1440\n",
      "weighted avg       0.80      0.82      0.80      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7049\n",
      "f1_macro (Test Decision Tree) = 0.6856\n",
      "[[999  69  34]\n",
      " [ 17 169   3]\n",
      " [ 80  23  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1102\n",
      "           1       0.65      0.89      0.75       189\n",
      "           2       0.55      0.31      0.40       149\n",
      "\n",
      "    accuracy                           0.84      1440\n",
      "   macro avg       0.70      0.70      0.69      1440\n",
      "weighted avg       0.84      0.84      0.84      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.5566\n",
      "f1_macro (Test SVM) = 0.5455\n",
      "[[1013   89    0]\n",
      " [   9  180    0]\n",
      " [ 115   34    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      1102\n",
      "           1       0.59      0.95      0.73       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.83      1440\n",
      "   macro avg       0.50      0.62      0.55      1440\n",
      "weighted avg       0.76      0.83      0.79      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using 10 features with correlation with target > 0.1\n",
    "train_and_evaluate(estimators, x_train_cor, x_test_cor, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Chi-Squared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5757 entries, 5452 to 2732\n",
      "Data columns (total 12 columns):\n",
      "size_bytes          5757 non-null int64\n",
      "price               5757 non-null float64\n",
      "rating_count_tot    5757 non-null int64\n",
      "rating_count_ver    5757 non-null int64\n",
      "user_rating_ver     5757 non-null float64\n",
      "ver                 5757 non-null int32\n",
      "cont_rating         5757 non-null int32\n",
      "prime_genre         5757 non-null int32\n",
      "sup_devices.num     5757 non-null int64\n",
      "ipadSc_urls.num     5757 non-null int64\n",
      "lang.num            5757 non-null int64\n",
      "vpp_lic             5757 non-null int64\n",
      "dtypes: float64(2), int32(3), int64(7)\n",
      "memory usage: 517.2 KB\n"
     ]
    }
   ],
   "source": [
    "# columns = ['ver', 'cont_rating', 'prime_genre']\n",
    "# x_train_num = get_numeric_features(x_train, columns=columns)\n",
    "# x_test_num = get_numeric_features(x_test, columns=columns)\n",
    "# x_train_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chi2_features(X, Y, num_k=10):\n",
    "    # Create a selector\n",
    "    # Setting k: we want top k features\n",
    "    selector = SelectKBest(chi2, k=num_k)\n",
    "    \n",
    "    x_new = selector.fit_transform(X, Y)\n",
    "    col_index = selector.get_support(indices=True)\n",
    "    \n",
    "    cols = X.columns[col_index]\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>2.99</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "5452    79053824   0.00                14                 3              2.5   \n",
       "3788    12320768   0.00                 0                 0              0.0   \n",
       "4381   539088896   0.00                89                 2              5.0   \n",
       "3874   223020032   0.00                 0                 0              0.0   \n",
       "3131    14583808   2.99               859                52              3.0   \n",
       "\n",
       "       ver prime_genre  sup_devices.num  ipadSc_urls.num  lang.num  \n",
       "5452   298           7               38                4         1  \n",
       "3788    29           9               38                5         1  \n",
       "4381   649           7               38                5        11  \n",
       "3874  1115           7               38                5         1  \n",
       "3131   725           8               13                0         1  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Case 1: k = 10\n",
    "# cols = get_chi2_features(x_train_num, y_train, num_k=10)\n",
    "\n",
    "# x_train_chi2 = x_train_num[cols]\n",
    "# x_test_chi2 = x_test_num[cols]\n",
    "\n",
    "cols = get_chi2_features(x_train, y_train, num_k=10)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7763\n",
      "f1_macro (Test Decision Tree) = 0.7881\n",
      "[[1036   15   51]\n",
      " [   5  182    2]\n",
      " [  78    4   67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1102\n",
      "           1       0.91      0.96      0.93       189\n",
      "           2       0.56      0.45      0.50       149\n",
      "\n",
      "    accuracy                           0.89      1440\n",
      "   macro avg       0.80      0.78      0.79      1440\n",
      "weighted avg       0.89      0.89      0.89      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using top 10 features - chi2\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  rating_count_ver  user_rating_ver   ver  \\\n",
       "5452    79053824                14                 3              2.5   298   \n",
       "3788    12320768                 0                 0              0.0    29   \n",
       "4381   539088896                89                 2              5.0   649   \n",
       "3874   223020032                 0                 0              0.0  1115   \n",
       "3131    14583808               859                52              3.0   725   \n",
       "\n",
       "      ipadSc_urls.num  lang.num  \n",
       "5452                4         1  \n",
       "3788                5         1  \n",
       "4381                5        11  \n",
       "3874                5         1  \n",
       "3131                0         1  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: k = 7\n",
    "cols = get_chi2_features(x_train, y_train, num_k=7)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7785\n",
      "f1_macro (Test Decision Tree) = 0.7581\n",
      "[[1030    7   65]\n",
      " [   4  180    5]\n",
      " [  86    7   56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1102\n",
      "           1       0.93      0.95      0.94       189\n",
      "           2       0.44      0.38      0.41       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.76      0.75      0.76      1440\n",
      "weighted avg       0.87      0.88      0.87      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using top 7 features - chi2\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  rating_count_ver   ver\n",
       "5452    79053824                14                 3   298\n",
       "3788    12320768                 0                 0    29\n",
       "4381   539088896                89                 2   649\n",
       "3874   223020032                 0                 0  1115\n",
       "3131    14583808               859                52   725"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: k = 4\n",
    "cols = get_chi2_features(x_train, y_train, num_k=4)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.6591\n",
      "f1_macro (Test Decision Tree) = 0.6473\n",
      "[[980  15 107]\n",
      " [ 17 167   5]\n",
      " [121   4  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1102\n",
      "           1       0.90      0.88      0.89       189\n",
      "           2       0.18      0.16      0.17       149\n",
      "\n",
      "    accuracy                           0.81      1440\n",
      "   macro avg       0.65      0.64      0.65      1440\n",
      "weighted avg       0.81      0.81      0.81      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using top 4 features - chi2\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ig_features(X, Y, num_k=10):\n",
    "    # Create a selector\n",
    "    # Setting k: we want top k features\n",
    "    selector = SelectKBest(mutual_info_classif, k=num_k)\n",
    "    \n",
    "    x_new = selector.fit_transform(X, Y)\n",
    "    col_index = selector.get_support(indices=True)\n",
    "    \n",
    "    cols = X.columns[col_index]\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>2.99</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "5452    79053824   0.00                14                 3              2.5   \n",
       "3788    12320768   0.00                 0                 0              0.0   \n",
       "4381   539088896   0.00                89                 2              5.0   \n",
       "3874   223020032   0.00                 0                 0              0.0   \n",
       "3131    14583808   2.99               859                52              3.0   \n",
       "\n",
       "       ver cont_rating prime_genre  ipadSc_urls.num  lang.num  \n",
       "5452   298           2           7                4         1  \n",
       "3788    29           2           9                5         1  \n",
       "4381   649           2           7                5        11  \n",
       "3874  1115           2           7                5         1  \n",
       "3131   725           2           8                0         1  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1: k = 10\n",
    "cols = get_ig_features(x_train, y_train, num_k=10)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7742\n",
      "f1_macro (Test Decision Tree) = 0.7765\n",
      "[[1025   11   66]\n",
      " [   5  180    4]\n",
      " [  76    6   67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.91      0.95      0.93       189\n",
      "           2       0.49      0.45      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.78      0.78      0.78      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using top 10 features - information gain\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "5452    79053824                14                 3              2.5   \n",
       "3788    12320768                 0                 0              0.0   \n",
       "4381   539088896                89                 2              5.0   \n",
       "3874   223020032                 0                 0              0.0   \n",
       "3131    14583808               859                52              3.0   \n",
       "\n",
       "     prime_genre  ipadSc_urls.num  lang.num  \n",
       "5452           7                4         1  \n",
       "3788           9                5         1  \n",
       "4381           7                5        11  \n",
       "3874           7                5         1  \n",
       "3131           8                0         1  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: k = 7\n",
    "cols = get_ig_features(x_train, y_train, num_k=7)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.6161\n",
      "f1_macro (Test KNN) = 0.6286\n",
      "[[1054   19   29]\n",
      " [  14  175    0]\n",
      " [ 134    8    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91      1102\n",
      "           1       0.87      0.93      0.90       189\n",
      "           2       0.19      0.05      0.08       149\n",
      "\n",
      "    accuracy                           0.86      1440\n",
      "   macro avg       0.65      0.64      0.63      1440\n",
      "weighted avg       0.80      0.86      0.83      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7691\n",
      "f1_macro (Test Decision Tree) = 0.7641\n",
      "[[1020   16   66]\n",
      " [   2  180    7]\n",
      " [  78    7   64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.89      0.95      0.92       189\n",
      "           2       0.47      0.43      0.45       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.76      0.77      0.76      1440\n",
      "weighted avg       0.87      0.88      0.88      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using top 7 features - information gain\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating_count_tot  rating_count_ver  user_rating_ver  lang.num\n",
       "5452                14                 3              2.5         1\n",
       "3788                 0                 0              0.0         1\n",
       "4381                89                 2              5.0        11\n",
       "3874                 0                 0              0.0         1\n",
       "3131               859                52              3.0         1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3: k = 4\n",
    "cols = get_ig_features(x_train, y_train, num_k=4)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.6900\n",
      "f1_macro (Test KNN) = 0.6653\n",
      "[[1082    0   20]\n",
      " [   9  175    5]\n",
      " [ 138    1   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1102\n",
      "           1       0.99      0.93      0.96       189\n",
      "           2       0.29      0.07      0.11       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.72      0.66      0.67      1440\n",
      "weighted avg       0.83      0.88      0.85      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7766\n",
      "f1_macro (Test Decision Tree) = 0.7565\n",
      "[[1024    2   76]\n",
      " [   5  183    1]\n",
      " [  92    4   53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1102\n",
      "           1       0.97      0.97      0.97       189\n",
      "           2       0.41      0.36      0.38       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.76      0.75      0.76      1440\n",
      "weighted avg       0.87      0.88      0.87      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using top 4 features - information gain\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function\n",
    "def normalize_features(df):\n",
    "    # Names of the features\n",
    "    names = df.columns\n",
    "    \n",
    "    # Create the Scaler object\n",
    "    normalizer = preprocessing.Normalizer()\n",
    "    df_norm = normalizer.fit_transform(df)\n",
    "    df_norm = pd.DataFrame(df_norm, columns=names)\n",
    "    \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-5.789039e-06</td>\n",
       "      <td>-0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-5.936699e-06</td>\n",
       "      <td>-0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-6.059672e-06</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-5.713223e-06</td>\n",
       "      <td>-0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000099</td>\n",
       "      <td>8.565898e-07</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1           PC2       PC3\n",
       "0 -0.000158 -5.789039e-06 -0.000009\n",
       "1 -0.000158 -5.936699e-06 -0.000010\n",
       "2 -0.000158 -6.059672e-06 -0.000011\n",
       "3 -0.000158 -5.713223e-06 -0.000007\n",
       "4 -0.000099  8.565898e-07  0.000037"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm = normalize_features(x_train)\n",
    "x_test_norm = normalize_features(x_test)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(x_train_norm)\n",
    "\n",
    "train_pca = pca.transform(x_train_norm)\n",
    "test_pca = pca.transform(x_test_norm)\n",
    "\n",
    "col_pca = ['PC1', 'PC2', 'PC3']\n",
    "\n",
    "principalDf = pd.DataFrame(data=train_pca, columns=col_pca)\n",
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components: 1\n",
      "---\n",
      "f1_macro (Validation KNN) = 0.5307\n",
      "f1_macro (Test KNN) = 0.5241\n",
      "[[1042   51    9]\n",
      " [  58  129    2]\n",
      " [ 140    9    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      1102\n",
      "           1       0.68      0.68      0.68       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.81      1440\n",
      "   macro avg       0.51      0.54      0.52      1440\n",
      "weighted avg       0.73      0.81      0.77      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.2869\n",
      "f1_macro (Test Decision Tree) = 0.2869\n",
      "[[1088    1   13]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.25      0.33      0.29      1440\n",
      "weighted avg       0.58      0.76      0.66      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2909\n",
      "f1_macro (Test SVM) = 0.2934\n",
      "[[1101    0    1]\n",
      " [ 189    0    0]\n",
      " [ 148    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.50      0.01      0.01       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.42      0.34      0.29      1440\n",
      "weighted avg       0.64      0.77      0.66      1440\n",
      "\n",
      "\n",
      "Number of principal components: 2\n",
      "---\n",
      "f1_macro (Validation KNN) = 0.6254\n",
      "f1_macro (Test KNN) = 0.6297\n",
      "[[1079   12   11]\n",
      " [  21  168    0]\n",
      " [ 143    1    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      1102\n",
      "           1       0.93      0.89      0.91       189\n",
      "           2       0.31      0.03      0.06       149\n",
      "\n",
      "    accuracy                           0.87      1440\n",
      "   macro avg       0.70      0.63      0.63      1440\n",
      "weighted avg       0.82      0.87      0.83      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.3299\n",
      "f1_macro (Test Decision Tree) = 0.3138\n",
      "[[1057    1   44]\n",
      " [ 185    3    1]\n",
      " [ 142    1    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85      1102\n",
      "           1       0.60      0.02      0.03       189\n",
      "           2       0.12      0.04      0.06       149\n",
      "\n",
      "    accuracy                           0.74      1440\n",
      "   macro avg       0.49      0.34      0.31      1440\n",
      "weighted avg       0.68      0.74      0.66      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2878\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "Number of principal components: 3\n",
      "---\n",
      "f1_macro (Validation KNN) = 0.5867\n",
      "f1_macro (Test KNN) = 0.6043\n",
      "[[1047   45   10]\n",
      " [  18  170    1]\n",
      " [ 130   12    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1102\n",
      "           1       0.75      0.90      0.82       189\n",
      "           2       0.39      0.05      0.08       149\n",
      "\n",
      "    accuracy                           0.85      1440\n",
      "   macro avg       0.67      0.63      0.60      1440\n",
      "weighted avg       0.81      0.85      0.81      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.4364\n",
      "f1_macro (Test Decision Tree) = 0.3983\n",
      "[[1040   12   50]\n",
      " [ 161   25    3]\n",
      " [ 136    0   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1102\n",
      "           1       0.68      0.13      0.22       189\n",
      "           2       0.20      0.09      0.12       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.55      0.39      0.40      1440\n",
      "weighted avg       0.70      0.75      0.69      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_pc in range(1, principalDf.shape[1]+1):\n",
    "    print(\"Number of principal components: {}\".format(num_pc))\n",
    "    print(\"---\")\n",
    "    \n",
    "    df_pca_train = pd.DataFrame(data = train_pca[:,:num_pc], columns = col_pca[:num_pc])\n",
    "    df_pca_test = pd.DataFrame(data = test_pca[:,:num_pc], columns = col_pca[:num_pc])\n",
    "  \n",
    "    train_and_evaluate(estimators, df_pca_train, df_pca_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.729537e-06</td>\n",
       "      <td>1.096675e-07</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.479318e-07</td>\n",
       "      <td>3.603370e-05</td>\n",
       "      <td>1.208544e-07</td>\n",
       "      <td>7.572699e-07</td>\n",
       "      <td>2.383384e-06</td>\n",
       "      <td>1.417095e-07</td>\n",
       "      <td>1.969103e-07</td>\n",
       "      <td>6.244423e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.850639e-06</td>\n",
       "      <td>-2.720284e-08</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-2.374795e-08</td>\n",
       "      <td>-6.612498e-06</td>\n",
       "      <td>-2.539387e-08</td>\n",
       "      <td>-2.045319e-07</td>\n",
       "      <td>-5.409411e-07</td>\n",
       "      <td>-2.928681e-08</td>\n",
       "      <td>-3.355409e-08</td>\n",
       "      <td>-1.430328e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.488976e-07</td>\n",
       "      <td>-5.203757e-10</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.284545e-09</td>\n",
       "      <td>-3.603155e-07</td>\n",
       "      <td>-3.209692e-10</td>\n",
       "      <td>-4.269422e-09</td>\n",
       "      <td>2.429558e-10</td>\n",
       "      <td>8.931404e-10</td>\n",
       "      <td>5.979289e-11</td>\n",
       "      <td>-8.504671e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes         price  rating_count_tot  rating_count_ver  \\\n",
       "0  -1.729537e-06  1.096675e-07          0.000233          0.000008   \n",
       "1  -5.850639e-06 -2.720284e-08          0.000716          0.000014   \n",
       "2   2.488976e-07 -5.203757e-10         -0.000002          0.000011   \n",
       "3   0.000000e+00 -0.000000e+00          0.000000          0.000000   \n",
       "4   0.000000e+00  0.000000e+00          0.000000         -0.000000   \n",
       "5  -0.000000e+00  0.000000e+00         -0.000000          0.000000   \n",
       "6  -0.000000e+00  0.000000e+00         -0.000000          0.000000   \n",
       "7   0.000000e+00  0.000000e+00          0.000000         -0.000000   \n",
       "8  -0.000000e+00  0.000000e+00         -0.000000         -0.000000   \n",
       "9   0.000000e+00  0.000000e+00          0.000000          0.000000   \n",
       "10 -0.000000e+00  0.000000e+00          0.000000         -0.000000   \n",
       "11 -0.000000e+00  0.000000e+00         -0.000000         -0.000000   \n",
       "\n",
       "    user_rating_ver           ver   cont_rating   prime_genre  \\\n",
       "0      1.479318e-07  3.603370e-05  1.208544e-07  7.572699e-07   \n",
       "1     -2.374795e-08 -6.612498e-06 -2.539387e-08 -2.045319e-07   \n",
       "2      2.284545e-09 -3.603155e-07 -3.209692e-10 -4.269422e-09   \n",
       "3     -0.000000e+00  0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "4      0.000000e+00 -0.000000e+00  0.000000e+00 -0.000000e+00   \n",
       "5      0.000000e+00  0.000000e+00  0.000000e+00 -0.000000e+00   \n",
       "6     -0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00   \n",
       "7     -0.000000e+00 -0.000000e+00  0.000000e+00 -0.000000e+00   \n",
       "8      0.000000e+00 -0.000000e+00 -0.000000e+00  0.000000e+00   \n",
       "9      0.000000e+00 -0.000000e+00  0.000000e+00 -0.000000e+00   \n",
       "10    -0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00   \n",
       "11     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "    sup_devices.num  ipadSc_urls.num      lang.num       vpp_lic  \n",
       "0      2.383384e-06     1.417095e-07  1.969103e-07  6.244423e-08  \n",
       "1     -5.409411e-07    -2.928681e-08 -3.355409e-08 -1.430328e-08  \n",
       "2      2.429558e-10     8.931404e-10  5.979289e-11 -8.504671e-11  \n",
       "3     -0.000000e+00    -0.000000e+00 -0.000000e+00 -0.000000e+00  \n",
       "4      0.000000e+00     0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "5      0.000000e+00     0.000000e+00 -0.000000e+00  0.000000e+00  \n",
       "6     -0.000000e+00     0.000000e+00  0.000000e+00 -0.000000e+00  \n",
       "7     -0.000000e+00     0.000000e+00 -0.000000e+00  0.000000e+00  \n",
       "8     -0.000000e+00     0.000000e+00 -0.000000e+00  0.000000e+00  \n",
       "9     -0.000000e+00    -0.000000e+00  0.000000e+00 -0.000000e+00  \n",
       "10     0.000000e+00     0.000000e+00  0.000000e+00 -0.000000e+00  \n",
       "11     0.000000e+00     0.000000e+00  0.000000e+00 -0.000000e+00  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the number of factors to 11\n",
    "factor = FactorAnalysis(n_components = None, random_state = 101).fit(x_train_norm)\n",
    "# Convert the factor loadings into a data frame\n",
    "factor_df = pd.DataFrame(factor.components_, columns = x_train.columns)\n",
    "factor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor 1</th>\n",
       "      <th>Factor 2</th>\n",
       "      <th>Factor 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.202359</td>\n",
       "      <td>-0.055045</td>\n",
       "      <td>-0.016727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.290771</td>\n",
       "      <td>-0.208415</td>\n",
       "      <td>-0.018769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.292407</td>\n",
       "      <td>-0.028512</td>\n",
       "      <td>-0.015958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.252034</td>\n",
       "      <td>-0.039544</td>\n",
       "      <td>-0.017033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243263</td>\n",
       "      <td>-0.141611</td>\n",
       "      <td>-0.019807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Factor 1  Factor 2  Factor 3\n",
       "0 -0.202359 -0.055045 -0.016727\n",
       "1  0.290771 -0.208415 -0.018769\n",
       "2 -0.292407 -0.028512 -0.015958\n",
       "3 -0.252034 -0.039544 -0.017033\n",
       "4  0.243263 -0.141611 -0.019807"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Factor 1', 'Factor 2', 'Factor 3']\n",
    "\n",
    "x_train_factor = factor.fit_transform(x_train_norm)\n",
    "x_test_factor = factor.fit_transform(x_test_norm)\n",
    "\n",
    "x_train_factor = pd.DataFrame(data = x_train_factor[:,:3], columns = columns)\n",
    "x_test_factor = pd.DataFrame(data = x_test_factor[:,:3], columns = columns)\n",
    "\n",
    "x_train_factor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.4289\n",
      "f1_macro (Test KNN) = 0.2213\n",
      "[[413 688   1]\n",
      " [104  85   0]\n",
      " [ 84  64   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.37      0.49      1102\n",
      "           1       0.10      0.45      0.17       189\n",
      "           2       0.50      0.01      0.01       149\n",
      "\n",
      "    accuracy                           0.35      1440\n",
      "   macro avg       0.43      0.28      0.22      1440\n",
      "weighted avg       0.59      0.35      0.39      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.4719\n",
      "f1_macro (Test Decision Tree) = 0.2070\n",
      "[[414   0 688]\n",
      " [110   0  79]\n",
      " [ 82   0  67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.38      0.48      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.08      0.45      0.14       149\n",
      "\n",
      "    accuracy                           0.33      1440\n",
      "   macro avg       0.25      0.28      0.21      1440\n",
      "weighted avg       0.53      0.33      0.39      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2901\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(estimators, x_train_factor, x_test_factor, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set 3: Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Default Classifiers\n",
    "\n",
    "We start with a few selected classifiers with their respective default parameters without ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary of classifiers\n",
    "# max_iter - stopping criteria: to speed up the training process\n",
    "# dict_clf_default = {\n",
    "#     # --- clf_index: 0 - 4\n",
    "#     \"K-Nearest Neighbors\": KNeighborsClassifier(), \n",
    "#     \"Decision Tree\": DecisionTreeClassifier(random_state=0), \n",
    "#     \"Gaussian Naive Bayes\": GaussianNB(), \n",
    "#     \"Bernoulli Naive Bayes\": BernoulliNB(), \n",
    "#     \"Multinomial Naive Bayes\": MultinomialNB(), \n",
    "#     # --- clf_index: 5 - 9\n",
    "#     \"Linear SVM\": SVC(kernel='linear', max_iter=10000), \n",
    "#     \"Polynomial SVM\": SVC(kernel='poly', max_iter=10000), \n",
    "#     \"RBF SVM\": SVC(kernel='rbf', max_iter=10000), \n",
    "#     \"Sigmoid SVM\": SVC(kernel='sigmoid', max_iter=10000),\n",
    "#     \"Logistic Regression\": LogisticRegression()\n",
    "#    }\n",
    "\n",
    "\n",
    "dict_clf_default = {\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(), \n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"Linear SVM\": SVC(kernel='linear', max_iter=400), \n",
    "    \"Polynomial SVM\": SVC(kernel='poly', max_iter=400), \n",
    "    \"RBF SVM\": SVC(kernel='rbf', max_iter=400), \n",
    "    \"Sigmoid SVM\": SVC(kernel='sigmoid', max_iter=400),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `clf_index` from 0 - 9, each corresponding to the default classifier defined in `dict_clf_default`. \n",
    "\n",
    "Helper function `test_model()` is called to test the model test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Decision Tree) = 0.7764\n",
      "f1_macro (Test Decision Tree) = 0.7732\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify one classifier\n",
    "clf_index = 1\n",
    "\n",
    "estimator_name = list(dict_clf_default.keys())[clf_index]\n",
    "estimator = {estimator_name: dict_clf_default[estimator_name]}\n",
    "\n",
    "# # Print classifier name\n",
    "# print(\"{}\\n===\".format(estimator_name))\n",
    "\n",
    "# # Test using features with original Scale\n",
    "# print(\"Original scale\\n---\")\n",
    "# _ = test_model(estimator, x_train, x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "# # Test using features with standardized scale\n",
    "# print(\"\\nStandardized scale\\n---\")\n",
    "# _ = test_model(estimator, scaled_x_train, scaled_x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the test performance of different models by using a `for` loop.\n",
    "\n",
    "Then, initialize two list variables: `list_clf` and `list_score`. These two lists are used to store list of classifier names and model test performance respectively. These values are used to generate a CSV file and bar plot respectively.\n",
    "\n",
    "Then, a horizontal barplot is generated to visualize the test performance by using the function `matplotlib.pyplot.barh()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation K-Nearest Neighbors) = 0.3262\n",
      "f1_macro (Test K-Nearest Neighbors) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7764\n",
      "f1_macro (Test Decision Tree) = 0.7732\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Linear SVM) = 0.2238\n",
      "f1_macro (Test Linear SVM) = 0.2900\n",
      "[[1020   21   61]\n",
      " [ 184    1    4]\n",
      " [ 143    3    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.83      1102\n",
      "           1       0.04      0.01      0.01       189\n",
      "           2       0.04      0.02      0.03       149\n",
      "\n",
      "    accuracy                           0.71      1440\n",
      "   macro avg       0.28      0.32      0.29      1440\n",
      "weighted avg       0.59      0.71      0.64      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Polynomial SVM) = 0.1641\n",
      "f1_macro (Test Polynomial SVM) = 0.0770\n",
      "[[   0 1102    0]\n",
      " [   1  188    0]\n",
      " [   0  149    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1102\n",
      "           1       0.13      0.99      0.23       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.13      1440\n",
      "   macro avg       0.04      0.33      0.08      1440\n",
      "weighted avg       0.02      0.13      0.03      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation RBF SVM) = 0.1328\n",
      "f1_macro (Test RBF SVM) = 0.1285\n",
      "[[115  16 971]\n",
      " [  6   1 182]\n",
      " [  8   5 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.10      0.19      1102\n",
      "           1       0.05      0.01      0.01       189\n",
      "           2       0.11      0.91      0.19       149\n",
      "\n",
      "    accuracy                           0.17      1440\n",
      "   macro avg       0.35      0.34      0.13      1440\n",
      "weighted avg       0.70      0.17      0.16      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Sigmoid SVM) = 0.1841\n",
      "f1_macro (Test Sigmoid SVM) = 0.1902\n",
      "[[265   0 837]\n",
      " [ 24   0 165]\n",
      " [ 24   0 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.24      0.37      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.11      0.84      0.20       149\n",
      "\n",
      "    accuracy                           0.27      1440\n",
      "   macro avg       0.32      0.36      0.19      1440\n",
      "weighted avg       0.66      0.27      0.31      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Logistic Regression) = 0.2881\n",
      "f1_macro (Test Logistic Regression) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAGJCAYAAADv1AnGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdebgkVX3/8ffHAVGUVcBMcBkXXKLoqAOKccElBsEEjSgoKhgVjYrR/IziEkWNBuMuxgVccMUNwQUVFAUXRBlgYADFjUFRlB1EEFm+vz/qNPQ0997qO3Nn7mXu+/U897ndp05VfU9Vd/W3z6mqTlUhSZIkTeUWsx2AJEmS5j6TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJpnKeS7J2k2t89Jpi+49D0x87QOhe15e29CvMem+TYKaYfMhTvVH87rkYTBuvaP8mjx6y798j6/5Tk1CQvTrLe6sYytJ7bJPlkkvPbet49U8ueb5IcmOSrQ88XDe2/fSaof5u2XyvJf6/daFfdBK/N4b/HDtV7S5Kjk1y0qu/fm5Mkt05yXpKnzHYsAxPsqz8nWZHk8CRPTXKLkfoTHmuTvDrJb5Jcm2RZK/ubJF9JcnGb56VrsWljSbJpO+4+cJrzPT7J19px8Zokf2xtfdJQnf2TzMq9B9vn1oqRsnsl+U6Sy9v+eOJsxjhqxj60dLP1J+CZwH+NlD+rTdtorUe0at4EfHDo+XOB5wAPA64bKj9zBtb1euDNwHemMc9TgHOBjdvjA4GtgNfNQDwALwKeBvwr8HPgvBla7ryS5G7A84GHTjB58F45aKT8ycCcOKCvosFrc9jw+2RfYBnwNbrjwjqtqq5K8r/A/yQ5oqqume2Yhgz21QbAnYBdgEOBfZL8U1Vd1eqdB+wA/GowY5Lt6Y5bbwOOoHs9Q3cMeiSwd5tvxZpuxCrYlO64ey5w8jgzJHkH8B/AF4EXA38Abg/8E/D5JEuq6tQ1E+7Y3gS8Z6TsncBdgacClwJnAUuBb67d0CZm0qgvAc9I8rpqd3pPcmu6D8LD6A4kc15V/YqVD5A7tYc/rqprZyeqlSyrql+2x0cnuTvwUlYzaUyyQVVdDdwb+H1VfWI14xxd7nzzUuDUqlo6wbQvAc9KcpeqOnuo/FnMwntlBvfR8GtzIptU1fXtNXuzTBpXYVsdAhwAPAn4/BoJatWM7qtPJvkC8AXgf+kSfFpbTxiZ997t/wer6tcj5adW1eEzEeBcOHYkeQZdwvjyqnrHyOQvJHkPcMnaj2xl7XNr1L2B71XVcJJ4CTf9YrdKkqwPXFur+MsuDk/rk8Cd6XrkBp4ELKD7ILyJJM9oQ6x/SXJhGxZdOFJnwyTvb0NaVyT5CnCHSZb3yCTHtCG+Pyc5Ksl9Z6Z5K61nvSSvSvKzJFcn+X2SdyS51UidNyX51VD7fpDkYW364I32mqGhov1XIZwTgY2SbNWWe/82bHJJkquS/DDJw0fiPyTJuUl2SHJ8kquA/20x7Q3cMSPD8Enu2YawLm3LPWEooR4sd/82z33btr+C9kHZyv87yf9Lck7bP0cm2ar9fT7JZUl+m+SVI8vdMsmHkvw8yZWtzmeSbD3J+rdpy76iret1uemw25btdfXbtg9/215/GwzV6d2WE2nLeAbwmUmq/AD4daszmOcOwKOAmyTr47Z/KObD2/vlqiRnJXnV0PRj2+vwn5KckuRq4IVt2vZJvt2225/be2n7vvaOq6qun4nlJPn3JD9t7bskydIMDRO2Ok9q++uKdMNzP0nyz0PTN07yvvbevbptp5clyVCdwak1/5Lk4CQXAH8cmv68rHz8+kiSzUfafAlwFN2IxThtG+eYuCLJp5Ls0bbDn9s2eNhkyx1HVR0GfBl4XpIN27pWGp5Od2rPIW2WX7Vph6Q7duwIPDw3HjsWtXnukuTTSS5o23rZBPtrqmPHhknemuTsJH9t/18z/J4e2lf/3PbrhW19n0qy6aAtwOBL2sFDce49xWZ5NXD6BAnjYJudVFW/mWzmdKcP/SjdkP2l6Y6bu4zUmfKzotV5enu/XpHuOLk8yfOHpt8wPD3YFsAi4JmDdg5v5wnW3/d5NngdvDDJ/yb5PXA1sGm60xI+PvReOi/dUP5WU2xXk0ZxDvA9umG3gWcBhwNXjFZOd07XJ4GfAv8C7Af8I3BcktsOVf0Q3QH3na3eWUzwYdzeiMe0dT0DeDrdkPj3k9xxNds26lPAa1scuwD/QzeE/emhOq8EXga8l65dz27xDT5Udmj/D2mPdwA+vAqx3IVu2PyKdOfpHN/W8Ty6Xt6LgG8nedDIfJsAn6Ubknp8a8sOdB9wfxiK6eQkf0uX6NyfbnhmMNxxZJLHTxDTl4HjgH8G3jVU/kzg0XRJyr7Aw+mSpMOB01q8XwcOSLLz0HybA38BXgXsBPwnsA3ww+ED25DD6Yb8n0g3fPYGYK/BxCSbte20O93ramfgFcD6wC1bnelsy1EPoRsG+/4UdT7Fyu+VZ9D1ABw7Qd2x2p8uwfsRcDe6194urX2jX7LuQfe6PJDutXlMkvvR7bPN6L44PIvuFIjjkty/p70DC9oH0OBvwZjzjS3JnsA76F63OwN70g0bbj5UZ1+63tzz6fb7U+heE4va9FsAR9K9J99BN8z4Tbpt9eYJVnsgELr9tXdbxgHA+4Fv073O/5Nu33xjgnZ/D3jkJK/V4baNe0yE7r3z/+hOB9qd7sv51wYJ0mr4Ot2Q9ZJJpr+Q7nhHi3EHuuHeHejew6dw47HjvHbs/THdseNldNvqZOCwDCXxQ1Y6dqQ7X3uQdL+H7lj1Ybp2v22C+d9Dd4rH04E30r1vB8O257WYaW0YxHnkRA1tx717A1+daPqYFrV4n0K3n5bS7afh4+aUnxUtefwU3XZ5YlvWwXTHmImcTNeuC+j256Cdkxnn82zgNXTHj33oOoX+Qvea3YHuPfAPwEvojmUbTrFOqCr/5uEf3UG0gLvTnQd3CXArYCFwbXsR7djqPLbNs4DuG/t3R5b1sFbvJe35PekSov1G6n2g1dt7qOyXwDEj9TYGLgTePVR2LHDsNNq3f1vXeu35w9vzZ43U27OVL27PvwZ8qWfZBfz3NLfzPelOB9mM7py564AjWp1j6D5wbjk034JWdsRQ2SFtWbtOsJ5PAStGyt7e9uXdR5Z7FnDyBNvq3ydp688H27GVvbOVv3aobD26D/uPTbEtFgB3bPM+aYL1P3uk/nLg6KHnb2zb7QFTrGOsbTnJvK8Erh+et5UvavE9l+5cowIe0qadAbx5nNfFFO3/HvBbYMMp5j22xbZ4pPyLdF8ENh15/1w8xut48Noc/fvBJPXvzsj7dxrvx/cNv+YmmL4x3Tl2k8YMPGGi9dN9uF8NbNGe79jqHT7BfrwOeN1I+d+3+k8cKX9MK39ozz7tPSa2shV0x9nNhsqWtHpPH3Nf3X2S6f/Ypu8+8prde6jOc1vZopF5f8DIsRX4CF3ycruR8m/RDZFPeeygS9QLeMRI+WuAvwJbjeyrj0/wevkLkNH34BivtQe3us8f87W5P1BTTL8F3fHtaODLQ+VTflYALwcu7ln3Idz0uH0ucMhUMTL+59lgu5082JZDda8Yfn2O+2dPo6A7H2YDum/ue9L1WB0zQb170l28sdI3mar6AV2P5SNb0YPp3mij5wJ9dvhJkm3oelc+PdzTAVxJ1/PyiNVo06id6A5Wh42s6+g2fbCuE4Gdk7w5ycOS3HKG1v8z4Bq6D/P3023Df013/ugj6fbB9UNxha43ZHQbXEt3sBrHI4ATaugcqKq6jq63Z3GSjUfqT3ZO07dq5fNCf9b+HzW03GvpvgCs1Duc5N/SDdtd0WIfDAndc4L1jPYcnE53sv/A44ATq+qUiYJchW056m+By6vqr5NVqO5csB/SDR8tAf6OCYamh2Kasv3phhP/Hvh0VV3ZE9+Kqlo2UvYI4GtVdelQjJcDX+HG92OfJwHbDf09Z8z5puNEutfcgUke29o97KHAbbnpRUbDHkGXOB86Uv4pup7m0V6Z0dfzP9Adl0aPNz8GLuemr48L2v+/nSKmcY+JAz+qbuh7YHn7fydWz2B4vlZzOQM70fV2XTayrY4C7j/GsWMnuvYfP8Hxdn26Xv1ho+/95XSfSbefgbZMW5IHtaHaP9K9b6+he/0MH7f6PitOBDZLN9T+hBnoTR427ufZwBHVMsWR+P4z3Wkj2yY3nuIxFZNGUVV/ohsOfCbd8Nana+LzmAZDSRNdmfuHoemDc3n+OFJn9Png3ImP0L0ph/+eANxuzCaMYyu6D5YrRtZzfps+WNdb6IZt/plumPKiJB9LssVqrn/wwXwv4DZV9ayquphumy2gG7YZ3QYvpjvoDL9Pz2+J3zg2Z/J9Fbpez2GTXXE9esL4X6coHx523ZcbhwL/BdieGz8sJhryu3jk+dUj9W7H1CeDT3dbjrpVW2efT9ANWT0X+ElVnTVRpTHbvxndcXick9wn2j9T7ePR/TuZ06tq6dDfhO1ZTZ8A/o3uC+VRwMVJvpR2/hw3vv/69u/FddOLLP4wNH3Y6HYZHG9+yU1fHxtz0+PN4ErkW/fENNG6BnGNxrTSa3yoLVMOgY9h8GVtpu6asBXdZ8HodhoMLY9uq4m29Z0nmP8nk8w/0XsfVm27/Lb9v/MqzEsbmh8MM+9L94VmO7pTIYbjmfKzoqqOoxuSviNdUn1BunOP77cqcY0Y9/NsYKLXxe50Xy5fQXeKwu8ywXnko7x6WgOfoPu2dwu6W7dMZPDG/psJpv0N3XkfcOML9PZ0Fw4w9HzYRe3/q+g+WEdN2uOzCi6iG+6Y7IKI3wNUd3uNtwJvTfI3dMnrO+nO89h9NdZ/ek18heqldL0n/8ckPVYjCfx0ehIuZvJ9Vdz0QD1TvRQDe9CdevD/BgVJ7rIay7sQuMlFJEOmuy1HXcR4idbn6c63eh7deUCTGaf9l7SYp2rXwET7Z6p9PLp/Z03r5fgQ8KF2burj6M5L/BxdInlhq7o1XQ/zRC4GNk9yy5He4EH7LxqpP7q9BtMfx8RXzo7OP0j4LhytOBLTcAzDho+Ja9oudMe3k2ZoeRfRJUJvnWT670eeT7Stz6Y7j3oiK1Y5sh5V9fskP6UbOXv1KixiJ7pzx59aVTd8iRntHR/ns6Kqvgh8sZ3bumOr/80kd+g5FvUZ6/NsONzRClV1Pt2t2l6U5J505xG/ga6H/QOTrdikUQPfovswvLSqzpikzll0vYV70PUOApDkoXTf6gZXqv2Y7oPwqXS3rRjYY4LlrQDuU1UHsGZ9k+6ctU2qaqKh95uoqj8AH24Xdwxfzf1Xpu59GFtV/TnJ9+lOOD95NQ8ko44DXppkUVWtAGgn++8OnNJ6mNekDemG/YY9ezWWdzTw2iT3rwnurzYD2/JnwPrtgD5pj1dVXZrkf4AHMHLKxYje9lfVlUl+QHfbqzfWjffZG9dxwC5JNhrszyQb0X1gHjvNZa0VbXj2c0keTHd+L3QXL11Bd6L+UZPMehzdSftPYeXh4D3p3pOjt5gZ9S2649KdqupbY4Q6SPCn6nkd95i4xiT5F7rerveMcYrDuL5JN9x/xiq8JgfzPxm4oqp+1ld5DIOex3GPu2+hux3Rf1TVO0cnJnkAcFFNfAX1IDm8Zqj+PehOI5nwuDDFZ8Vg+hV0F9Lcle4L5+248fSHVTHtz7OptNGFVyd5ARPEP8ykUcAN57pN1sN4Q50kr6PrLfgU3blEW9NdufgL4GOt3llJPgO8sXV1n0h3PsjOI8urJC8CvtzOB/k83bf629MNCfxmojf8Krbv2CSH0n3reyfdMMn1dCcK7wy8sqp+nuTLwKl0Jw5fQpcY7ETXSzJwJt0H9Tdbnd9X1eg3u+n4D7qLIY5K8hG6ntotgAcCC6pqv1Vc7rvoTqD/VpLX0yUwL6S7im6XKeabKd8EXpnk1XTb+9HAbquxvHfRXV357XS/vLKcbjvtCrygJU2rsy2/1/5vT89wcVW9cYx4x23/y+kSoh+luyHxuXQX3Cyuqn171vEmuh6OY5K8la5H4ZV0H3zjxNgrySOBLbmxN21JO0dz0JMyzjIOorvQ5Ud0Q2j3oDsd5ui2nD+lu8XQgUkOo0sK/wQsBv5SVQcC36C7aOODSbakuwhpZ7rTBP6nqqbqEaSqftW20ftaz8pxdL01d6Q7Pn24qr47NMuDgd/Vyvc0HF3mWMfEGbS4DX/eku48yCfQJdHfohuxmSmvo3vNfi/J++i+3G9Gl1Dctar+tWf+T9OuJm6v6VNbzHejS3CfOM0E9490vWt7JDkN+DNwdlWN9g4DUFWfSncnhXck2YHus+UPdMO6u9C99pZw4znGw75Ndx7jJ1rsC+l64H7D0Cl9fZ8VSd5I91n2XbqevzvQjUwsq6rVSRjH/jybbP4km7R2fpobz7fflW4fHz3ZfIOV+zcP/+i5Gq/V2ZGhq6eHyp9B92a5mu6N/Elg4UidDem6uC+m60H4Cjdepbj3SN0d6C7uuITuIL6Crgdnh6E6x7IaV0+3slsA/95i/wtwWXv8v3Tf2KC7HcYJrV1X0fUk7A+sP7Scv6cbBvpLW8f+q7OdW717tzaf37bruW2b7TxU5xDg3Enmv8nV0638nnTnq17W4j0B2KlvWw1Nu8kVwZO1qe2jHww9v3V7DVxAlwB8ja73ZqVtNtn6mfjKwq3oLpY4j6536bfAx4ENprMtp9gPP2bkCnDGvHJzdFuN2/5W9wF0twi5tL3ufkZ34J9w247M+2C6D4Ar6D5MjwG2n4ljwNC6a6K/abwf92rLGeyTs+m+BGw8Um+3tg+uovuS82PgCUPTN6a7snaw/39Od9uTDNXZkQmOW0PTn0n3Pvhz22Y/bcu8w0i9nwNvH7N94xwTVwCfmuR1M+kxZGRfDf6uorvQ5HC6pHH0ytjBa3bvobKxr55u5XeguzL9d21bn0eXnD6j773bpt2qTf9Z2y4X03Ug7M+Nd7WYcF8NtXfRUNkT6b6wXzPatim22850p11d0Ob7I93tgf5ptA0j8z21xf0Xui8nezByPKLns4IuOT2qbber6Y5VHwH+dmgZKy2zlfVePd3Kxvk8G7wOnjsy7wZ0ye0ZdO+By9u+mfIq/qq64XJ2SZr30t0w+D10H/gzNdSnm5k2dH48cO+aosdGmm9MGiWpaed8Lgc+WlVvn+14NDuSHA5cUv3DsNK84jmNktRUd47av9KdA6kxtER7qnu8XV8ze4HXGpXuF2BOofv1DklD7GmUJK2ydL9rPNWNxD9eVXuvnWgkrUkmjZKkVdauRN5oiioXVrvlk6SbN5NGTWiLLbaoRYsWzXYYkiRpBpx00kkXVtWWq7MMz2nUhBYtWsTSpWvrxwwkSdKalOSc1V2Gvz0tSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXuvNdgCam5b/7jIW7XfkbIchrbYVB+wy2yFI0jrBnkZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1mvWkMckVM7CMJUneO8X0RUmePm79CeY/NslZSU5NcmKSxasb80xJ8s9J9pvtOCRJ0rptvdkOYCZU1VJg6RRVFgFPBz4zZv2J7FlVS5M8G3gb8A+rEOpKkiyoqutWZxlV9RXgK6sbiyRJ0lRmvadxIkkWJzkhyWlJDk+yWSvfrpX9KMnbkpzeyndM8rX2+JFJlrW/U5JsBBwAPLyVvWyk/m2TfCzJ8rbsJ/eE9yNg6zbvbZJ8tPU+npJk11a+YZLPt+V9LsmPkyxp065I8sYkPwZ2SPKMJD9psX0oyYL2d0iS01tcL2vzviTJmW25n21leyd5X3t85yTHtOnHJLlTKz8kyXuTHJ/k10l2m8HdJUmS5oE5mTQCnwBeWVX3A5YDr2/lHwNeUFU7AJP10L0ceFFVLQYeDlwF7Ad8v6oWV9W7Rur/F3BZVW3b1vednth2Ao5oj18DfKeqtgMeBbwtyW2AFwKXtOW9CXjQ0Py3AU6vqgcDFwG7A3/f4r0O2BNYDGxdVfetqm1bu2nteEBb7gsmiO19wCfa9E8Dw0PwC4GHAU+gS6IlSZLGNueSxiSbAJtW1XGt6OPAI5JsCmxUVce38s9MsogfAu9M8pK2nGt7VvlY4P8GT6rqkknqfTrJucArgQNb2eOA/ZIsA44FbgXciS45+2xb3unAaUPLuQ44rD1+DF1CeWJbxmOAuwK/Bu6a5MAkOwGXt/qntTieAUzUrh24cbt8ssUxcERVXV9VZwK3n6iBSfZJsjTJ0uuuvGySzSBJkuajOZc0TiHjVKqqA4DnArcGTkhyrzGWW2Msek/gLnRJ2SDJDPDk1oO5uKruVFU/7Yn1L0PnMQb4+ND896yq/Vvien+6RPRFwIdb/V3auh8EnJSk75zU4XZdPfR4wviq6qCqWlJVSxZsuEnPoiVJ0nwy55LGqroMuCTJw1vRM4HjWiL1pyQPaeV7TDR/krtV1fKqeivdxS73Av4EbDTJKo8GXjw0/2ZTxHYN8FrgIUnuDRwF7Jskbd4HtKo/AJ7ayv4O2HaSRR4D7JZkq1Z383Ze4hbALarqMLrh8wcmuQVwx6r6LvAKYFPgtiPLO54bt8ueLQ5JkqTVNheunt6wDfsOvBPYC/hgkg3phmqf3aY9Bzg4yZ/peuEmGkN9aZJH0Q0Dnwl8A7geuDbJqcAhwClD9f8b+L92Uc11wBuAL00WbFVdleQddOdOvhh4N3BaSxxX0J0z+H7g40lOa+s6baJYq+rMJK8Fjm5J4TV0PYtXAR9rZQCvAhYAn2rD9wHeVVWXtnx14CXAR5P8J3DB0HaTJElaLakaZ2R2bkhy26q6oj3eD1hYVf8+y2HdRJIFwPpV9Zckd6PrUbxHVf11lkMb2wYLt6mFe717tsOQVtuKA3aZ7RAkadYlOamqlqzOMuZCT+N07JLkVXRxnwPsPbvhTGpD4LtJ1qfrFfy3m1PCKEmSNOpmlTRW1eeAz812HH2q6k/AamXzkiRJc8mcuxBGkiRJc49JoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ63ax+RlBrz7Zbb8LSA3aZ7TAkSdIcYU+jJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZc399aElv/uMhbtd+Rsh6EZtsIbtkuSVpE9jZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSeo1r5PGJK9JckaS05IsS/LgVv7hJH+3htf99SSbTlC+f5KXT1B+zyTHtjh/muSgJLdJclGSTUbqHpHkqUn2TlJJHjM07UmtbLc10zJJkrQumrdJY5IdgCcAD6yq+wGPBX4LUFXPraoz1+T6q2rnqrp0GrO8F3hXVS2uqnsDB1bVn4GjgScOKrUE8mHA11rRcuBpQ8vZAzh1tYKXJEnzzrxNGoGFwIVVdTVAVV1YVb8HaD16S9rj5yT5eSs7OMn7WvkhST6Q5LtJfp3kkUk+2noBDxmsJMnTkixPcnqStw6Vr0iyRXv8miRnJfk2cM8p4j138KSqlreHh9IlggNPAr5ZVVe2598Htk+yfpLbAncHlq3SFpMkSfPWfE4ajwbu2BLC9yd55GiFJH8L/BfwEOAfgHuNVNkMeDTwMuCrwLuA+wDbJlnc5n9rq7MY2C7JE4cXkORBdEnfA4B/AbabJN53Ad9J8o0kLxsa2v4m8KAkt2vP96BLJAcK+Dbwj8CuwFcm2yBJ9kmyNMnS6668bLJqkiRpHpq3SWNVXQE8CNgHuAD4XJK9R6ptDxxXVRdX1TXAF0amf7Wqim4I+I9VtbyqrgfOABbRJYDHVtUFVXUt8GngESPLeDhweFVdWVWXM0lSV1UfA+7dYtgROCHJBlX11zbPbq3ncjFdQjzss3TJ5GhCObqOg6pqSVUtWbDhJpNVkyRJ89C8TRoBquq6qjq2ql4PvBh48kiV9Czi6vb/+qHHg+frjTH/DaGMVanq91X10araFbgWuG+bNBii3g34cktwh+f7Sau7RVX9fMyYJEmSbjBvk8Z2NfI2Q0WLgXNGqv0EeGSSzZKsx02Tyj4/bvNvkWQB3QUpx43U+R7wpCS3TrIR8E+TxLtTkvXb478Bbgf8rk3+LrAN8CIm70l8FfDqacYvSZIEdL1h89VtgQPbuYHXAr+kG6q+QVX9Lslb6JK/3wNnAmOf7FdV5yV5FV1SF+DrVfXlkTonJ/kc3cUp59BduDKRxwHvSfKX9vw/q+oPbRnXJzkMeApdEjpRLN8YN25JkqRR6U7J02SS3Laqrmg9jYcDH62qw2c7rjVtg4Xb1MK93j3bYWiGrThgl9kOQZI0C5KcVFVLVmcZ83Z4ehr2T7IMOB04GzhiluORJEla6+bz8PRYquomv84iSZI039jTKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnq5c8IakLbbr0JSw/YZbbDkCRJc4Q9jZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqRe3txbE1r+u8tYtN+Rsx3GzdYKb4wuSVrH2NMoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNMyzJdUmWJTk9yVeTbNrKFyW5qk07NcnxSe7Zpu2Y5LI2bVmSb0+w3Nsn+Vqb98wkX2/lZw+WM11hszoAACAASURBVFT33Ule0ZZbSZ4zNO0Brezla3ZLSJKkdYlJ48y7qqoWV9V9gYuBFw1N+1Wbdn/g48Crh6Z9v01bXFWPnWC5bwS+VVX3r6q/A/Zr5Z8F9hhUSnILYDfgc61oObD70HL2AE5djfZJkqR5yKRxzfoRsPUk0zYGLpnGshYC5w6eVNVp7eGhDCWNwCOAFVV1Tnv+G+BWracywE7AN6axXkmSJNab7QDWVUkWAI8BPjJUfLcky4CNgA2BBw9Ne3ibBvCFqnrzyCL/D/hckhcD3wY+VlW/r6rTklyf5P5VdSpdAnnoyLxfBJ4CnAKcDFw9Scz7APsALNh4y+k1WJIkrdPsaZx5t27J30XA5sC3hqYNhqfvBrwUOGho2vDw9GjCSFUdBdwVOBi4F3BKkkFmdyiwR5L1gF2BL4zM/nm6pPFp3DShHF7HQVW1pKqWLNhwk2k0WZIkretMGmfeVVW1GLgzcEtWPqdx2FfohpLHVlUXV9VnquqZwIlD8x8KPBV4LHBaVZ0/Mt8fgGuAfwCOmc46JUmSwKRxjamqy4CXAC9Psv4EVR4G/Grc5SV5dJIN2+ONgLvRna9IVf2KrmfzACbvSXwd8Mqqum7sRkiSJDWe07gGVdUpSQbnGX6fG89pDPBX4LnTWNyDgPcluZYu2f9wVZ04NP1Q4H+AwyeJ5fhVaIIkSRIAqarZjkFz0AYLt6mFe717tsO42VpxwC6zHYIkSTdIclJVLVmdZTg8LUmSpF4mjZIkSepl0ihJkqReJo2SJEnqtVpJY5K7J7nVTAUjSZKkuWnspDHJW5Ls1R4nybeAnwPnJXnw1HNLkiTp5mw6PY17Ame1x48HFgMPAT5Bd1NpSZIkraOmc3Pv2wPntsc7A5+vqp8kuRhYOuORSZIkac6YTk/jRXS/pwzwOOA77fF6dL9wIkmSpHXUdHoaDwM+k+TnwObAN1v5YuCXMx2YJEmS5o7pJI3/Aayg6218RVX9uZUvBD4ww3FJkiRpDhnrt6eTrA+8Gfi/qjpnjUelWbdkyZJautRTVSVJWhestd+erqprgBfiuYuSJEnz0nQuhDkKePSaCkSSJElz13TOaTwGeEuS+wEnAX8enlhVX5rJwCRJkjR3TCdpfF/7/5IJphWwYPXDkSRJ0lw0dtJYVav1O9WSJEm6+TIRlCRJUq+xk8Z0XpjkjCRXJrlrK98vyVPXXIiSJEmabdPpafx34LXAQax8653fAS+eyaAkSZI0t0znQpgXAM+rqiOT/PdQ+cnAfWY2LM225b+7jEX7HTnbYayyFQfsMtshSJK0TplOT+OdgdMnKL8GuPXMhCNJkqS5aDpJ46+BB05QvjNw5syEI0mSpLloOsPTbwfel2RDunMad0jyTOAVwL+uieAkSZI0N0znPo0fS7Ie8BZgQ+CTdBfBvKSqPreG4pMkSdIcMJ2eRqrqYODgJFsAt6iq89dMWJIkSZpLppU0DlTVhTMdiCRJkuauKZPGJKcBj6yqS5Isp/uN6QlV1f1mOjhJkiTNDX09jYcBVw89njRplCRJ0rqrL2k8G7gOoKr2X+PRSJIkaU7qu0/jx4CNAZJcl2SrNR+SJEmS5pq+pPECYIf2ODg8LUmSNC/1DU9/EDgiSdEljH9IMmHFqloww7FJkiRpjpgyaayq/ZN8AdgG+BLwPODStRGYJEmS5o7e356uqjOq6gjgDcChVXXYRH9rPtTJtfMtlyU5PckX2k8dTlZ37yTvW5vxDa37jUke21PnkCS7TVD+kCQ/bu38aZL9kyxKcm6SW4zUXZZk+1anktx9aNrLWtmSmWuZJEla1/UmjQNV9YaqunJNBrMarqqqxVV1X+CvwAtmO6CJVNXrqurbqzj7x4F9qmoxcF/g81W1Avgt8PBBpST3Ajaqqp+0ouXAHkPL2Q04cxVjkCRJ89SUSWOS05Js1h4vb88n/Fs74Y7l+8Ddk2ye5IgW3wlJVrr5eJKNkpydZP32fOMkK5Ksn+TYJG9N8pMkP0/y8FbnVkk+1rbFKUke1cr3buv6alvmi5P8R6tzQpLNW70behGTvC7Jia139KBMdrLojbYCzgOoquuqapD4HcrKSeEerWzgCGDXts67ApfRXeAkSZI0tr6exuGbe3+xPZ/sb9YlWQ94PF3v2huAU9ov1bwa+MRw3ar6E3AssEsr2gM4rKquac/Xq6rtgZcCr29lL2rzbgs8Dfh4klu1afcFng5sD7wZuLKqHgD8CHjWBOG+r6q2a72jtwae0NO8dwFnJTk8yfOH1vt54Imt7QC7A58dmu9y4LdJ7tti/lzPeiRJkm6i70KYN0z0eA66dZJl7fH3gY8APwaeDFBV30lyuySbjMz3YeAVdL1xz6a70GfgS+3/ScCi9vhhwIFtmT9Lcg5wjzbtuy0R/VOSy4CvtvLlwEQ/sfioJK8ANgQ2B84YmucmquqNST4NPI4uOX0asGNV/SHJGcBjkvwRuKaqTh+Z/bN0SfE/Ao9pbb2JJPsA+wAs2HjLyUKRJEnzUN8td24wuNiiqq5vz/+GrnfszKo6fs2EN7ar2rl+N5hkuHel+0xW1Q/bxSSPBBaMJFuDHtbruHE7TTWEfPXQ4+uHnl/PyHZuvYTvB5ZU1W+T7A/cih5V9SvgA0kOBi5Icruquogbh6j/yMpD0wNfBd4GLK2qy6e4bdJBwEEAGyzcxntySpKkG4x9IQxwJLAvQJLbAkvpEpHjkkw0/DrbvgfsCZBkR+DCqrp8gnqfoEu0PjbNZd4DuBNw1irENkgQL2zb8iZXS49KsstQIrwNXTI7uP3RYcDO3HRoGoCqugp4Jd2wuSRJ0rRNJ2l8EPCd9vhf6M6V24puSPflMxzXTNgfWNIu0jkA2GuSep8GNmPiHrpR7wcWJFlOd27g3lV1dc88N1FVlwIH0w1dHwGcOMZsz6Q7p3EZ8Elgz6oa/C74pcAJwB+r6uxJ1vnZqjp5urFKkiQBpGq8UcgkVwH3aMOpnwLOqarXJLkT8NOqus2aDHRNaVcz71pVz5ztWOaSDRZuUwv3evdsh7HKVhywS38lSZLmiSQnVdVq3aN57HMagd8Af5/kq3QXVDyllW8OzNX7N04pyYF0V1vvPNuxSJIkzWXTSRrfSTcsegVwDt35fQCPoBtmvdmpqn1nOwZJkqSbg7GTxqr6UJKTgDsC3xpcRQ38CvivNRGcJEmS5obp9DRSVUvprpoGIMn6VXXkjEclSZKkOWXsq6eTvCTJk4eefwS4KslZSe65RqKTJEnSnDCdW+68hPabxUkeATyV7pdJlgHvmPnQJEmSNFdMZ3h6a2BFe/xPwBeq6vPtnoXfn+nAJEmSNHdMp6fxcmDwg8T/ABzTHl/DGD+BJ0mSpJuv6fQ0Hg0cnOQU4O7AN1r5fYAJf4VEkiRJ64bp9DS+CPghsAWwW1Vd3MofyHg/wSdJkqSbqencp/Fy4CY3w66q189oRJIkSZpzpnWfxoEkfwPccrisqn4zIxFJkiRpzhk7aUyyCfBeulvt3HKCKgtmKijNvm233oSlB+wy22FIkqQ5YjrnNL4duD/wROAvdPdo/E/gXGD3mQ9NkiRJc8V0hqcfDzytqr6f5DrgpKr6XJLzgOcDX1wjEUqSJGnWTaencVPgnPb4MuB27fGPgIfOZFCSJEmaW6aTNP4KuGt7/FNgjyQB/gW4eNK5JEmSdLM3naTxEOB+7fEBdEPSfwXeBrx1ZsOSJEnSXDKd+zS+a+jxd5LcC1gC/KKqlq+J4CRJkjQ3rNJ9GuGG+zJ6b0ZJkqR5YMqkMcl/jLugqnrn6ocjSZKkuShVNfnE5Owxl1NVddf+arq52GDhNrVwr3fPdhjSjFjhjeolzXNJTqqqJauzjCl7GqvqLquzcEmSJK0beq+eTvL4JCvazwiOTtukTXvcmglPkiRJc8E4t9zZF3hbVV02OqGVvRX495kOTJIkSXPHOEnjtsC3p5j+HbrfpJYkSdI6apykcUvg+immFzf+pKAkSZLWQeMkjedy4y/BTOR+wO9mJhxJkiTNReMkjUcCb0py69EJSTYE3tjqSJIkaR01zi/CvBnYDfhFkgOBn7XyewMvBgK8Zc2EJ0mSpLmgN2msqvOTPBT4AF1ymMEk4CjghVX1xzUXoiRJkmbbWL89XVXnADsn2Qy4O13i+IuqumRNBidJkqS5YaykcaAliSeuoVgkSZI0R41zIYwkSZLmOZNGSZIk9TJp7JHkignKXpDkWWs5jickOSXJqUnOTPL8JDsm+dFIvfWS/DHJwiSHJLkyyUZD09+TpJJssTbjlyRJN2/TOqdRnar64JpcfpIAqarr2/P1gYOA7avq3CQbAIuAXwB3SLKoqla02R8LnF5V53WL4ZfArsCnktwCeBTejF2SJE2TPY2rIMn+SV7eHh+b5K1JfpLk50ke3soXJHlbkhOTnJbk+a38tkmOSXJykuVJdm3li5L8NMn7gZOBOw6tciO6BP8igKq6uqrOaknlF4Ddh+ruARw69PzQoek7Aj8Erp3RDSJJktZ5Jo0zY72q2h54KfD6VvYc4LKq2g7YDnhekrsAfwGeVFUPpOv1e0frWQS4J/CJqnpAu80RAFV1MfAV4JwkhybZs/UaQpcU7gHQeiB3Bg4biu0XwJbtdklPAz47WSOS7JNkaZKl11152apvDUmStM4xaZwZX2r/T6IbNgZ4HPCsJMuAHwO3A7ah/YJOktOAbwNbA7dv85xTVSdMtIKqei7wGOAnwMuBj7byE4HbJrkn8HjghAnun/klusTywcD3J2tEVR1UVUuqasmCDTcZs+mSJGk+8JzGmXF1+38dN27TAPtW1VHDFZPsDWwJPKiqrkmyArhVm/znqVZSVcuB5Uk+CZwN7N0mfZYuKbw3Kw9NMzT9ZODjVXX9jR2bkiRJ47Gncc05Cvi3dhELSe6R5DbAJsD5LWF8FHDnvgW18yB3HCpaDJwz9PxQ4BnAo+mGsVdSVb8BXgO8fxXbIkmS5jl7GvttmOTcoefvHHO+D9MNVZ/czlm8AHgi8Gngq0mWAsuAn42xrACvSPIh4Cq6Hsm9BxOr6swkVwInVdWEvZVV9aEx45YkSbqJVNVsx6A5aIOF29TCvd4922FIM2LFAbvMdgiSNKuSnFRVS1ZnGQ5PS5IkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSeq032wFobtp2601YesAusx2GJEmaI+xplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi/v06gJLf/dZSza78jZDkOSpHlhxc3g3sj2NEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKnXvE0ak1yXZFmSM5KcmuQ/kqzS9kjyxiSPnWL6C5I8a9WjhSTbtniXJbk4ydnt8bdXZ7mSJEnjWG+2A5hFV1XVYoAkWwGfATYBXj/dBVXV63qmf3CVIlx5GcuBQbyHAF+rqi8O10myXlVdu7rrkiRJGjVvexqHVdX5wD7Ai9NZkORtSU5MclqS5w/qJnlFkuWtd/KAVnZIkt3a4wOSnNnme3sr2z/Jy9vjxUlOaNMPT7JZKz82yVuT/CTJz5M8fJzY23xvSXIc8O9JHpTkuCQnJTkqycJW725JvtnKv5/kXjO4CSVJ0jpuPvc0rqSqft2Gp7cCdgUuq6rtkmwA/DDJ0cC9gCcCD66qK5NsPryM9vxJwL2qqpJsOsGqPgHsW1XHJXkjXc/mS9u09apq+yQ7t/JJh7xHbFpVj0yyPnAcsGtVXZBkd+DNwL8CBwEvqKpfJHkw8H7g0WMuX5IkzXMmjStL+/844H6D3kO6Yett6JK4j1XVlQBVdfHI/JcDfwE+nORI4GsrLTzZhC7BO64VfRz4wlCVL7X/JwGLphH359r/ewL3Bb6VBGABcF6S2wIPBb7QygE2GF1Ikn3oelxZsPGW01i9JEla15k0NknuClwHnE+XPO5bVUeN1NkJqMmWUVXXJtkeeAywB/Biptebd3X7fx3T2zd/HoQInFFVOwxPTLIxcOngHM7JVNVBdD2SbLBwm0nbKUmS5h/PaQSSbAl8EHhfVRVwFPBvbbiXJPdIchvgaOBfk2zYykeHp28LbFJVX6cbcl4pSauqy4BLhs5XfCbdcPJMOQvYMskOLZ71k9ynqi4Hzk7ylFaeJPefwfVKkqR13Hzuabx1kmXA+sC1wCeBd7ZpH6YbHj453XjuBcATq+qbSRYDS5P8Ffg68OqhZW4EfDnJreh6/V42wXr3Aj7YEs9fA8+eqQZV1V/bkPp721D4esC7gTOAPYEPJHlta/NngVNnat2SJGndlq5jTVrZBgu3qYV7vXu2w5AkaV5YccAua3T5SU6qqiWrswyHpyVJktTLpFGSJEm9TBolSZLUy6RRkiRJvUwaJUmS1MukUZIkSb1MGiVJktTLpFGSJEm9TBolSZLUy6RRkiRJvUwaJUmS1MukUZIkSb3Wm+0ANDdtu/UmLF3DP54uSZJuPuxplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPXy5t6a0PLfXcai/Y6c7TCkm5UV3hBf0jrMnkZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1WmtJY5Irhh7vnOQXSe40UmdFksOGnu+W5JC1FeNILK+eYtq040yyJMl7e+osSnL6JNOOTbKkJ2xJkqQ1Yq33NCZ5DHAgsFNV/WaCKkuS3GeG17lgFWabNGlsphVnVS2tqpesQhyrLcl6s7FeSZK07lirSWOShwMHA7tU1a8mqfZ2JkjYktwmyUeTnJjklCS7tvJFSb6f5OT299BWvmOS7yb5DLA8yYIkb2vzn5bk+a3ewiTfS7IsyelJHp7kAODWrezTMxTnjkm+1h5vmeRbLd4PJTknyRZtEQuSHJzkjCRHJ7n10OKfkeT4Fuf2bVmbJzmitemEJPdr5fsnOSjJ0cAnktwnyU9am05Lss2kO0qSJGnE2kwaNwC+DDyxqn42Rb3PAw9McveR8tcA36mq7YBHAW9LchvgfOAfquqBwO7A8BDw9sBrqurvgOcAl7X5twOel+QuwNOBo6pqMXB/YFlV7QdcVVWLq2rPGYpz2OtbnQcChwPDw/TbAP9XVfcBLgWePDTtNlX1UOCFwEdb2RuAU6rqfnRJ7CeG6j8I2LWqng68AHhPa+cS4NzRBiXZJ8nSJEuvu/KySZotSZLmo7WZNF4DHE+XvE3lOuBtwKtGyh8H7JdkGXAscCu6ZGt94OAky4EvAH83NM9Pqursofmf1eb/MXA7ugTtRODZSfYHtq2qP43ZnunGOexhwGcBquqbwCVD086uqmXt8UnAoqFph7Z5vgdsnGTTtqxPtvLvALdLskmr/5Wquqo9/hHw6iSvBO48VH6DqjqoqpZU1ZIFG24yOlmSJM1jazNpvB54KrBdkle34eJl7e+NI3U/CTyClZOtAE9uvX+Lq+pOVfVT4GXAH+l6CZcAtxya588j8+87NP9dquroloA9Avgd8Mkkz5pGm6YTJyN1JnP10OPrgOHzEWukbk2yrEG9G9pfVZ8B/hm4CjgqyaOniEGSJGkla/Wcxqq6EngCsCew91Bi9bqRetcA7wJeOlR8FLBvkgAkeUAr3wQ4r6quB54JTHbRy1HAvyVZv81/j3b+4Z2B86vqYOAjwANb/WsGdadoz3TiHPYDugSaJI8DNptqPUN2b/M8jG6o/TLge3TbkyQ7AhdW1eWjMya5K/Drqnov8BXgfmOuU5Ikae1fPV1VFwM7Aa8dXCQyiY+wci/bm+iGok9rt6V5Uyt/P7BXkhOAe7By7+KwDwNnAie3+T/Ulr8jsCzJKXTnD76n1T+orWuyC2GmG+ewNwCPS3Iy8HjgPGCcYfFLkhwPfJAbh/n3p7uS+zTgAGCvSebdHTi9DZvfi5XPfZQkSZpSqkZHPLWmJdkAuK6qrk2yA/CBdoHKnLHBwm1q4V7vnu0wpJuVFQfsMtshSNKEkpxUVat1v2fv3zc77gR8PsktgL8Cz5vleCRJkqZk0jgLquoXwETnOkqSJM1J/va0JEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXPyOoCW279SYsPWCX2Q5DkiTNEfY0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqlqmY7Bs1BSf4EnDXbccyCLYALZzuIWWC755f52O752Gaw3fPNVO2+c1VtuToLX291ZtY67ayqWjLbQaxtSZba7vnDds8f87HNYLtnO461bU232+FpSZIk9TJplCRJUi+TRk3moNkOYJbY7vnFds8f87HNYLvnmzXabi+EkSRJUi97GiVJktTLpHGeS7JTkrOS/DLJfhNMT5L3tumnJXngbMQ508Zo972S/CjJ1UlePhsxrgljtHvPtp9PS3J8kvvPRpwzaYw279rauyzJ0iQPm404Z1pfu4fqbZfkuiS7rc341pQx9veOSS5r+3tZktfNRpwzbZz93dq+LMkZSY5b2zGuCWPs7/8c2tent9f65rMR60wao92bJPlqklPb/n72jKy4qvybp3/AAuBXwF2BWwKnAn83Umdn4BtAgIcAP57tuNdSu7cCtgPeDLx8tmNei+1+KLBZe/z4m/v+HrPNt+XGU3XuB/xstuNeG+0eqvcd4OvAbrMd91ra3zsCX5vtWGeh3ZsCZwJ3as+3mu2410a7R+r/E/Cd2Y57Le3vVwNvbY+3BC4Gbrm667ancX7bHvhlVf26qv4KfBbYdaTOrsAnqnMCsGmShWs70BnW2+6qOr+qTgSumY0A15Bx2n18VV3Snp4A3GEtxzjTxmnzFdWOrMBtgHXhRO9x3tsA+wKHAeevzeDWoHHbva4Zp91PB75UVb+B7hi3lmNcE6a7v58GHLpWIluzxml3ARslCd0X44uBa1d3xSaN89vWwG+Hnp/byqZb5+ZmXWzTOKbb7ufQ9TLfnI3V5v/f3rnHW1Vcd/z7Q+ATo9HaUquSIERQkKighNhGHvURH+hHiCRKfBNLfFaltKYmMVatUSGJDzQmQSRRQ60WETGaGBSN1kcUFBVSQhQVsEax8gY1rP6x5jTb3fPYl8O5l3tY389nf+45M7PXrDUz5+511syckTRC0m+B+4HRraRbI6lpt6SuwAjg5lbUq9EUHeN/nabtHpDUt3VUayhF7N4T2EnSbEnPSTql1bRrHIX/p0n6OHAE/iWpvVPE7olAH2AZ8CJwvpltrLfiOBFm60Zl0vJRliJl2hvNaFMRCtst6W9xp7G9r+8rZLOZ3QPcI2kwcDlwaKMVazBF7L4WuMjM/ujBiKagiN1z8OPUVks6CpgO9Gq4Zo2liN0dgQOAQ4BtgSclPWVmCxutXANpyf/yY4AnzOzdBurTWhSx+3DgeeBgYA/gIUm/NrOV9VQckcatmyXApzLvP4l/K2lpmfZGM9pUhEJ2S9oXmAQca2bLW0m3RtGivjazx4A9JHVptGINpojdA4B/k7QYGAncJGl466jXMGrabWYrzWx1ev1zoNNW0t9LgAfNbI2ZvQM8BrT3jW4t+XyfQHNMTUMxu0/HlyOYmS0CXgV611txOI1bN78BeknqIakz/qGakSszAzgl7aI+EFhhZm+2tqKbmSJ2NyM17ZbUDZgGnNzOIxAlitjcM637If06QGegvTvLNe02sx5m1t3MugN3A2eb2fTWV3WzUqS/d8n090D8Odj0/Q3cCwyS1DFN1X4OWNDKem5uCv0vl7QjMARvg2agiN2v41FlJP0VsBfwSr0Vx/T0VoyZfSjpXOAX+G6syWb2sqQzU/7N+K7Ko4BFwFr820u7pojdknYBngV2ADZKugDfnVZXaL8tKdjflwB/gUedAD40swFtpXO9FLT5OPyL0QfAOuD4zMaYdklBu5uOgnaPBM6S9CHe3ydsDf1tZgskPQjMAzYCk8zspbbTun5aMM5HAL80szVtpOpmpaDdlwNTJL2IT2dflCLMdREnwgRBEARBEAQ1ienpIAiCIAiCoCbhNAZBEARBEAQ1CacxCIIgCIIgqEk4jUEQBEEQBEFNwmkMgiAIgiAIahJOYxAEQRAEQVCTcBqDIKiJpC6STNLQFtxzqaR2/Ttw9SBpjKTXJW2UdGlb67MlIamTpIXp2MagHSLpbklj21qPoHUJpzEI2jmSpiSHblKZvGtS3sy20K0Skk5LelW7htYhf7GkcQXKzc7UtyE5MhdL2mZT605ydwJuBMYDXYEJ9chrQsYAS9OxjQBk+uEj551L2kbSspQ3stU1rYGk7hXG7/RMmeskPStpvfzYxmbgX4BvptNWgq2EcBqDoDl4Azhe0nalBEkdgZPx46S2NO4Eds1cvwL+PZf2n62ky62pvr2A64ErgJoOZyUkdQJ2x0/cmmlmb5bOOt4EWZ03VY8tnPOAW8qkvwF8NZd2JPBhoxXaDG19BB8dv6dl8joAPwF+WmcdDadoO5jZi/ixdCc1VqNgSyKcxiBoDuYBvwO+nEkbBqwHZmcLSuog6VuS3kjRtRclHZsr81lJz6XIyFz8nFpyZfaWdL+kVZL+IGlqOn6xJma2zsz+u3QBKzIVnAAACaJJREFUG4B1mffvApdLWiJpjaTfSDo8U3cnSdenCNSGZMtVKW827rSNL0V9aqizNtW72MwmArOA4UlWZ0lXV9FjaKrjKEnPSHof+BowNxV5JeV3T+W/JmmRpPfT37/LtalJOkfSNElrgCtL0/ySTk0R1NWSbk26nZ1sXy7pe5I6ZGSdlPQt9c9dkrqW0f0QSU9LWpuiYfvndDpQ0sPJ/hWSZknaLeVJ0j9J+r2kdWksVXUiJA0A9gTKRb+nAF+StH0m7au4Y5+XM1bSvKTXUkmTJP1ZC3SfLekHkiZIeht4IqUPTu2xXtJbkr5f0JFanh3TZvZeKcPMzjOzG4AWn+cuaUdJt6U+XC/pFfmxpqX8HZIdb6b8BZKOz+R/MfVL6XPyDcnPCE35i9MYmyzpPeCOlP43kh5N42JpqmOHnHozgFEttSlov4TTGATNwy3A6Mz70fjDNu80nQ/8I3ARsA9wDzBNUj8AebTyfjyKMAD4OrnpVUm7Ao8BLwEDgUOB7YEZWcelDm4FhgBfSTr+BLhP0n4p/+/x82RPAHoBxwP/lfK+CCwBLuNPUZ+WsA7oVFCPElcD3wR6A/fiUSfwttkVeEPSCGAicC3wGeA6/IzvY3Kyvo2f+b4PPsUN0B04FjgaPyv7S6mezwJfAM7Ao3cjMnI6J1n7pfu6AFPL2PsdvI/3B5YDd5ScimTnI/jZ858HDsQjwh3TvVfgTt05wN5J1g8lDStTT4lBwKKsU5VhHrAA708k7QwcRRmnET8/+QKgL94/A4EbSpkFdAePkinpdEpyqh/Anf7+ybZRya624gp8LByNj6/RwFJwpx3XdwhwOt4HY4H3U/4BwF3AtCTj68A/A+fm6hgL/Bb/vF8saR/gl7hTuB/+meoHTM7d9wwwUNK2m83aYMvGzOKKK652fOHRmZnATrjD0wvYBY/edSvlZ8ovBS7JyZgN3J5ejwHeA7bP5J+EO59D0/vLgFk5GTulMgPT+0uBlwraMBOYkl7vgTsE3XJlpgM3pdfX4xFBVZC3GBhXoN7ZwMT0ugPu7G3AncAiegxNNh+XKzMgpXfPpD0BTC7Td49n3htwQ67Mpalfd8yk3Q28DXQuZ0sFW3sn+Z/M6X54psznc2XuAJ6qIG+7pNegXPq1wM+r6HEt8GiZdANGAmcBT6S0ccCvsvlV5Jb6rkMt3TPtNS+X9q+4k9khk3ZakvvxCnK6J93WAqsz16AyZccBi4t8JjL3zABurZB3WBqjfSrk3wE8XGY8Lcl9Vu7LlfkpcEsurV+yc+dM2r4pbY+W2BRX+70i0hgETYKZ/Q8eNRwNnArMNrOPrGdM00u7kabiMjyORykA+uAP0+w6vCdz5Q8ABqep0tWSVuPr0cCdrXrYH4/+zM/JH5aRPQV/iC2UdKOkYXVEOMck+evxB/Tt+CL/InqUeLZAPX2o3u7VZL1uZisy798CFprZ+7m0nUtvJO0v6V5Jr0lalZHbLSd7Xub1svS3JKc/7pyXY2/gY8CDufY5i+pjYFu8rSvxM6C/pL3wsVxu7SOSDpb0kHzpwCo8mtYZ/8JUS/cSz+Xe9wGeNLONmbTHk9yeNWR9BR+TpavImCjCD4AvS3ohTaUPyeT1B940swUV7q005rrmpprzuh4AnJTr15KcbN+uS38j0riV0LF2kSAI2hGT8SnU1cAlVcqVW+dXSlOZvDwd8CnschtG3ipwfy3Zhk+9fpDLWwdgZnPk6wSPAA7GbX5B0mG5B34R7sSdxA3AMjP7I/jaz1p6ZFhTsK5q7V5NVr5+q5C2DfzfEoNf4BuMTgb+gE9P/xp3gCrJLulScsCrjYVSmWP4/5ut8rpleQd3dspiZiskTQNuxqf278mXkbQ7Pv5+jI/z5biTP5U/2VdkHOfbWpTvI6qkl1hiZosK1NkizOyBZO+RwCHA/ZLuMrPTqW1jUXvy7dABmAR8v8x9SzOv/zz9fbuGHkGTEE5jEDQXs/D1TF3wadSPYGYrJS0DDgIezmQdBMxPr+cDp0razsxKD5MDc6Lm4JtuXjOzag7CpjAXf9jtYmaPVCpkZqvw9Vp3SZoCPIVHgxbibVD0Z3NWVHjYF9KjBSzA2zm7Lizb7puT3vgYuNjMXgXfELEJcubgTnk55uOO9u5m9nCFMuWYC5wrqUMVB/8WfHzeaGblopIDcOfwwoyTf3QLdK/EfDyql9XtIHw8/b6FsjYbZvYOcBtwm6QHgKmSzsRt3FVSnwrRxvm4/lkOwh3cVVWqnAP0LeAEfwb/olXvF8WgnRDT00HQRJiZ4euMepjZhgrFxgPjJI2StKeky/CNAN9N+T/Df+JksqS+kg4DvpGTcSOwI3CnpM9J+rSkQyX9SNIn6rRhIb4Wa4qkkUn2AEnjSo6PfOfsKEl9JPXEpwZX4htgwNdpDZLUVVKXRunRQsYDJ8t3R/eSdB5wInDNpuhXg9dxh+7cpPcw4PJNkDMenyr+kaT9JO0l6QxJ3ZLTMQGYIGm0pJ6S+kk6U9KYKjIfwae1961UIDnpfwn8Q4Uiv8OfXxdI6iFpFL4pppDuVXS7CV++cVMaW8OAq/C1omur3FeVUtsk2Z1TO/VTgV3Zki6TNDyNmT74ppRX0ud7FvA08B+SDk9tcZik4en27wJD5Luj95R0It6mtcbc1fgGl5sl9U/6Hy3ph7lyg4AHCzdE0O4JpzEImgwzW2VmK6sUuR5/oF6D734egW/keD7dvxrfqdkLjzhMwHdaZ+tYhm+a2Ig/NF7GHckN6aqX0/Eds9fguzpnAoOB11L+KnwH+DNJx37AkZkH+yXAp/DoUD1TZ7X0KIyZTcd3OF+IR4DOB842s/vq0K9SXW/j61qHp7q+je+Qbamc5/Gd8b3xSO7T+I71UnT5W/jGinH4GHgI3939ahWZy/H1hyfWqPudSl98zGwe3n5jcfvOILdUooDu5eQuxaeB+wPP41HhqcDF1XQtwCQ8wnohPuU+N127Fbh3A75B5wV8XeEn8CUBpGjokSn9djyafR1pit7M5uA77Y/DP+tXpWtitQpT+w7GN/k8mur+DpmlJ5I+hv/v+HEBG4ImQR6YCIIgCILWQVJfPOLYs8YXnGALRdI5wLFm9oW21iVoPSLSGARBELQqZvYyHhns0da6BJvMB3jkPNiKiEhjEARBELQRaWPLoArZV5rZla2pTxBUI5zGIAiCIGgj5KfQVPqdw3fN7N3W1CcIqhFOYxAEQRAEQVCTWNMYBEEQBEEQ1CScxiAIgiAIgqAm4TQGQRAEQRAENQmnMQiCIAiCIKjJ/wLDnuarS7C+4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "feature_train = x_train\n",
    "feature_test = x_test\n",
    "# feature_train = scaled_x_train\n",
    "# feature_test = scaled_x_test\n",
    "\n",
    "\n",
    "# Generating results\n",
    "# ---\n",
    "# Iterate through all classifiers\n",
    "for clf in dict_clf_default:\n",
    "#     print(\"- {}\".format(clf))\n",
    "#     estimator = dict_clf_default[clf]\n",
    "    \n",
    "    estimator = { clf: dict_clf_default[clf] }\n",
    "    try:\n",
    "#         score = test_model(estimator, feature_train, feature_test, y_train, y_test,\n",
    "#                       score=score_param, average=average_param)\n",
    "\n",
    "        score = train_and_evaluate(estimator, feature_train, feature_test, y_train, y_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "#     list_score.append(score[clf])\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "\n",
    "    \n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file\n",
    "# df_performance.to_csv(r'final_project_performance_default.csv', index = False, header = True)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# ---\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"{} on Different Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save plot into PNG (optional) \n",
    "# plt.savefig(\"final_project_performance_default.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'f1_macro': 0.3328694504027031}, {'f1_macro': 0.7732013528151364}, {'f1_macro': 0.10192419135739424}, {'f1_macro': 0.28897637795275594}, {'f1_macro': 0.2890112772095463}, {'f1_macro': 0.2890112772095463}, {'f1_macro': 0.2890112772095463}]\n"
     ]
    }
   ],
   "source": [
    "print(list_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bagging\n",
    "\n",
    "Recall the definition of `dict_clf_default` from the [earlier section](#3.0-Default-Classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - K-Nearest Neighbors\n",
      "Index: 1 - Decision Tree\n",
      "Index: 2 - Gaussian Naive Bayes\n",
      "Index: 3 - Bernoulli Naive Bayes\n",
      "Index: 4 - Multinomial Naive Bayes\n",
      "Index: 5 - Linear SVM\n",
      "Index: 6 - Polynomial SVM\n",
      "Index: 7 - RBF SVM\n",
      "Index: 8 - Sigmoid SVM\n",
      "Index: 9 - Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "_ = [print(\"Index: {} - {}\".format(i, clf)) for i, clf in enumerate(dict_clf_default.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `clf_index` from 0 - 9 as a base classifier in bagging approach, each corresponding to the classifier defined in `dict_clf_default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Bagging - Decision Tree) = 0.8152\n",
      "f1_macro (Test Bagging - Decision Tree) = 0.8090\n",
      "[[1075    2   25]\n",
      " [   4  182    3]\n",
      " [  88    1   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1102\n",
      "           1       0.98      0.96      0.97       189\n",
      "           2       0.68      0.40      0.51       149\n",
      "\n",
      "    accuracy                           0.91      1440\n",
      "   macro avg       0.86      0.78      0.81      1440\n",
      "weighted avg       0.90      0.91      0.91      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bagging - Decision Tree': {'f1_macro': 0.8090483781836065}}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify classifier\n",
    "clf_index = 1\n",
    "\n",
    "base = list(dict_clf_default.values())[clf_index]\n",
    "bagging_param = dict(base_estimator=base,\n",
    "                     n_estimators=100,\n",
    "                     random_state=0)\n",
    "\n",
    "model_bagging = BaggingClassifier(**bagging_param)\n",
    "\n",
    "estimator_name = \"Bagging - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_bagging}\n",
    "\n",
    "# # Print classifier name\n",
    "# print(\"{}\\n===\".format(estimator_name))\n",
    "\n",
    "# # Test using features with original Scale\n",
    "# print(\"Original scale\\n---\")\n",
    "# _ = test_model(model_bagging, x_train, x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "# # Test using features with standardized scale\n",
    "# print(\"\\nStandardized scale\\n---\")\n",
    "# _ = test_model(model_bagging, scaled_x_train, scaled_x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest** is another ensemble learning method. You can think of random forest as a collection of smaller (but different) trees (same machine learning algorithms) so it is included in the comparison with other *bagging* methods by specifying different base classifiers.\n",
    "\n",
    "However, note that there are still some differences between *bagging* method and a *random forest* method. Click [here](https://stats.stackexchange.com/a/364453) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Random Forest) = 0.8106\n",
      "f1_macro (Test Random Forest) = 0.8103\n",
      "[[1078    1   23]\n",
      " [   4  182    3]\n",
      " [  90    0   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1102\n",
      "           1       0.99      0.96      0.98       189\n",
      "           2       0.69      0.40      0.50       149\n",
      "\n",
      "    accuracy                           0.92      1440\n",
      "   macro avg       0.87      0.78      0.81      1440\n",
      "weighted avg       0.91      0.92      0.91      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Random Forest': {'f1_macro': 0.8102923956188063}}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify classifier - Random Forest\n",
    "random_forest_param = dict(\n",
    "                     n_estimators=100,\n",
    "                     random_state=0)\n",
    "\n",
    "rf_clf = RandomForestClassifier(**random_forest_param)\n",
    "\n",
    "estimator = {\"Random Forest\": rf_clf}\n",
    "\n",
    "# # Print classifier name\n",
    "# # print(\"{}\\n===\".format(estimator_name))\n",
    "# print(\"Random Forest Classifier\\n===\")\n",
    "\n",
    "# # Test using features with original Scale\n",
    "# print(\"Original scale\\n---\")\n",
    "# test_model(rf_clf, x_train, x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "# # Test using features with standardized scale\n",
    "# print(\"\\nStandardized scale\\n---\")\n",
    "# test_model(rf_clf, scaled_x_train, scaled_x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation K-Nearest Neighbors) = 0.3358\n",
      "f1_macro (Test K-Nearest Neighbors) = 0.3292\n",
      "[[1059   34    9]\n",
      " [ 176   10    3]\n",
      " [ 139    6    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.20      0.05      0.08       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.41      0.35      0.33      1440\n",
      "weighted avg       0.64      0.75      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.8152\n",
      "f1_macro (Test Decision Tree) = 0.8090\n",
      "[[1075    2   25]\n",
      " [   4  182    3]\n",
      " [  88    1   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1102\n",
      "           1       0.98      0.96      0.97       189\n",
      "           2       0.68      0.40      0.51       149\n",
      "\n",
      "    accuracy                           0.91      1440\n",
      "   macro avg       0.86      0.78      0.81      1440\n",
      "weighted avg       0.90      0.91      0.91      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Linear SVM) = 0.2703\n",
      "f1_macro (Test Linear SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Polynomial SVM) = 0.1860\n",
      "f1_macro (Test Polynomial SVM) = 0.0770\n",
      "[[   0 1102    0]\n",
      " [   1  188    0]\n",
      " [   0  149    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1102\n",
      "           1       0.13      0.99      0.23       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.13      1440\n",
      "   macro avg       0.04      0.33      0.08      1440\n",
      "weighted avg       0.02      0.13      0.03      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation RBF SVM) = 0.2881\n",
      "f1_macro (Test RBF SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Sigmoid SVM) = 0.2709\n",
      "f1_macro (Test Sigmoid SVM) = 0.2639\n",
      "[[566   0 536]\n",
      " [ 97   0  92]\n",
      " [ 74   0  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.51      0.62      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.11      0.50      0.18       149\n",
      "\n",
      "    accuracy                           0.45      1440\n",
      "   macro avg       0.29      0.34      0.26      1440\n",
      "weighted avg       0.60      0.45      0.49      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Logistic Regression) = 0.2881\n",
      "f1_macro (Test Logistic Regression) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Random Forest*) = 0.8106\n",
      "f1_macro (Test Random Forest*) = 0.8103\n",
      "[[1078    1   23]\n",
      " [   4  182    3]\n",
      " [  90    0   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1102\n",
      "           1       0.99      0.96      0.98       189\n",
      "           2       0.69      0.40      0.50       149\n",
      "\n",
      "    accuracy                           0.92      1440\n",
      "   macro avg       0.87      0.78      0.81      1440\n",
      "weighted avg       0.91      0.92      0.91      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "feature_train = x_train\n",
    "feature_test = x_test\n",
    "# feature_train = scaled_x_train\n",
    "# feature_test = scaled_x_test\n",
    "\n",
    "bagging_param = dict(n_estimators=100, random_state=0)\n",
    "\n",
    "# Loop through all classifiers\n",
    "for i, clf in enumerate(dict_clf_default):\n",
    "#     print(\"- {}\".format(clf))\n",
    "    base = dict_clf_default[clf]\n",
    "    \n",
    "    params = bagging_param.copy()\n",
    "    params[\"base_estimator\"] = base\n",
    "\n",
    "    model_bagging = BaggingClassifier(**params)\n",
    "    \n",
    "    estimator = { clf: model_bagging }\n",
    "    \n",
    "    try:\n",
    "#         score = test_model(model_bagging, feature_train, feature_test, y_train, y_test, \n",
    "#                            score=score_param, average=average_param)\n",
    "        \n",
    "        score = train_and_evaluate(estimator, feature_train, feature_test, y_train, y_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "#     list_score.append(score[\"score\"])\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "\n",
    "# (Bonus) Random Forest classifier\n",
    "model_rf = RandomForestClassifier(**bagging_param)\n",
    "\n",
    "name_rf = \"Random Forest*\"\n",
    "# print(\"- {}\".format(name_rf))\n",
    "\n",
    "# score_rf = test_model(model_rf, feature_train, feature_test, y_train, y_test,\n",
    "#                       score=score_param, average=average_param)\n",
    "\n",
    "estimator = { name_rf: model_rf }\n",
    "\n",
    "score_rf = train_and_evaluate(estimator, feature_train, feature_test, y_train, y_test)\n",
    "\n",
    "list_clf.append(name_rf)\n",
    "# list_score.append(score_rf[\"score\"])\n",
    "list_score = list_score + list(score_rf[name_rf].values())\n",
    "\n",
    "# Create data frame\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file\n",
    "# df_performance.to_csv(r'final_project_performance_bagging.csv', index = False, header = True)\n",
    "\n",
    "# Plotting for comparison\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"Bagging: {} on Different Base Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Base Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save plot into PNG (optional) \n",
    "# plt.savefig(\"final_project_performance_bagging.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Boosting\n",
    "\n",
    "Recall the definition of `dict_clf_default` from the [earlier section](#3.0-Default-Classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - K-Nearest Neighbors\n",
      "Index: 1 - Decision Tree\n",
      "Index: 2 - Linear SVM\n",
      "Index: 3 - Polynomial SVM\n",
      "Index: 4 - RBF SVM\n",
      "Index: 5 - Sigmoid SVM\n",
      "Index: 6 - Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "_ = [print(\"Index: {} - {}\".format(i, clf)) for i, clf in enumerate(dict_clf_default)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `clf_index` from 0 - 9 as a base classifier in AdaBoost approach, each corresponding to the classifier defined in `dict_clf_default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Boosting - Decision Tree) = 0.7783\n",
      "f1_macro (Test Boosting - Decision Tree) = 0.7786\n",
      "[[1035   18   49]\n",
      " [   4  180    5]\n",
      " [  79    5   65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1102\n",
      "           1       0.89      0.95      0.92       189\n",
      "           2       0.55      0.44      0.49       149\n",
      "\n",
      "    accuracy                           0.89      1440\n",
      "   macro avg       0.79      0.78      0.78      1440\n",
      "weighted avg       0.88      0.89      0.88      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Boosting - Decision Tree': {'f1_macro': 0.7786248020789598}}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify one classifier\n",
    "clf_index = 1\n",
    "\n",
    "# estimator_name = list(dict_clf_default.keys())[clf_index]\n",
    "# estimator = list(dict_clf_default.values())[clf_index]\n",
    "base = list(dict_clf_default.values())[clf_index]\n",
    "\n",
    "boosting_param = dict(base_estimator=base,\n",
    "                     n_estimators=100,\n",
    "                     random_state=0)\n",
    "\n",
    "model_boosting = AdaBoostClassifier(**boosting_param)\n",
    "\n",
    "estimator_name = \"Boosting - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_boosting}\n",
    "\n",
    "# # Print classifier name\n",
    "# print(\"{}\\n===\".format(estimator_name))\n",
    "\n",
    "# # Test using features with original Scale\n",
    "# print(\"Original scale\\n---\")\n",
    "# test_model(model_boosting, x_train, x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "# # Test using features with standardized scale\n",
    "# print(\"\\nStandardized scale\\n---\")\n",
    "# test_model(model_boosting, scaled_x_train, scaled_x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides `AdaBoostClassifier`, there is also another boosting algorithms available in the `sklearn` library, which is  `GradientBoostingClassifier`.\n",
    "\n",
    "For a **Gradient Boost** method, a base estimator is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Gradient Boosting) = 0.8172\n",
      "f1_macro (Test Gradient Boosting) = 0.8102\n",
      "[[1072    0   30]\n",
      " [   5  181    3]\n",
      " [  86    1   62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1102\n",
      "           1       0.99      0.96      0.98       189\n",
      "           2       0.65      0.42      0.51       149\n",
      "\n",
      "    accuracy                           0.91      1440\n",
      "   macro avg       0.86      0.78      0.81      1440\n",
      "weighted avg       0.90      0.91      0.91      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Gradient Boosting': {'f1_macro': 0.8101721092165249}}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify classifier - Gradient Boosting Classifier\n",
    "gradient_boosting_param = dict(n_estimators=100, random_state=0)\n",
    "\n",
    "model_boosting = GradientBoostingClassifier(**gradient_boosting_param)\n",
    "\n",
    "estimator = {\"Gradient Boosting\": model_boosting}\n",
    "\n",
    "# # Print classifier name\n",
    "# print(\"Gradient Boosting\\n===\")\n",
    "\n",
    "# # Test using features with original Scale\n",
    "# print(\"Original scale\\n---\")\n",
    "# test_model(model_boosting, x_train, x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "# # Test using features with standardized scale\n",
    "# print(\"\\nStandardized scale\\n---\")\n",
    "# test_model(model_boosting, scaled_x_train, scaled_x_test, y_train, y_test, \n",
    "#            score=\"f1_score\", average=\"macro\", clf_report=True)\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- K-Nearest Neighbors\n",
      "f1_macro (Validation K-Nearest Neighbors) = nan\n",
      "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
      "\n",
      "- Decision Tree\n",
      "f1_macro (Validation Decision Tree) = 0.7783\n",
      "f1_macro (Test Decision Tree) = 0.7786\n",
      "[[1035   18   49]\n",
      " [   4  180    5]\n",
      " [  79    5   65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1102\n",
      "           1       0.89      0.95      0.92       189\n",
      "           2       0.55      0.44      0.49       149\n",
      "\n",
      "    accuracy                           0.89      1440\n",
      "   macro avg       0.79      0.78      0.78      1440\n",
      "weighted avg       0.88      0.89      0.88      1440\n",
      "\n",
      "\n",
      "\n",
      "- Linear SVM\n",
      "f1_macro (Validation Linear SVM) = nan\n",
      "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
      "Please change the base estimator or set algorithm='SAMME' instead.\n",
      "\n",
      "- Polynomial SVM\n",
      "f1_macro (Validation Polynomial SVM) = nan\n",
      "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
      "Please change the base estimator or set algorithm='SAMME' instead.\n",
      "\n",
      "- RBF SVM\n",
      "f1_macro (Validation RBF SVM) = nan\n",
      "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
      "Please change the base estimator or set algorithm='SAMME' instead.\n",
      "\n",
      "- Sigmoid SVM\n",
      "f1_macro (Validation Sigmoid SVM) = nan\n",
      "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
      "Please change the base estimator or set algorithm='SAMME' instead.\n",
      "\n",
      "- Logistic Regression\n",
      "f1_macro (Validation Logistic Regression) = 0.3013\n",
      "f1_macro (Test Logistic Regression) = 0.2889\n",
      "[[1101    0    1]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.76      0.66      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Gradient Boosting*) = 0.8172\n",
      "f1_macro (Test Gradient Boosting*) = 0.8102\n",
      "[[1072    0   30]\n",
      " [   5  181    3]\n",
      " [  86    1   62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1102\n",
      "           1       0.99      0.96      0.98       189\n",
      "           2       0.65      0.42      0.51       149\n",
      "\n",
      "    accuracy                           0.91      1440\n",
      "   macro avg       0.86      0.78      0.81      1440\n",
      "weighted avg       0.90      0.91      0.91      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "# Specify model evaluation metric\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "feature_train = x_train\n",
    "feature_test = x_test\n",
    "# feature_train = scaled_x_train\n",
    "# feature_test = scaled_x_test\n",
    "\n",
    "# Initialize parameter values of boosting classifier\n",
    "boosting_param = dict(n_estimators=100, random_state=0)\n",
    "\n",
    "# Loop through all classifiers\n",
    "# ---\n",
    "for i, clf in enumerate(dict_clf_default):\n",
    "    print(\"- {}\".format(clf))\n",
    "    base = dict_clf_default[clf]\n",
    "    \n",
    "    params = boosting_param.copy()\n",
    "    params[\"base_estimator\"] = base\n",
    "    \n",
    "    model_boosting = AdaBoostClassifier(**params)\n",
    "    \n",
    "    estimator = { clf: model_boosting }\n",
    "    \n",
    "    try:\n",
    "        \n",
    "#         score = test_model(model_boosting, feature_train, feature_test, y_train, y_test, \n",
    "#                            score=score_param, average=average_param)\n",
    "        score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "#     list_score.append(score[\"score\"])\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "\n",
    "# (Bonus) Gradient Boosting Classifier\n",
    "# ---\n",
    "model_gb = GradientBoostingClassifier(**boosting_param)\n",
    "\n",
    "name_gb = \"Gradient Boosting*\"\n",
    "\n",
    "estimator = {\"Gradient Boosting*\": model_gb}\n",
    "# print(\"GradientBoostingClassifier\\n===\")\n",
    "# print(\"- {}\".format(name_gb))\n",
    "\n",
    "score_gb = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "\n",
    "# score_gb = test_model(model_gb, feature_train, feature_test, y_train, y_test,\n",
    "#                    score=score_param, average=average_param)\n",
    "\n",
    "list_clf.append(name_gb)\n",
    "list_score = list_score + list(score_gb[name_gb].values())\n",
    "\n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file\n",
    "# df_performance.to_csv(r'final_project_performance_boosting.csv', index = False, header = True)\n",
    "\n",
    "# Plotting\n",
    "# ---\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"Boosting: {} on Different Base Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Base Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save plot into PNG (optional) \n",
    "# plt.savefig(\"final_project_performance_boosting.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Voting \n",
    "\n",
    "Voting is a method involving different machine learning algorithms.\n",
    "\n",
    "To implement voting method, specify `num_base_clf`, the number of base classifiers when defining an object of `VotingClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('K-Nearest Neighbors', 'Decision Tree', 'Linear SVM')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4003\n",
      "f1_macro (Test Voting Classifier) = 0.3423\n",
      "[[1093    3    6]\n",
      " [ 178   11    0]\n",
      " [ 145    0    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      1102\n",
      "           1       0.79      0.06      0.11       189\n",
      "           2       0.40      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.65      0.36      0.34      1440\n",
      "weighted avg       0.74      0.77      0.68      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Decision Tree', 'Polynomial SVM')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4770\n",
      "f1_macro (Test Voting Classifier) = 0.6034\n",
      "[[1058   43    1]\n",
      " [   9  180    0]\n",
      " [ 136   10    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1102\n",
      "           1       0.77      0.95      0.85       189\n",
      "           2       0.75      0.02      0.04       149\n",
      "\n",
      "    accuracy                           0.86      1440\n",
      "   macro avg       0.80      0.64      0.60      1440\n",
      "weighted avg       0.85      0.86      0.82      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Decision Tree', 'RBF SVM')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4717\n",
      "f1_macro (Test Voting Classifier) = 0.4692\n",
      "[[1039    2   61]\n",
      " [ 171   11    7]\n",
      " [  89    0   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87      1102\n",
      "           1       0.85      0.06      0.11       189\n",
      "           2       0.47      0.40      0.43       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.70      0.47      0.47      1440\n",
      "weighted avg       0.77      0.77      0.72      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Decision Tree', 'Sigmoid SVM')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4575\n",
      "f1_macro (Test Voting Classifier) = 0.4612\n",
      "[[1041    2   59]\n",
      " [ 172   10    7]\n",
      " [  92    0   57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      1102\n",
      "           1       0.83      0.05      0.10       189\n",
      "           2       0.46      0.38      0.42       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.70      0.46      0.46      1440\n",
      "weighted avg       0.77      0.77      0.72      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Decision Tree', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.3358\n",
      "f1_macro (Test Voting Classifier) = 0.3363\n",
      "[[1099    2    1]\n",
      " [ 179   10    0]\n",
      " [ 146    0    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.83      0.05      0.10       189\n",
      "           2       0.75      0.02      0.04       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.79      0.36      0.34      1440\n",
      "weighted avg       0.78      0.77      0.68      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Linear SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.2897\n",
      "f1_macro (Test Voting Classifier) = 0.2889\n",
      "[[1101    1    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.76      0.66      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Polynomial SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.3044\n",
      "f1_macro (Test Voting Classifier) = 0.3175\n",
      "[[1072   30    0]\n",
      " [ 178   11    0]\n",
      " [ 145    4    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.34      0.34      0.32      1440\n",
      "weighted avg       0.62      0.75      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'RBF SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.2961\n",
      "f1_macro (Test Voting Classifier) = 0.3046\n",
      "[[1093    0    9]\n",
      " [ 187    0    2]\n",
      " [ 145    0    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.27      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.34      0.34      0.30      1440\n",
      "weighted avg       0.61      0.76      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Sigmoid SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.2962\n",
      "f1_macro (Test Voting Classifier) = 0.3046\n",
      "[[1093    0    9]\n",
      " [ 187    0    2]\n",
      " [ 145    0    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.27      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.34      0.34      0.30      1440\n",
      "weighted avg       0.61      0.76      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "('Decision Tree', 'Linear SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.3573\n",
      "f1_macro (Test Voting Classifier) = 0.2963\n",
      "[[1097    0    5]\n",
      " [ 188    1    0]\n",
      " [ 148    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       1.00      0.01      0.01       189\n",
      "           2       0.17      0.01      0.01       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.64      0.34      0.30      1440\n",
      "weighted avg       0.73      0.76      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "('Decision Tree', 'Polynomial SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4749\n",
      "f1_macro (Test Voting Classifier) = 0.6162\n",
      "[[1087   15    0]\n",
      " [  10  179    0]\n",
      " [ 143    6    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.59      0.64      0.62      1440\n",
      "weighted avg       0.79      0.88      0.83      1440\n",
      "\n",
      "\n",
      "\n",
      "('Decision Tree', 'RBF SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4340\n",
      "f1_macro (Test Voting Classifier) = 0.4399\n",
      "[[1049    0   53]\n",
      " [ 183    1    5]\n",
      " [  90    0   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.87      1102\n",
      "           1       1.00      0.01      0.01       189\n",
      "           2       0.50      0.40      0.44       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.77      0.45      0.44      1440\n",
      "weighted avg       0.79      0.77      0.71      1440\n",
      "\n",
      "\n",
      "\n",
      "('Decision Tree', 'Sigmoid SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4185\n",
      "f1_macro (Test Voting Classifier) = 0.4314\n",
      "[[1051    0   51]\n",
      " [ 184    0    5]\n",
      " [  93    0   56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.50      0.38      0.43       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.43      0.44      0.43      1440\n",
      "weighted avg       0.66      0.77      0.71      1440\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_0</th>\n",
       "      <th>classifier_1</th>\n",
       "      <th>classifier_2</th>\n",
       "      <th>test_performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.342279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>0.603434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.469199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>0.461199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.336290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.288863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.317549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.304613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.304613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.296304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.616192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.439882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.431380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           classifier_0    classifier_1         classifier_2  test_performance\n",
       "0   K-Nearest Neighbors   Decision Tree           Linear SVM          0.342279\n",
       "1   K-Nearest Neighbors   Decision Tree       Polynomial SVM          0.603434\n",
       "2   K-Nearest Neighbors   Decision Tree              RBF SVM          0.469199\n",
       "3   K-Nearest Neighbors   Decision Tree          Sigmoid SVM          0.461199\n",
       "4   K-Nearest Neighbors   Decision Tree  Logistic Regression          0.336290\n",
       "5   K-Nearest Neighbors      Linear SVM  Logistic Regression          0.288863\n",
       "6   K-Nearest Neighbors  Polynomial SVM  Logistic Regression          0.317549\n",
       "7   K-Nearest Neighbors         RBF SVM  Logistic Regression          0.304613\n",
       "8   K-Nearest Neighbors     Sigmoid SVM  Logistic Regression          0.304613\n",
       "9         Decision Tree      Linear SVM  Logistic Regression          0.296304\n",
       "10        Decision Tree  Polynomial SVM  Logistic Regression          0.616192\n",
       "11        Decision Tree         RBF SVM  Logistic Regression          0.439882\n",
       "12        Decision Tree     Sigmoid SVM  Logistic Regression          0.431380"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify model evaluation metrics\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "feature_train = x_train\n",
    "feature_test = x_test\n",
    "# feature_train = scaled_x_train\n",
    "# feature_test = scaled_x_test\n",
    "\n",
    "# specify number of base classifiers\n",
    "num_base_clf = 3\n",
    "list_clf = [[] for i in range(num_base_clf)]\n",
    "list_score = []\n",
    "\n",
    "# Generate all possible combinations of base classifiers with # of classifiers = num_base_clf\n",
    "# For example: if num_base_clf = 4, \n",
    "# [A, B, C, D, E] -> [A, B, C, D], [A, B, C, E], [A, B, D, E], [A, C, D, E] and [B, C, D, E]\n",
    "combinations_base_clf = itertools.combinations(dict_clf_default, num_base_clf)\n",
    "\n",
    "# Loop through all generated lists\n",
    "for comb in combinations_base_clf:\n",
    "    list_base_clf = []\n",
    "    \n",
    "    # Return number of SVM and Naive Bayes classifiers in a list\n",
    "    count_svm = sum(\"SVM\" in clf for clf in comb)\n",
    "    count_nb = sum(\"Naive Bayes\" in clf for clf in comb)\n",
    "    \n",
    "    # At most one SVM classifiers and Naive Bayes classifiers in the list.\n",
    "    # - skip all the lists with >1 SVM and >1 Naive Bayes classifiers - speed up looping process\n",
    "    # - ensure variation in machine learning algorithms in the voting classifier\n",
    "    if (count_svm <= 1) & (count_nb <= 1):\n",
    "        for i, clf in enumerate(comb):\n",
    "            list_base_clf.append((clf, dict_clf_default[clf]))\n",
    "            list_clf[i].append(clf)\n",
    "    \n",
    "        print(comb)\n",
    "        print(\"---\")\n",
    "        \n",
    "        try:\n",
    "            model_voting = VotingClassifier(estimators=list_base_clf)\n",
    "#             score = test_model(model_voting, feature_train, feature_test, y_train, y_test, \n",
    "#                                score=score_param, average=average_param)\n",
    "            \n",
    "            estimator_name = \"Voting Classifier\"\n",
    "            estimator = { estimator_name : model_voting }\n",
    "            score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "            \n",
    "#             list_score.append(score[\"score\"])\n",
    "            list_score = list_score + list(score[estimator_name].values())\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_class_name = e.__class__.__name__\n",
    "            print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "            continue\n",
    "        \n",
    "        print()\n",
    "\n",
    "        \n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict()\n",
    "for i, base_clf in enumerate(list_clf):\n",
    "    clf_key = \"classifier_{}\".format(i)\n",
    "    data[clf_key] = base_clf\n",
    "\n",
    "data[\"test_performance\"] = list_score\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# Save and export df_performance to CSV file\n",
    "df_performance.to_csv(r'final_project_performance_voting_{}clf.csv'.format(num_base_clf), index = False, header = True)\n",
    "\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set 4: Vary Training Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 subsamples from the original training set.\n",
    "num_subsamples = 10\n",
    "\n",
    "x_train_subs = []\n",
    "y_train_subs = []\n",
    "\n",
    "for k in range(num_subsamples - 1):\n",
    "    x_train_sub, _, y_train_sub, _ = train_test_split(x_train, y_train, \n",
    "                                                      train_size=((k+1) / 10),\n",
    "                                                      random_state=0)\n",
    "    x_train_subs.append(x_train_sub)\n",
    "    y_train_subs.append(y_train_sub)\n",
    "    \n",
    "x_train_subs.append(x_train)\n",
    "y_train_subs.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function\n",
    "def train_and_evaluate_vary_size(estimator, x_train_list, x_test, y_train_list, y_test):\n",
    "    # 2 - Train and evaluate\n",
    "    # Initialize 3 empty lists to store the values of k and validation and test score \n",
    "    # Initialize 1 empty dictionary (scores) to store the k: validation_score / test_score (key:value) pairs\n",
    "    K = [] \n",
    "    validationf1macro = []\n",
    "    testf1macro = []\n",
    "    scores = {}\n",
    "\n",
    "    for k, (x_train, y_train) in enumerate(zip(x_train_list, y_train_list)):\n",
    "        # 10-fold Cross-Validation\n",
    "        # ---\n",
    "        # Compute the validation score for the model using 10-fold cross validation \n",
    "        scores_val = cross_val_score(estimator, x_train, y_train, cv = 10, scoring = 'f1_macro')\n",
    "\n",
    "        # Compute the mean validation score\n",
    "        score_val_mean = scores_val.mean()\n",
    "\n",
    "        # Training and testing\n",
    "        # ---\n",
    "        # Fit and train the model to the subsample training data.\n",
    "        estimator.fit(x_train, y_train)\n",
    "\n",
    "        # Compute the test score by compare the actual and prediction outcome.\n",
    "        test_predict = estimator.predict(x_test)\n",
    "\n",
    "        # Compute the test score by compare the actual and prediction outcome.\n",
    "        score_test = metrics.f1_score(y_test, test_predict, average='macro')\n",
    "\n",
    "        # Update lists\n",
    "        # ---\n",
    "        key = k + 1\n",
    "        K.append(key)\n",
    "\n",
    "        validationf1macro.append(score_val_mean)\n",
    "        testf1macro.append(score_test)\n",
    "\n",
    "        # A dictionary holds key: value pairs and Store the validation score for each value of k\n",
    "        scores[key] = (score_val_mean, score_test)\n",
    "\n",
    "\n",
    "    # 3 - Print result\n",
    "    print(\"Subsample (%): Macro F1 score (Validation | Test)\")\n",
    "\n",
    "    for key_score in scores:\n",
    "        score_val = scores[key_score][0]\n",
    "        score_test = scores[key_score][1]\n",
    "        print(\"{:.1f}%: ({:.4f} | {:.4f})\".format(key_score*10, score_val, score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Best Model from Experiment Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample (%): Macro F1 score (Validation | Test)\n",
      "10.0%: (0.7223 | 0.7347)\n",
      "20.0%: (0.7465 | 0.7508)\n",
      "30.0%: (0.7658 | 0.7499)\n",
      "40.0%: (0.7678 | 0.7449)\n",
      "50.0%: (0.7430 | 0.7449)\n",
      "60.0%: (0.7744 | 0.7692)\n",
      "70.0%: (0.7776 | 0.7757)\n",
      "80.0%: (0.7815 | 0.7700)\n",
      "90.0%: (0.7771 | 0.7692)\n",
      "100.0%: (0.7764 | 0.7732)\n"
     ]
    }
   ],
   "source": [
    "# Define Decision Tree classifier\n",
    "dtree = DecisionTreeClassifier(criterion = 'gini',splitter = 'best', random_state = 0)\n",
    "\n",
    "train_and_evaluate_vary_size(dtree, x_train_subs, x_test, y_train_subs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Best Model from Experiment Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = get_chi2_features(x_train, y_train, num_k=10)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_sub_chi2 = []\n",
    "for k in range(num_subsamples - 1):\n",
    "    x_train_sub, _, _, _ = train_test_split(x_train, y_train,           \n",
    "                                            train_size=((k+1) / 10),\n",
    "                                            random_state=0)\n",
    "    x_train_sub_chi2.append(x_train_sub)\n",
    "#     y_train_subs.append(y_train_sub)\n",
    "    \n",
    "x_train_sub_chi2.append(x_train_chi2)\n",
    "# y_train_subs.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample (%): Macro F1 score (Validation | Test)\n",
      "10.0%: (0.7223 | 0.7347)\n",
      "20.0%: (0.7465 | 0.7508)\n",
      "30.0%: (0.7658 | 0.7499)\n",
      "40.0%: (0.7678 | 0.7449)\n",
      "50.0%: (0.7430 | 0.7449)\n",
      "60.0%: (0.7744 | 0.7692)\n",
      "70.0%: (0.7776 | 0.7757)\n",
      "80.0%: (0.7815 | 0.7700)\n",
      "90.0%: (0.7771 | 0.7692)\n",
      "100.0%: (0.7764 | 0.7732)\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using top 10 features - chi2\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "train_and_evaluate_vary_size(dtree, x_train_subs, x_test, y_train_subs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3: Best Model from Experiment Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample (%): Macro F1 score (Validation | Test)\n",
      "10.0%: (0.7515 | 0.7899)\n",
      "20.0%: (0.7898 | 0.8064)\n",
      "30.0%: (0.8087 | 0.7952)\n",
      "40.0%: (0.8044 | 0.8088)\n",
      "50.0%: (0.8097 | 0.8167)\n",
      "60.0%: (0.8079 | 0.8135)\n",
      "70.0%: (0.8095 | 0.8132)\n",
      "80.0%: (0.8119 | 0.8179)\n",
      "90.0%: (0.8144 | 0.8031)\n",
      "100.0%: (0.8152 | 0.8090)\n"
     ]
    }
   ],
   "source": [
    "# #Import the package for Bagging Classifier\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model_bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=0), \n",
    "                                  n_estimators = 100, random_state = 0)\n",
    "\n",
    "train_and_evaluate_vary_size(model_bagging, x_train_subs, x_test, y_train_subs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall best model is the bagging model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
