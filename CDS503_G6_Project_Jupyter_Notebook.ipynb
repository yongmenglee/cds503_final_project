{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDS503 - Machine Learning Final Project\n",
    "\n",
    "Universiti Sains Malaysia\n",
    "\n",
    "Semester 2, Academic Session 2019/2020\n",
    "\n",
    "\n",
    "Group 6 - **Data Masters**\n",
    "\n",
    "Members:\n",
    "- Lee Yong Meng\n",
    "- Lee Kar Choon\n",
    "- Tan Wei Chean\n",
    "- Yee Hoong Yip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- [Data Preparation](#Data-Preparation)\n",
    "- [Experiment Set 1: Machine Learning Algorithm](#Experiment-Set-1:-Comparing-Machine-Learning-Algorithms)\n",
    "- [Experiment Set 2: Feature Selection](#Experiment-Set-2:-Feature-Selection)\n",
    "- [Experiment Set 3: Ensemble Learning](#Experiment-Set-3:-Ensemble-Learning)\n",
    "- [Experiment Set 4: Training Sample Size](#Experiment-Set-4:-Vary-Training-Sample-Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Before working on the experiment sets, we need to import some necessary libraries for working on data pre-processing and conducting experiment sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python libraries\n",
    "import pandas as pd                  # Use pandas.DataFrame to manipulate data\n",
    "import matplotlib.pyplot as plt      # Standard plotting library\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn import preprocessing    # Data preprocessing\n",
    "\n",
    "# Model selection - split data, cv, model evaluation\n",
    "from sklearn.model_selection import train_test_split    # Split dataset into training and test sets\n",
    "from sklearn.model_selection import cross_val_score     # k-fold cross-validation\n",
    "from sklearn.model_selection import GridSearchCV        # search for best parameters\n",
    "from sklearn import metrics                             # metrics to evaluate the model performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix    # analyze prediction made by the classification model\n",
    "\n",
    "# Machine learning algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Feature extraction - Decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "# Ensemble learning methods\n",
    "from sklearn.ensemble import BaggingClassifier            # Bagging - (B)ootstrap (AGG)regat(ING)\n",
    "from sklearn.ensemble import AdaBoostClassifier           # Boosting - (ADA)ptive (BOOST)ing\n",
    "from sklearn.ensemble import VotingClassifier             # Voting\n",
    "\n",
    "# Itertools - here, used to generate combinations of base classifiers for voting\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence all warnings during training and evaluation process\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click [here](#Start-Here-To-Skip-Data-Preprocessing-Step) to skip the preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV file\n",
    "\n",
    "Next, we read in the data from the CSV file: AppleStore.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>281656475</td>\n",
       "      <td>PAC-MAN Premium</td>\n",
       "      <td>100788224</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>281796108</td>\n",
       "      <td>Evernote - stay organized</td>\n",
       "      <td>158578688</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>281940292</td>\n",
       "      <td>WeatherBug - Local Weather, Radar, Maps, Alerts</td>\n",
       "      <td>100524032</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>282614216</td>\n",
       "      <td>eBay: Best App to Buy, Sell, Save! Online Shop...</td>\n",
       "      <td>128512000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>282935706</td>\n",
       "      <td>Bible</td>\n",
       "      <td>92774400</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                                         track_name  \\\n",
       "0           1  281656475                                    PAC-MAN Premium   \n",
       "1           2  281796108                          Evernote - stay organized   \n",
       "2           3  281940292    WeatherBug - Local Weather, Radar, Maps, Alerts   \n",
       "3           4  282614216  eBay: Best App to Buy, Sell, Save! Online Shop...   \n",
       "4           5  282935706                                              Bible   \n",
       "\n",
       "   size_bytes currency  price  rating_count_tot  rating_count_ver  \\\n",
       "0   100788224      USD   3.99             21292                26   \n",
       "1   158578688      USD   0.00            161065                26   \n",
       "2   100524032      USD   0.00            188583              2822   \n",
       "3   128512000      USD   0.00            262241               649   \n",
       "4    92774400      USD   0.00            985920              5320   \n",
       "\n",
       "   user_rating  user_rating_ver     ver cont_rating   prime_genre  \\\n",
       "0          4.0              4.5   6.3.5          4+         Games   \n",
       "1          4.0              3.5   8.2.2          4+  Productivity   \n",
       "2          3.5              4.5   5.0.0          4+       Weather   \n",
       "3          4.0              4.5  5.10.0         12+      Shopping   \n",
       "4          4.5              5.0   7.5.1          4+     Reference   \n",
       "\n",
       "   sup_devices.num  ipadSc_urls.num  lang.num  vpp_lic  \n",
       "0               38                5        10        1  \n",
       "1               37                5        23        1  \n",
       "2               37                5         3        1  \n",
       "3               37                5         9        1  \n",
       "4               37                5        45        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('AppleStore.csv')\n",
    "\n",
    "# Quick view on the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several columns in the datasets are not helpful in our work. Therefore, we will remove these columns.\n",
    "\n",
    "- `Id`: App ID\n",
    "- `track_name`: App name\n",
    "- `currency`: not helpful because it only has one unique value \"USD\" for all examples.\n",
    "- Unnamed: the first column, which is the count of the record.\n",
    "\n",
    "We use the method `.drop()` to remove the specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes  price  rating_count_tot  rating_count_ver  user_rating  \\\n",
       "0   100788224   3.99             21292                26          4.0   \n",
       "1   158578688   0.00            161065                26          4.0   \n",
       "2   100524032   0.00            188583              2822          3.5   \n",
       "3   128512000   0.00            262241               649          4.0   \n",
       "4    92774400   0.00            985920              5320          4.5   \n",
       "\n",
       "   user_rating_ver     ver cont_rating   prime_genre  sup_devices.num  \\\n",
       "0              4.5   6.3.5          4+         Games               38   \n",
       "1              3.5   8.2.2          4+  Productivity               37   \n",
       "2              4.5   5.0.0          4+       Weather               37   \n",
       "3              4.5  5.10.0         12+      Shopping               37   \n",
       "4              5.0   7.5.1          4+     Reference               37   \n",
       "\n",
       "   ipadSc_urls.num  lang.num  vpp_lic  \n",
       "0                5        10        1  \n",
       "1                5        23        1  \n",
       "2                5         3        1  \n",
       "3                5         9        1  \n",
       "4                5        45        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define columns to drop\n",
    "columns_drop = ['id', 'track_name', 'currency']\n",
    "\n",
    "# Drop columns from list\n",
    "df.drop(columns_drop, axis = 1, inplace = True)\n",
    "# Drop unnamed column\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed', case = False)], \n",
    "        axis = 1, inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping `user_rating` using `pd.cut()` \n",
    "\n",
    "For our business problem, we would like to group the column `user_rating` (i.e. our target column) into three groups, namely \"Low\", \"Medium\" and \"High\". We use the function `pd.cut()` to perform the binning. Then, we add a new column `user_rating_label` into the data frame, which will be shown at the very end when the data frame preview is scrolling horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes  price  rating_count_tot  rating_count_ver  user_rating  \\\n",
       "0   100788224   3.99             21292                26          4.0   \n",
       "1   158578688   0.00            161065                26          4.0   \n",
       "2   100524032   0.00            188583              2822          3.5   \n",
       "3   128512000   0.00            262241               649          4.0   \n",
       "4    92774400   0.00            985920              5320          4.5   \n",
       "\n",
       "   user_rating_ver     ver cont_rating   prime_genre  sup_devices.num  \\\n",
       "0              4.5   6.3.5          4+         Games               38   \n",
       "1              3.5   8.2.2          4+  Productivity               37   \n",
       "2              4.5   5.0.0          4+       Weather               37   \n",
       "3              4.5  5.10.0         12+      Shopping               37   \n",
       "4              5.0   7.5.1          4+     Reference               37   \n",
       "\n",
       "   ipadSc_urls.num  lang.num  vpp_lic user_rating_label  \n",
       "0                5        10        1              High  \n",
       "1                5        23        1              High  \n",
       "2                5         3        1              High  \n",
       "3                5         9        1              High  \n",
       "4                5        45        1              High  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_rating_label'] = pd.cut(df['user_rating'], bins = 3, labels = ['Low', 'Medium', 'High'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will drop the column `user_rating` because it is no longer needed - we will be using the new column `user_rating_label` as the target of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "0   100788224   3.99             21292                26              4.5   \n",
       "1   158578688   0.00            161065                26              3.5   \n",
       "2   100524032   0.00            188583              2822              4.5   \n",
       "3   128512000   0.00            262241               649              4.5   \n",
       "4    92774400   0.00            985920              5320              5.0   \n",
       "\n",
       "      ver cont_rating   prime_genre  sup_devices.num  ipadSc_urls.num  \\\n",
       "0   6.3.5          4+         Games               38                5   \n",
       "1   8.2.2          4+  Productivity               37                5   \n",
       "2   5.0.0          4+       Weather               37                5   \n",
       "3  5.10.0         12+      Shopping               37                5   \n",
       "4   7.5.1          4+     Reference               37                5   \n",
       "\n",
       "   lang.num  vpp_lic user_rating_label  \n",
       "0        10        1              High  \n",
       "1        23        1              High  \n",
       "2         3        1              High  \n",
       "3         9        1              High  \n",
       "4        45        1              High  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop column: user_rating\n",
    "df.drop('user_rating', axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further inspect the data by calling the method `.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7197 entries, 0 to 7196\n",
      "Data columns (total 13 columns):\n",
      "size_bytes           7197 non-null int64\n",
      "price                7197 non-null float64\n",
      "rating_count_tot     7197 non-null int64\n",
      "rating_count_ver     7197 non-null int64\n",
      "user_rating_ver      7197 non-null float64\n",
      "ver                  7197 non-null object\n",
      "cont_rating          7197 non-null object\n",
      "prime_genre          7197 non-null object\n",
      "sup_devices.num      7197 non-null int64\n",
      "ipadSc_urls.num      7197 non-null int64\n",
      "lang.num             7197 non-null int64\n",
      "vpp_lic              7197 non-null int64\n",
      "user_rating_label    7197 non-null category\n",
      "dtypes: category(1), float64(2), int64(7), object(3)\n",
      "memory usage: 682.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is no missing values in our data.\n",
    "\n",
    "Some of the columns contain `String` values which might not be compatible to certain machine learning algorithms that will be implemented in the subsequent sections. Therefore, we need to transform the data into labels encoded by numeric values (i.e., 0, 1, 2, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding - Categorical Attributes\n",
    "\n",
    "We use `sklearn.preprocessing.LabelEncoder()` to transform the following columns into numeric labels:\n",
    "- `prime_genre`: contains 22 unique `String` values.\n",
    "- `user_rating_label`: contains 3 unique `String` values (\"Low\", \"Medium\", \"High\")\n",
    "- `cont_rating`: app content rating, contains 4 unique `String` values.\n",
    "- `ver`: app version, contains 1590 unique `String` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 unique values of cont_rating.\n",
      "There are 23 unique values of prime_genre.\n",
      "There are 3 unique values of user_rating_label.\n",
      "There are 1590 unique values of ver.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7197 entries, 0 to 7196\n",
      "Data columns (total 13 columns):\n",
      "size_bytes           7197 non-null int64\n",
      "price                7197 non-null float64\n",
      "rating_count_tot     7197 non-null int64\n",
      "rating_count_ver     7197 non-null int64\n",
      "user_rating_ver      7197 non-null float64\n",
      "ver                  7197 non-null object\n",
      "cont_rating          7197 non-null object\n",
      "prime_genre          7197 non-null object\n",
      "sup_devices.num      7197 non-null int64\n",
      "ipadSc_urls.num      7197 non-null int64\n",
      "lang.num             7197 non-null int64\n",
      "vpp_lic              7197 non-null int64\n",
      "user_rating_label    7197 non-null object\n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 731.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Define names of columns selected for label encoding\n",
    "col_categories = [\"cont_rating\", \"prime_genre\", \"user_rating_label\", \"ver\"]\n",
    "col_num_unique_values = dict()\n",
    "\n",
    "for col_name in col_categories:\n",
    "    count = len(df[col_name].unique())\n",
    "    col_num_unique_values[col_name] = count\n",
    "    \n",
    "    print(\"There are {} unique values of {}.\".format(count, col_name))\n",
    "    \n",
    "    df[col_name] = le.fit_transform(df[col_name])\n",
    "    df[col_name] = df[col_name].astype(str)\n",
    "\n",
    "print()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1379</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1514</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1210</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1236</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1472</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "0   100788224   3.99             21292                26              4.5   \n",
       "1   158578688   0.00            161065                26              3.5   \n",
       "2   100524032   0.00            188583              2822              4.5   \n",
       "3   128512000   0.00            262241               649              4.5   \n",
       "4    92774400   0.00            985920              5320              5.0   \n",
       "\n",
       "    ver cont_rating prime_genre  sup_devices.num  ipadSc_urls.num  lang.num  \\\n",
       "0  1379           2           7               38                5        10   \n",
       "1  1514           2          15               37                5        23   \n",
       "2  1210           2          22               37                5         3   \n",
       "3  1236           0          17               37                5         9   \n",
       "4  1472           2          16               37                5        45   \n",
       "\n",
       "   vpp_lic user_rating_label  \n",
       "0        1                 0  \n",
       "1        1                 0  \n",
       "2        1                 0  \n",
       "3        1                 0  \n",
       "4        1                 0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the preprocessed dataset is saved into a new CSV file. This is the dataset used for conducting the experiment sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r'AppleStore_preprocessed.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here To Skip Data Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100788224</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1379</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158578688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1514</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100524032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1210</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128512000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1236</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92774400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1472</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "0   100788224   3.99             21292                26              4.5   \n",
       "1   158578688   0.00            161065                26              3.5   \n",
       "2   100524032   0.00            188583              2822              4.5   \n",
       "3   128512000   0.00            262241               649              4.5   \n",
       "4    92774400   0.00            985920              5320              5.0   \n",
       "\n",
       "    ver  cont_rating  prime_genre  sup_devices.num  ipadSc_urls.num  lang.num  \\\n",
       "0  1379            2            7               38                5        10   \n",
       "1  1514            2           15               37                5        23   \n",
       "2  1210            2           22               37                5         3   \n",
       "3  1236            0           17               37                5         9   \n",
       "4  1472            2           16               37                5        45   \n",
       "\n",
       "   vpp_lic  user_rating_label  \n",
       "0        1                  0  \n",
       "1        1                  0  \n",
       "2        1                  0  \n",
       "3        1                  0  \n",
       "4        1                  0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('AppleStore_preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Target and Features and Splitting Dataset\n",
    "\n",
    "The attribute `user_rating_label` is the target throught the experiment sets. At this stage, all the other attributes are selected as the features used for predicting the `user_rating_label` to this classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target - `user_rating_label`\n",
    "target = df['user_rating_label']\n",
    "\n",
    "# Feature - all other attributes\n",
    "features = df.drop('user_rating_label', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the dataset is split into training and test sets, with proportions of 80% and 20% respectively.\n",
    "\n",
    "The parameter `random_state=0` is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                    test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to train and evaluate model performance. This function includes a 10-fold cross-validation.\n",
    "\n",
    "The performance metric is `\"f1_macro\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #1: train and evaluate model performance.\n",
    "# - The parameter `estimator` takes a list of classifier dictionary: {name, classifier}\n",
    "def train_and_evaluate(estimators, X_train, X_test, Y_train, Y_test):\n",
    "    # Nested function #1: Specify performance metric: only \"f1_macro\"\n",
    "    def get_scoring_metric():\n",
    "        return ['f1_macro']\n",
    "    \n",
    "    # Nested function #2: K-fold cross validation\n",
    "    def print_validation_performance(estimator, X_train, Y_train, name=None, cv=10):\n",
    "        for metric in get_scoring_metric():\n",
    "            scores = cross_val_score(estimator, X_train, Y_train, cv=cv, scoring=metric)\n",
    "            estimator_name = \"\"\n",
    "            \n",
    "            if name is not None:\n",
    "                estimator_name = \" {}\".format(name)\n",
    "                \n",
    "            print(\"{} (Validation{}) = \".format(metric, estimator_name), end=\"\")\n",
    "            print(\"{:.4f}\".format(scores.mean()))\n",
    "    \n",
    "    # Nested function #3: Training and testing\n",
    "    def print_test_performance(estimator, X_train, X_test, Y_train, Y_test, name=None):\n",
    "        estimator.fit(X_train, Y_train)\n",
    "        test_predict = estimator.predict(X_test)\n",
    "        \n",
    "        dict_score = {}\n",
    "        \n",
    "        # Get performance score for each metric\n",
    "        for metric in get_scoring_metric():\n",
    "            estimator_name = \"\"\n",
    "            score = 0.0\n",
    "            \n",
    "            if name is not None:\n",
    "                estimator_name = \" {}\".format(name) \n",
    "            \n",
    "            average = None\n",
    "            acc_flag = True\n",
    "            \n",
    "            if \"macro\" in metric:\n",
    "                average = \"macro\"\n",
    "                acc_flag = False\n",
    "            elif \"weighted\" in metric:\n",
    "                average = \"weighted\"\n",
    "                acc_flag = False\n",
    "            \n",
    "            print(\"{} (Test{}) = \".format(metric, estimator_name), end=\"\")\n",
    "            \n",
    "            # Currently only supports accuracy and f1_score.\n",
    "            if acc_flag:\n",
    "                score = metrics.accuracy_score(Y_test, test_predict)\n",
    "            else:\n",
    "                score = metrics.f1_score(Y_test, test_predict, average=average)\n",
    "            \n",
    "            print(\"{:.4f}\".format(score))\n",
    "            \n",
    "            dict_score[metric] = score\n",
    "        \n",
    "        print(confusion_matrix(Y_test, test_predict))         # Confusion matrix\n",
    "        print(classification_report(Y_test, test_predict))    # Classification report\n",
    "        \n",
    "        return dict_score\n",
    "    \n",
    "    dict_est_score = {}\n",
    "    \n",
    "    # Print validation and test performance for all classifiers in the list.\n",
    "    for key_est in estimators:\n",
    "        print_validation_performance(estimators[key_est], X_train, Y_train, name=key_est)\n",
    "        dict_est_score[key_est] = print_test_performance(estimators[key_est], \n",
    "                                                         X_train, X_test, Y_train, Y_test, \n",
    "                                                         name=key_est)\n",
    "        print()\n",
    "        \n",
    "    return dict_est_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are ready to conduct the experiment sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set 1: Comparing Machine Learning Algorithms\n",
    "\n",
    "In this experiment set, we compare the baseline performance and the best performance (after parameter tuning) on the test set for each machine learning algorithm being used.\n",
    "\n",
    "The list of machine learning algorithms are:\n",
    "\n",
    "- K-Nearest Neighbors\n",
    "- Decision Tree\n",
    "- Linear SVM\n",
    "- Polynomial SVM\n",
    "- RBF SVM\n",
    "- Sigmoid SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the experiment set, a helper function is defined to identify the best set of parameters for a machine learning model for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #2 - Get the best parameter set for a classifier\n",
    "# using GridSearchCV()\n",
    "def get_best_parameter_set(estimator, param_grid, scoring):\n",
    "    # Fit on the dataset on all parameter combinations in param_grid\n",
    "    # Retain the best combination\n",
    "    grid_search = GridSearchCV(estimator, param_grid, cv=10, scoring=scoring) #f1_macro\n",
    "    grid_result = grid_search.fit(x_train, y_train)\n",
    "    \n",
    "    return grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 K-Nearest Neighbors\n",
    "\n",
    "Train and evaluate a KNN classifier using the training and test set using helper function \\#1: `train_and_evaluate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN - baseline) = 0.3262\n",
      "f1_macro (Test KNN - baseline) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN - baseline': {'f1_macro': 0.3328694504027031}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline KNN classifier\n",
    "estimator = {\"KNN - baseline\": KNeighborsClassifier()}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call helper function \\#2: `get_best_parameter_set()` to obtain the best parameter set for a KNN classifier to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best parameter set for KNN Classifier for the dataset\n",
    "# - Specify range of parameter values to find the best parameter set.\n",
    "param_grid = {'n_neighbors': range(2, 20)}\n",
    "\n",
    "# - Call helper function #2: get_best_parameter_set which returns the best parameter set\n",
    "#   for KNN classifier.\n",
    "best_param_set = get_best_parameter_set(KNeighborsClassifier(), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define new KNN classifier with the best parameter set, repeat the training and evaluation process to generate test performance for comparison with the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN - best parameter) = 0.3395\n",
      "f1_macro (Test KNN - best parameter) = 0.3424\n",
      "[[1017   54   31]\n",
      " [ 162   18    9]\n",
      " [ 137    7    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1102\n",
      "           1       0.23      0.10      0.13       189\n",
      "           2       0.11      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.72      1440\n",
      "   macro avg       0.37      0.35      0.34      1440\n",
      "weighted avg       0.63      0.72      0.67      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN - best parameter': {'f1_macro': 0.34235527231968366}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a KNN classifier with the best parameter set\n",
    "estimator = {\"KNN - best parameter\": KNeighborsClassifier(**best_param_set)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similar process is repeated for the other machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Decision Trees\n",
    "\n",
    "**Note**: The parameter `random_state=0` is specified for both baseline and the best performing classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Decision Tree - baseline) = 0.7764\n",
      "f1_macro (Test Decision Tree - baseline) = 0.7732\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree - baseline': {'f1_macro': 0.7732013528151364}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline Decision Tree classifier\n",
    "estimator = {\"Decision Tree - baseline\": DecisionTreeClassifier(random_state=0)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'splitter': 'best'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best parameter set for Decision Tree Classifier for the dataset\n",
    "param_grid = {'criterion': ['gini','entropy'],\n",
    "              'splitter': ['best','random']}\n",
    "\n",
    "best_param_set = get_best_parameter_set(DecisionTreeClassifier(random_state=0), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Decision Tree - best parameter) = 0.7764\n",
      "f1_macro (Test Decision Tree - best parameter) = 0.7732\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree - best parameter': {'f1_macro': 0.7732013528151364}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a Decision Tree classifier with the best parameter set\n",
    "estimator = {\"Decision Tree - best parameter\": DecisionTreeClassifier(**best_param_set, random_state=0)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Linear SVM\n",
    "\n",
    "**Note**: The parameter `max_iter=10000` is a stopping criteria to speed up the training and evaluation process for SVM classifiers. However, it does not guarantee a good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Linear SVM - baseline) = 0.1785\n",
      "f1_macro (Test Linear SVM - baseline) = 0.1019\n",
      "[[  68    0 1034]\n",
      " [   2    0  187]\n",
      " [   5    0  144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.06      0.12      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.11      0.97      0.19       149\n",
      "\n",
      "    accuracy                           0.15      1440\n",
      "   macro avg       0.34      0.34      0.10      1440\n",
      "weighted avg       0.70      0.15      0.11      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Linear SVM - baseline': {'f1_macro': 0.10192419135739424}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline linear SVM classifier\n",
    "estimator = {\"Linear SVM - baseline\": SVC(kernel='linear', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best parameter set for Linear SVM Classifier for the dataset\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "best_param_set = get_best_parameter_set(SVC(kernel='linear', max_iter=10000), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Linear SVM - best parameter) = 0.1785\n",
      "f1_macro (Test Linear SVM - best parameter) = 0.1019\n",
      "[[  68    0 1034]\n",
      " [   2    0  187]\n",
      " [   5    0  144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.06      0.12      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.11      0.97      0.19       149\n",
      "\n",
      "    accuracy                           0.15      1440\n",
      "   macro avg       0.34      0.34      0.10      1440\n",
      "weighted avg       0.70      0.15      0.11      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Linear SVM - best parameter': {'f1_macro': 0.10192419135739424}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a linear SVM classifier with the best parameter set\n",
    "estimator = {\"Linear SVM - best parameter\": SVC(**best_param_set, kernel='linear', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Polynomial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Polynomial SVM - baseline) = 0.2017\n",
      "f1_macro (Test Polynomial SVM - baseline) = 0.2890\n",
      "[[1101    0    1]\n",
      " [ 188    0    1]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.76      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Polynomial SVM - baseline': {'f1_macro': 0.28897637795275594}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline polynomial SVM classifier\n",
    "estimator = {\"Polynomial SVM - baseline\": SVC(kernel='poly', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'degree': 4, 'gamma': 'scale'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best parameter set for Polynomial SVM Classifier for the dataset\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'degree': [2, 3, 4], \n",
    "              'gamma': ['scale', 'auto', 0.001, 0.1, 1, 10, 100]}\n",
    "\n",
    "best_param_set = get_best_parameter_set(SVC(kernel='poly', max_iter=10000), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Polynomial SVM - best parameter) = 0.2887\n",
      "f1_macro (Test Polynomial SVM - best parameter) = 0.0776\n",
      "[[   1 1101    0]\n",
      " [   0  188    1]\n",
      " [   0  149    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1102\n",
      "           1       0.13      0.99      0.23       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.13      1440\n",
      "   macro avg       0.38      0.33      0.08      1440\n",
      "weighted avg       0.78      0.13      0.03      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Polynomial SVM - best parameter': {'f1_macro': 0.07763780700527495}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a polynomial SVM classifier with the best parameter set\n",
    "estimator = {\"Polynomial SVM - best parameter\": SVC(**best_param_set, kernel='poly', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation RBF SVM - baseline) = 0.2881\n",
      "f1_macro (Test RBF SVM - baseline) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RBF SVM - baseline': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline RBF SVM classifier\n",
    "estimator = {\"RBF SVM - baseline\": SVC(kernel='rbf', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.001}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best parameter set for RBF SVM Classifier for the dataset\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': ['scale', 'auto', 0.001, 0.1, 1, 10, 100]}\n",
    "\n",
    "best_param_set = get_best_parameter_set(SVC(kernel='rbf', max_iter=10000), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation RBF SVM - best parameter) = 0.2897\n",
      "f1_macro (Test RBF SVM - best parameter) = 0.2962\n",
      "[[1102    0    0]\n",
      " [ 187    2    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       1.00      0.01      0.02       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.59      0.34      0.30      1440\n",
      "weighted avg       0.72      0.77      0.67      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RBF SVM - best parameter': {'f1_macro': 0.29621964793667804}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a RBF SVM classifier with the best parameter set\n",
    "estimator = {\"RBF SVM - best parameter\": SVC(**best_param_set, kernel='rbf', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Sigmoid SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Sigmoid SVM - baseline) = 0.2881\n",
      "f1_macro (Test Sigmoid SVM - baseline) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Sigmoid SVM - baseline': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a baseline Sigmoid SVM classifier\n",
    "estimator = {\"Sigmoid SVM - baseline\": SVC(kernel='sigmoid', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 'scale'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best parameter set for Sigmoid SVM Classifier for the dataset\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': ['scale', 'auto', 0.001, 0.1, 1, 10, 100]}\n",
    "\n",
    "best_param_set = get_best_parameter_set(SVC(kernel='sigmoid', max_iter=10000), param_grid, scoring='f1_macro')\n",
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Sigmoid SVM - best parameter) = 0.2972\n",
      "f1_macro (Test Sigmoid SVM - best parameter) = 0.3057\n",
      "[[969   0 133]\n",
      " [181   0   8]\n",
      " [133   0  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.10      0.11      0.10       149\n",
      "\n",
      "    accuracy                           0.68      1440\n",
      "   macro avg       0.29      0.33      0.31      1440\n",
      "weighted avg       0.59      0.68      0.63      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Sigmoid SVM - best parameter': {'f1_macro': 0.3057179265836314}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate test performance of a Sigmoid SVM classifier with the best parameter set\n",
    "estimator = {\"Sigmoid SVM - best parameter\": SVC(**best_param_set, kernel='sigmoid', max_iter=10000)}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Set 1 Summary\n",
    "\n",
    "The best model from this experiment is the **decision tree** (`random_state=0`) with the specified parameters as follows.\n",
    "\n",
    "    Parameters (params): {'criterion': 'gini', 'splitter': 'best'}\n",
    "    \n",
    "    Classifier: DecisionTreeClassifier(**params, random_state=0)\n",
    "    \n",
    "    Test performance (macro average F1 score): 0.7732"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set 2: Feature Selection\n",
    "\n",
    "In this experiment set, we compare the performance of different sets of features selected/extracted using different feature selection/extraction methods.\n",
    "\n",
    "The list of methods used for feature selection/extraction are:\n",
    "\n",
    "- Variance Threshold\n",
    "- Correlation\n",
    "- Chi-Squared ($\\chi^2$)\n",
    "- Information Gain\n",
    "- PCA (Principal Component Analysis)\n",
    "- FA (Factor Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the list of machine learning algorithms used for evaluating the model performance on the feature subsets.\n",
    "\n",
    "- K-Nearest Neighbors: `n_neighbors=5` (default)\n",
    "- Decision Tree: `random_state=0`\n",
    "- Polynomial SVM (degree 2): `gamma='scale', max_iter=10000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 3 different estimators\n",
    "estimators = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"SVM\": SVC(kernel='poly', degree=2, gamma='scale', max_iter=10000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some feature selection methods such as *variance threshold* and *correlation* only measures numerical columns.\n",
    "\n",
    "Therefore, we define a helper function to transform a data frame such that the selected selected columns are converted to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #3: Convert all the specified `columns` in `df` \n",
    "# from categorical type to numerical type.\n",
    "def get_numeric_features(df, columns):\n",
    "    df_num = df.copy()\n",
    "    \n",
    "    # Convert columns to type: int\n",
    "    col_to_int = columns\n",
    "\n",
    "    for col in col_to_int:\n",
    "        df_num[col] = df_num[col].astype(int)\n",
    "    \n",
    "    return df_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical columns in the data frames of training and test features respectively into numerical columns, then store the new values in new variables as follows:\n",
    "- `x_train_num`: features of the training set, all columns are numerical\n",
    "- `x_test_num`: features of the test set, all columns are numerical\n",
    "\n",
    "**Note**: `x_train` and `x_test` are both Pandas' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5757 entries, 5452 to 2732\n",
      "Data columns (total 12 columns):\n",
      "size_bytes          5757 non-null int64\n",
      "price               5757 non-null float64\n",
      "rating_count_tot    5757 non-null int64\n",
      "rating_count_ver    5757 non-null int64\n",
      "user_rating_ver     5757 non-null float64\n",
      "ver                 5757 non-null int32\n",
      "cont_rating         5757 non-null int32\n",
      "prime_genre         5757 non-null int32\n",
      "sup_devices.num     5757 non-null int64\n",
      "ipadSc_urls.num     5757 non-null int64\n",
      "lang.num            5757 non-null int64\n",
      "vpp_lic             5757 non-null int64\n",
      "dtypes: float64(2), int32(3), int64(7)\n",
      "memory usage: 517.2 KB\n"
     ]
    }
   ],
   "source": [
    "columns = ['ver', 'cont_rating', 'prime_genre']\n",
    "x_train_num = get_numeric_features(x_train, columns=columns)\n",
    "x_test_num = get_numeric_features(x_test, columns=columns)\n",
    "x_train_num.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Variance Threshold \n",
    "\n",
    "Variance threshold: use `x_train_num` to obtain the variance of all values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size_bytes          1.387115e+17\n",
       "rating_count_tot    5.946792e+09\n",
       "rating_count_ver    1.727523e+07\n",
       "ver                 1.926676e+05\n",
       "lang.num            6.354421e+01\n",
       "price               3.789444e+01\n",
       "prime_genre         2.388685e+01\n",
       "sup_devices.num     1.434726e+01\n",
       "ipadSc_urls.num     3.967491e+00\n",
       "user_rating_ver     3.287716e+00\n",
       "cont_rating         7.888607e-01\n",
       "vpp_lic             7.072274e-03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the variance of each column\n",
    "x_train_num.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1**: Obtain test performance using all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7764\n",
      "f1_macro (Test Decision Tree) = 0.7732\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3328694504027031},\n",
       " 'Decision Tree': {'f1_macro': 0.7732013528151364},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1: All features\n",
    "train_and_evaluate(estimators, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop 4 columns with the least variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>298</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>649</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1115</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>2.99</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>725</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  price  rating_count_tot  rating_count_ver   ver  \\\n",
       "5452    79053824   0.00                14                 3   298   \n",
       "3788    12320768   0.00                 0                 0    29   \n",
       "4381   539088896   0.00                89                 2   649   \n",
       "3874   223020032   0.00                 0                 0  1115   \n",
       "3131    14583808   2.99               859                52   725   \n",
       "\n",
       "      prime_genre  sup_devices.num  lang.num  \n",
       "5452            7               38         1  \n",
       "3788            9               38         1  \n",
       "4381            7               38        11  \n",
       "3874            7               38         1  \n",
       "3131            8               13         1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define columns with Least variance\n",
    "col_drop = ['vpp_lic', 'cont_rating', 'user_rating_ver', 'ipadSc_urls.num']\n",
    "\n",
    "# Use 8 features with the highest variances\n",
    "# - Drop columns with least variances from x_train_norm and x_test_norm\n",
    "x_train_num.drop(col_drop, axis = 1, inplace = True)\n",
    "x_test_num.drop(col_drop, axis = 1, inplace = True)\n",
    "\n",
    "x_train_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2**: Obtain test performance using 8 features with higher variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.6608\n",
      "f1_macro (Test Decision Tree) = 0.6726\n",
      "[[979  16 107]\n",
      " [ 14 169   6]\n",
      " [110   4  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      1102\n",
      "           1       0.89      0.89      0.89       189\n",
      "           2       0.24      0.23      0.24       149\n",
      "\n",
      "    accuracy                           0.82      1440\n",
      "   macro avg       0.67      0.67      0.67      1440\n",
      "weighted avg       0.82      0.82      0.82      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3328694504027031},\n",
       " 'Decision Tree': {'f1_macro': 0.672617329760187},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: 8 features\n",
    "train_and_evaluate(estimators, x_train_num, x_test_num, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the variance of all values in each of the 8 remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size_bytes          1.387115e+17\n",
       "rating_count_tot    5.946792e+09\n",
       "rating_count_ver    1.727523e+07\n",
       "ver                 1.926676e+05\n",
       "lang.num            6.354421e+01\n",
       "price               3.789444e+01\n",
       "prime_genre         2.388685e+01\n",
       "sup_devices.num     1.434726e+01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the variance of each column\n",
    "x_train_num.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop another 4 columns with the least variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  rating_count_ver   ver\n",
       "5452    79053824                14                 3   298\n",
       "3788    12320768                 0                 0    29\n",
       "4381   539088896                89                 2   649\n",
       "3874   223020032                 0                 0  1115\n",
       "3131    14583808               859                52   725"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_drop = ['sup_devices.num', 'prime_genre', 'price', 'lang.num']\n",
    "\n",
    "x_train_num.drop(col_drop, axis=1, inplace=True)\n",
    "x_test_num.drop(col_drop, axis=1, inplace=True)\n",
    "\n",
    "x_train_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 3**: Obtain test performance using 4 features with higher variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.6591\n",
      "f1_macro (Test Decision Tree) = 0.6473\n",
      "[[980  15 107]\n",
      " [ 17 167   5]\n",
      " [121   4  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1102\n",
      "           1       0.90      0.88      0.89       189\n",
      "           2       0.18      0.16      0.17       149\n",
      "\n",
      "    accuracy                           0.81      1440\n",
      "   macro avg       0.65      0.64      0.65      1440\n",
      "weighted avg       0.81      0.81      0.81      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3328694504027031},\n",
       " 'Decision Tree': {'f1_macro': 0.6473235340603761},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3: 4 features\n",
    "train_and_evaluate(estimators, x_train_num, x_test_num, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical columns from the preprocessed data into numerical columns. This is done by defining a new copy of the original data frame - the data frame before splitting into training and test set.\n",
    "\n",
    "We want to compare the correlation of each column to the target column: `user_rating_label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "      <th>user_rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>size_bytes</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182392</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.086075</td>\n",
       "      <td>-0.139159</td>\n",
       "      <td>-0.044634</td>\n",
       "      <td>-0.134438</td>\n",
       "      <td>-0.118347</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>-0.150418</td>\n",
       "      <td>-0.078687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.182392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039044</td>\n",
       "      <td>-0.018012</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>-0.017413</td>\n",
       "      <td>-0.115361</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>-0.006713</td>\n",
       "      <td>-0.029942</td>\n",
       "      <td>-0.048999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_count_tot</th>\n",
       "      <td>0.004486</td>\n",
       "      <td>-0.039044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163645</td>\n",
       "      <td>0.088744</td>\n",
       "      <td>0.142502</td>\n",
       "      <td>-0.016398</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.137675</td>\n",
       "      <td>-0.000982</td>\n",
       "      <td>-0.064099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_count_ver</th>\n",
       "      <td>0.006337</td>\n",
       "      <td>-0.018012</td>\n",
       "      <td>0.163645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077840</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.016948</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>0.037951</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>-0.049083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating_ver</th>\n",
       "      <td>0.086075</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>0.088744</td>\n",
       "      <td>0.077840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>0.090602</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>-0.018901</td>\n",
       "      <td>0.275737</td>\n",
       "      <td>0.175580</td>\n",
       "      <td>0.050094</td>\n",
       "      <td>-0.519424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ver</th>\n",
       "      <td>-0.139159</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>0.142502</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.110565</td>\n",
       "      <td>0.274150</td>\n",
       "      <td>-0.102288</td>\n",
       "      <td>-0.070954</td>\n",
       "      <td>0.137482</td>\n",
       "      <td>0.031991</td>\n",
       "      <td>-0.041580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont_rating</th>\n",
       "      <td>-0.044634</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>-0.016398</td>\n",
       "      <td>-0.016948</td>\n",
       "      <td>0.090602</td>\n",
       "      <td>-0.110565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052295</td>\n",
       "      <td>-0.047829</td>\n",
       "      <td>0.084674</td>\n",
       "      <td>0.024418</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>-0.045117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prime_genre</th>\n",
       "      <td>-0.134438</td>\n",
       "      <td>-0.017413</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>0.274150</td>\n",
       "      <td>-0.052295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.073675</td>\n",
       "      <td>-0.198290</td>\n",
       "      <td>0.104579</td>\n",
       "      <td>-0.028522</td>\n",
       "      <td>0.038696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup_devices.num</th>\n",
       "      <td>-0.118347</td>\n",
       "      <td>-0.115361</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.037951</td>\n",
       "      <td>-0.018901</td>\n",
       "      <td>-0.102288</td>\n",
       "      <td>-0.047829</td>\n",
       "      <td>-0.073675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037728</td>\n",
       "      <td>-0.041681</td>\n",
       "      <td>-0.037109</td>\n",
       "      <td>-0.013138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.275737</td>\n",
       "      <td>-0.070954</td>\n",
       "      <td>0.084674</td>\n",
       "      <td>-0.198290</td>\n",
       "      <td>-0.037728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088378</td>\n",
       "      <td>0.071901</td>\n",
       "      <td>-0.228352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang.num</th>\n",
       "      <td>0.004614</td>\n",
       "      <td>-0.006713</td>\n",
       "      <td>0.137675</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>0.175580</td>\n",
       "      <td>0.137482</td>\n",
       "      <td>0.024418</td>\n",
       "      <td>0.104579</td>\n",
       "      <td>-0.041681</td>\n",
       "      <td>0.088378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032477</td>\n",
       "      <td>-0.139049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vpp_lic</th>\n",
       "      <td>-0.150418</td>\n",
       "      <td>-0.029942</td>\n",
       "      <td>-0.000982</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.050094</td>\n",
       "      <td>0.031991</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>-0.028522</td>\n",
       "      <td>-0.037109</td>\n",
       "      <td>0.071901</td>\n",
       "      <td>0.032477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_rating_label</th>\n",
       "      <td>-0.078687</td>\n",
       "      <td>-0.048999</td>\n",
       "      <td>-0.064099</td>\n",
       "      <td>-0.049083</td>\n",
       "      <td>-0.519424</td>\n",
       "      <td>-0.041580</td>\n",
       "      <td>-0.045117</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>-0.013138</td>\n",
       "      <td>-0.228352</td>\n",
       "      <td>-0.139049</td>\n",
       "      <td>-0.055559</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   size_bytes     price  rating_count_tot  rating_count_ver  \\\n",
       "size_bytes           1.000000  0.182392          0.004486          0.006337   \n",
       "price                0.182392  1.000000         -0.039044         -0.018012   \n",
       "rating_count_tot     0.004486 -0.039044          1.000000          0.163645   \n",
       "rating_count_ver     0.006337 -0.018012          0.163645          1.000000   \n",
       "user_rating_ver      0.086075  0.025173          0.088744          0.077840   \n",
       "ver                 -0.139159 -0.010842          0.142502         -0.000678   \n",
       "cont_rating         -0.044634  0.033551         -0.016398         -0.016948   \n",
       "prime_genre         -0.134438 -0.017413          0.039188          0.011090   \n",
       "sup_devices.num     -0.118347 -0.115361          0.008832          0.037951   \n",
       "ipadSc_urls.num      0.152697  0.066100          0.015734          0.024333   \n",
       "lang.num             0.004614 -0.006713          0.137675          0.013287   \n",
       "vpp_lic             -0.150418 -0.029942         -0.000982          0.006460   \n",
       "user_rating_label   -0.078687 -0.048999         -0.064099         -0.049083   \n",
       "\n",
       "                   user_rating_ver       ver  cont_rating  prime_genre  \\\n",
       "size_bytes                0.086075 -0.139159    -0.044634    -0.134438   \n",
       "price                     0.025173 -0.010842     0.033551    -0.017413   \n",
       "rating_count_tot          0.088744  0.142502    -0.016398     0.039188   \n",
       "rating_count_ver          0.077840 -0.000678    -0.016948     0.011090   \n",
       "user_rating_ver           1.000000 -0.003986     0.090602    -0.033246   \n",
       "ver                      -0.003986  1.000000    -0.110565     0.274150   \n",
       "cont_rating               0.090602 -0.110565     1.000000    -0.052295   \n",
       "prime_genre              -0.033246  0.274150    -0.052295     1.000000   \n",
       "sup_devices.num          -0.018901 -0.102288    -0.047829    -0.073675   \n",
       "ipadSc_urls.num           0.275737 -0.070954     0.084674    -0.198290   \n",
       "lang.num                  0.175580  0.137482     0.024418     0.104579   \n",
       "vpp_lic                   0.050094  0.031991     0.055412    -0.028522   \n",
       "user_rating_label        -0.519424 -0.041580    -0.045117     0.038696   \n",
       "\n",
       "                   sup_devices.num  ipadSc_urls.num  lang.num   vpp_lic  \\\n",
       "size_bytes               -0.118347         0.152697  0.004614 -0.150418   \n",
       "price                    -0.115361         0.066100 -0.006713 -0.029942   \n",
       "rating_count_tot          0.008832         0.015734  0.137675 -0.000982   \n",
       "rating_count_ver          0.037951         0.024333  0.013287  0.006460   \n",
       "user_rating_ver          -0.018901         0.275737  0.175580  0.050094   \n",
       "ver                      -0.102288        -0.070954  0.137482  0.031991   \n",
       "cont_rating              -0.047829         0.084674  0.024418  0.055412   \n",
       "prime_genre              -0.073675        -0.198290  0.104579 -0.028522   \n",
       "sup_devices.num           1.000000        -0.037728 -0.041681 -0.037109   \n",
       "ipadSc_urls.num          -0.037728         1.000000  0.088378  0.071901   \n",
       "lang.num                 -0.041681         0.088378  1.000000  0.032477   \n",
       "vpp_lic                  -0.037109         0.071901  0.032477  1.000000   \n",
       "user_rating_label        -0.013138        -0.228352 -0.139049 -0.055559   \n",
       "\n",
       "                   user_rating_label  \n",
       "size_bytes                 -0.078687  \n",
       "price                      -0.048999  \n",
       "rating_count_tot           -0.064099  \n",
       "rating_count_ver           -0.049083  \n",
       "user_rating_ver            -0.519424  \n",
       "ver                        -0.041580  \n",
       "cont_rating                -0.045117  \n",
       "prime_genre                 0.038696  \n",
       "sup_devices.num            -0.013138  \n",
       "ipadSc_urls.num            -0.228352  \n",
       "lang.num                   -0.139049  \n",
       "vpp_lic                    -0.055559  \n",
       "user_rating_label           1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define categorical columns\n",
    "columns = ['ver', 'cont_rating', 'prime_genre', 'user_rating_label']\n",
    "# Define target column\n",
    "col_target = 'user_rating_label'\n",
    "\n",
    "# Create new copy of df, then convert categorical columns into numerical.\n",
    "df_cor = df.copy()\n",
    "df_cor = get_numeric_features(df_cor, columns=columns)\n",
    "\n",
    "# Display correlation matrix\n",
    "df_cor.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to get the list of features which has correlation to the target column above a specified threshold value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #4\n",
    "def get_correlated_features(df, col_target, threshold):\n",
    "    # Generate correlation matrix\n",
    "    cor = df.corr()\n",
    "    \n",
    "    # Correlation with target\n",
    "    # Apply abs() to get the absolute value so no need to deal with negative correlations\n",
    "    cor_target = abs(cor[col_target])\n",
    "    \n",
    "    # Select highly correlated features, with threshold\n",
    "    relevant_features = cor_target[cor_target > threshold]\n",
    "    \n",
    "    # Get names of the features which are highly correlated to the target. \n",
    "    cols = [col for col in relevant_features.index if col.lower() != col_target.lower()]\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1**: Set parameter `threshold=0.04`: 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>2.99</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "5452    79053824   0.00                14                 3              2.5   \n",
       "3788    12320768   0.00                 0                 0              0.0   \n",
       "4381   539088896   0.00                89                 2              5.0   \n",
       "3874   223020032   0.00                 0                 0              0.0   \n",
       "3131    14583808   2.99               859                52              3.0   \n",
       "\n",
       "       ver  cont_rating  ipadSc_urls.num  lang.num  vpp_lic  \n",
       "5452   298            2                4         1        1  \n",
       "3788    29            2                5         1        1  \n",
       "4381   649            2                5        11        1  \n",
       "3874  1115            2                5         1        1  \n",
       "3131   725            2                0         1        1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1: Threshold = 0.04\n",
    "cols = get_correlated_features(df_cor, col_target, threshold=0.04)\n",
    "\n",
    "x_train_cor = x_train[cols]\n",
    "x_test_cor = x_test[cols]\n",
    "\n",
    "x_train_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7750\n",
      "f1_macro (Test Decision Tree) = 0.7636\n",
      "[[1025    9   68]\n",
      " [   4  180    5]\n",
      " [  80    8   61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1102\n",
      "           1       0.91      0.95      0.93       189\n",
      "           2       0.46      0.41      0.43       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.76      0.76      0.76      1440\n",
      "weighted avg       0.87      0.88      0.88      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3328694504027031},\n",
       " 'Decision Tree': {'f1_macro': 0.763640054624303},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using 10 features with correlation with target > 0.04\n",
    "train_and_evaluate(estimators, x_train_cor, x_test_cor, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2**: Set parameter `threshold=0.05`: 6 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  user_rating_ver  ipadSc_urls.num  \\\n",
       "5452    79053824                14              2.5                4   \n",
       "3788    12320768                 0              0.0                5   \n",
       "4381   539088896                89              5.0                5   \n",
       "3874   223020032                 0              0.0                5   \n",
       "3131    14583808               859              3.0                0   \n",
       "\n",
       "      lang.num  vpp_lic  \n",
       "5452         1        1  \n",
       "3788         1        1  \n",
       "4381        11        1  \n",
       "3874         1        1  \n",
       "3131         1        1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: threshold = 0.05\n",
    "cols = get_correlated_features(df_cor, col_target, threshold=0.05)\n",
    "\n",
    "x_train_cor = x_train[cols]\n",
    "x_test_cor = x_test[cols]\n",
    "\n",
    "x_train_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3268\n",
      "f1_macro (Test KNN) = 0.3300\n",
      "[[1062   30   10]\n",
      " [ 177   10    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.23      0.05      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.64      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7601\n",
      "f1_macro (Test Decision Tree) = 0.7525\n",
      "[[1021    5   76]\n",
      " [   4  178    7]\n",
      " [  93    1   55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1102\n",
      "           1       0.97      0.94      0.95       189\n",
      "           2       0.40      0.37      0.38       149\n",
      "\n",
      "    accuracy                           0.87      1440\n",
      "   macro avg       0.76      0.75      0.75      1440\n",
      "weighted avg       0.87      0.87      0.87      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3300277470104516},\n",
       " 'Decision Tree': {'f1_macro': 0.7525062245457197},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using 6 features with correlation with target > 0.05\n",
    "train_and_evaluate(estimators, x_train_cor, x_test_cor, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 3**: Set parameter `threshold=0.1`: 3 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_rating_ver  ipadSc_urls.num  lang.num\n",
       "5452              2.5                4         1\n",
       "3788              0.0                5         1\n",
       "4381              5.0                5        11\n",
       "3874              0.0                5         1\n",
       "3131              3.0                0         1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3: threshold = 0.1\n",
    "cols = get_correlated_features(df_cor, col_target, threshold=0.1)\n",
    "\n",
    "x_train_cor = x_train[cols]\n",
    "x_test_cor = x_test[cols]\n",
    "\n",
    "x_train_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.6846\n",
      "f1_macro (Test KNN) = 0.6373\n",
      "[[1014   46   42]\n",
      " [  74  113    2]\n",
      " [  86   15   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      1102\n",
      "           1       0.65      0.60      0.62       189\n",
      "           2       0.52      0.32      0.40       149\n",
      "\n",
      "    accuracy                           0.82      1440\n",
      "   macro avg       0.68      0.61      0.64      1440\n",
      "weighted avg       0.80      0.82      0.80      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7049\n",
      "f1_macro (Test Decision Tree) = 0.6856\n",
      "[[999  69  34]\n",
      " [ 17 169   3]\n",
      " [ 80  23  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1102\n",
      "           1       0.65      0.89      0.75       189\n",
      "           2       0.55      0.31      0.40       149\n",
      "\n",
      "    accuracy                           0.84      1440\n",
      "   macro avg       0.70      0.70      0.69      1440\n",
      "weighted avg       0.84      0.84      0.84      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.5566\n",
      "f1_macro (Test SVM) = 0.5455\n",
      "[[1013   89    0]\n",
      " [   9  180    0]\n",
      " [ 115   34    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      1102\n",
      "           1       0.59      0.95      0.73       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.83      1440\n",
      "   macro avg       0.50      0.62      0.55      1440\n",
      "weighted avg       0.76      0.83      0.79      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.6373222291657421},\n",
       " 'Decision Tree': {'f1_macro': 0.6855570081706696},\n",
       " 'SVM': {'f1_macro': 0.5455251872750975}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using 10 features with correlation with target > 0.1\n",
    "train_and_evaluate(estimators, x_train_cor, x_test_cor, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Chi-Squared ($\\chi^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to get the list of specified number of features based on Chi-squared ($\\chi^2$) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #5\n",
    "def get_chi2_features(X, Y, num_k=10):\n",
    "    # Create a selector\n",
    "    # Set k: we want top k features\n",
    "    selector = SelectKBest(chi2, k=num_k)\n",
    "    \n",
    "    x_new = selector.fit_transform(X, Y)\n",
    "    col_index = selector.get_support(indices=True)    # Get the index\n",
    "    \n",
    "    cols = X.columns[col_index]                       # Get the name of the feature/column\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1**: Set `num_k=10`: get the set of 10 best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>2.99</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "5452    79053824   0.00                14                 3              2.5   \n",
       "3788    12320768   0.00                 0                 0              0.0   \n",
       "4381   539088896   0.00                89                 2              5.0   \n",
       "3874   223020032   0.00                 0                 0              0.0   \n",
       "3131    14583808   2.99               859                52              3.0   \n",
       "\n",
       "       ver  prime_genre  sup_devices.num  ipadSc_urls.num  lang.num  \n",
       "5452   298            7               38                4         1  \n",
       "3788    29            9               38                5         1  \n",
       "4381   649            7               38                5        11  \n",
       "3874  1115            7               38                5         1  \n",
       "3131   725            8               13                0         1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = get_chi2_features(x_train, y_train, num_k=10)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7763\n",
      "f1_macro (Test Decision Tree) = 0.7881\n",
      "[[1036   15   51]\n",
      " [   5  182    2]\n",
      " [  78    4   67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1102\n",
      "           1       0.91      0.96      0.93       189\n",
      "           2       0.56      0.45      0.50       149\n",
      "\n",
      "    accuracy                           0.89      1440\n",
      "   macro avg       0.80      0.78      0.79      1440\n",
      "weighted avg       0.89      0.89      0.89      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3328694504027031},\n",
       " 'Decision Tree': {'f1_macro': 0.7881292331600224},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using top 10 features - chi2\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2**: Set `num_k=7`: get the set of 7 best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  rating_count_ver  user_rating_ver   ver  \\\n",
       "5452    79053824                14                 3              2.5   298   \n",
       "3788    12320768                 0                 0              0.0    29   \n",
       "4381   539088896                89                 2              5.0   649   \n",
       "3874   223020032                 0                 0              0.0  1115   \n",
       "3131    14583808               859                52              3.0   725   \n",
       "\n",
       "      ipadSc_urls.num  lang.num  \n",
       "5452                4         1  \n",
       "3788                5         1  \n",
       "4381                5        11  \n",
       "3874                5         1  \n",
       "3131                0         1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: k = 7\n",
    "cols = get_chi2_features(x_train, y_train, num_k=7)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7785\n",
      "f1_macro (Test Decision Tree) = 0.7581\n",
      "[[1030    7   65]\n",
      " [   4  180    5]\n",
      " [  86    7   56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1102\n",
      "           1       0.93      0.95      0.94       189\n",
      "           2       0.44      0.38      0.41       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.76      0.75      0.76      1440\n",
      "weighted avg       0.87      0.88      0.87      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3328694504027031},\n",
       " 'Decision Tree': {'f1_macro': 0.7581044057408352},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using top 7 features - chi2\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 3**: Set `num_k=4`: get the set of 4 best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  rating_count_tot  rating_count_ver   ver\n",
       "5452    79053824                14                 3   298\n",
       "3788    12320768                 0                 0    29\n",
       "4381   539088896                89                 2   649\n",
       "3874   223020032                 0                 0  1115\n",
       "3131    14583808               859                52   725"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3: k = 4\n",
    "cols = get_chi2_features(x_train, y_train, num_k=4)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.6591\n",
      "f1_macro (Test Decision Tree) = 0.6473\n",
      "[[980  15 107]\n",
      " [ 17 167   5]\n",
      " [121   4  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1102\n",
      "           1       0.90      0.88      0.89       189\n",
      "           2       0.18      0.16      0.17       149\n",
      "\n",
      "    accuracy                           0.81      1440\n",
      "   macro avg       0.65      0.64      0.65      1440\n",
      "weighted avg       0.81      0.81      0.81      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3328694504027031},\n",
       " 'Decision Tree': {'f1_macro': 0.6473235340603761},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using top 4 features - chi2\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function to get the list of specified number of features based on the information gain method.\n",
    "\n",
    "**Note**: The steps are similar to *Chi-squared*, the only difference is to replace `chi2` with `mutual_info_classif` as the value of the first parameter when defining `SelectKBest()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #6\n",
    "def get_ig_features(X, Y, num_k=10):\n",
    "    # Create a selector\n",
    "    # Setting k: we want top k features\n",
    "    selector = SelectKBest(mutual_info_classif, k=num_k)\n",
    "    \n",
    "    x_new = selector.fit_transform(X, Y)\n",
    "    col_index = selector.get_support(indices=True)\n",
    "    \n",
    "    cols = X.columns[col_index]\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1**: Set `num_k=10`: get the set of 10 best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>79053824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>12320768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>539088896</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>223020032</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14583808</td>\n",
       "      <td>2.99</td>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes  price  rating_count_tot  rating_count_ver  user_rating_ver  \\\n",
       "5452    79053824   0.00                14                 3              2.5   \n",
       "3788    12320768   0.00                 0                 0              0.0   \n",
       "4381   539088896   0.00                89                 2              5.0   \n",
       "3874   223020032   0.00                 0                 0              0.0   \n",
       "3131    14583808   2.99               859                52              3.0   \n",
       "\n",
       "       ver  prime_genre  sup_devices.num  ipadSc_urls.num  lang.num  \n",
       "5452   298            7               38                4         1  \n",
       "3788    29            9               38                5         1  \n",
       "4381   649            7               38                5        11  \n",
       "3874  1115            7               38                5         1  \n",
       "3131   725            8               13                0         1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1: k = 10\n",
    "cols = get_ig_features(x_train, y_train, num_k=10)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.3262\n",
      "f1_macro (Test KNN) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7763\n",
      "f1_macro (Test Decision Tree) = 0.7881\n",
      "[[1036   15   51]\n",
      " [   5  182    2]\n",
      " [  78    4   67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1102\n",
      "           1       0.91      0.96      0.93       189\n",
      "           2       0.56      0.45      0.50       149\n",
      "\n",
      "    accuracy                           0.89      1440\n",
      "   macro avg       0.80      0.78      0.79      1440\n",
      "weighted avg       0.89      0.89      0.89      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.3328694504027031},\n",
       " 'Decision Tree': {'f1_macro': 0.7881292331600224},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using top 10 features - information gain\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2**: Set `num_k=7`: get the set of 7 best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>298</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>649</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1115</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>725</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating_count_tot  rating_count_ver  user_rating_ver   ver  prime_genre  \\\n",
       "5452                14                 3              2.5   298            7   \n",
       "3788                 0                 0              0.0    29            9   \n",
       "4381                89                 2              5.0   649            7   \n",
       "3874                 0                 0              0.0  1115            7   \n",
       "3131               859                52              3.0   725            8   \n",
       "\n",
       "      ipadSc_urls.num  lang.num  \n",
       "5452                4         1  \n",
       "3788                5         1  \n",
       "4381                5        11  \n",
       "3874                5         1  \n",
       "3131                0         1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: k = 7\n",
    "cols = get_ig_features(x_train, y_train, num_k=7)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.6161\n",
      "f1_macro (Test KNN) = 0.6286\n",
      "[[1054   19   29]\n",
      " [  14  175    0]\n",
      " [ 134    8    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91      1102\n",
      "           1       0.87      0.93      0.90       189\n",
      "           2       0.19      0.05      0.08       149\n",
      "\n",
      "    accuracy                           0.86      1440\n",
      "   macro avg       0.65      0.64      0.63      1440\n",
      "weighted avg       0.80      0.86      0.83      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7691\n",
      "f1_macro (Test Decision Tree) = 0.7641\n",
      "[[1020   16   66]\n",
      " [   2  180    7]\n",
      " [  78    7   64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.89      0.95      0.92       189\n",
      "           2       0.47      0.43      0.45       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.76      0.77      0.76      1440\n",
      "weighted avg       0.87      0.88      0.88      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.628582298730956},\n",
       " 'Decision Tree': {'f1_macro': 0.7641167707341315},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using top 7 features - information gain\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 3**: Set `num_k=4`: get the set of 4 best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>lang.num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>859</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating_count_tot  rating_count_ver  user_rating_ver  lang.num\n",
       "5452                14                 3              2.5         1\n",
       "3788                 0                 0              0.0         1\n",
       "4381                89                 2              5.0        11\n",
       "3874                 0                 0              0.0         1\n",
       "3131               859                52              3.0         1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 3: k = 4\n",
    "cols = get_ig_features(x_train, y_train, num_k=4)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_chi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.6900\n",
      "f1_macro (Test KNN) = 0.6653\n",
      "[[1082    0   20]\n",
      " [   9  175    5]\n",
      " [ 138    1   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1102\n",
      "           1       0.99      0.93      0.96       189\n",
      "           2       0.29      0.07      0.11       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.72      0.66      0.67      1440\n",
      "weighted avg       0.83      0.88      0.85      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7766\n",
      "f1_macro (Test Decision Tree) = 0.7565\n",
      "[[1024    2   76]\n",
      " [   5  183    1]\n",
      " [  92    4   53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1102\n",
      "           1       0.97      0.97      0.97       189\n",
      "           2       0.41      0.36      0.38       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.76      0.75      0.76      1440\n",
      "weighted avg       0.87      0.88      0.87      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.6653188967066276},\n",
       " 'Decision Tree': {'f1_macro': 0.7564866121742183},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluating using top 4 features - information gain\n",
    "train_and_evaluate(estimators, x_train_chi2, x_test_chi2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both PCA and FA are feature extraction methods. To ensure that all the values are on a same scale, the numeric features are used, and these features are normalized before feature extraction methods are applied.\n",
    "\n",
    "Define a helper function to normalize the values in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #7\n",
    "def normalize_features(df):\n",
    "    # Names of the features\n",
    "    names = df.columns\n",
    "    \n",
    "    # Create the Normalizer object\n",
    "    normalizer = preprocessing.Normalizer()\n",
    "    df_norm = normalizer.fit_transform(df)\n",
    "    df_norm = pd.DataFrame(df_norm, columns=names)\n",
    "    \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate PCA for the normalized features (both training and test, separately). Specify 3 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-5.789039e-06</td>\n",
       "      <td>-0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-5.936699e-06</td>\n",
       "      <td>-0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-6.059672e-06</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-5.713223e-06</td>\n",
       "      <td>-0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000099</td>\n",
       "      <td>8.565898e-07</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1           PC2       PC3\n",
       "0 -0.000158 -5.789039e-06 -0.000009\n",
       "1 -0.000158 -5.936699e-06 -0.000010\n",
       "2 -0.000158 -6.059672e-06 -0.000011\n",
       "3 -0.000158 -5.713223e-06 -0.000007\n",
       "4 -0.000099  8.565898e-07  0.000037"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "x_train_norm = normalize_features(x_train)\n",
    "x_test_norm = normalize_features(x_test)\n",
    "\n",
    "# Define PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(x_train_norm)\n",
    "\n",
    "# Project training and test features seperately into 3D space (n_components=3)\n",
    "train_pca = pca.transform(x_train_norm)\n",
    "test_pca = pca.transform(x_test_norm)\n",
    "\n",
    "# Define column names for the first 3 principal components\n",
    "col_pca = ['PC1', 'PC2', 'PC3']\n",
    "\n",
    "# Create new data frame to store value of transformed training features for viewing\n",
    "principalDf = pd.DataFrame(data=train_pca, columns=col_pca)\n",
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate the model performance using training and test features after projection for different number of principal components (1, 2 and 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components: 1\n",
      "---\n",
      "f1_macro (Validation KNN) = 0.5307\n",
      "f1_macro (Test KNN) = 0.5241\n",
      "[[1042   51    9]\n",
      " [  58  129    2]\n",
      " [ 140    9    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      1102\n",
      "           1       0.68      0.68      0.68       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.81      1440\n",
      "   macro avg       0.51      0.54      0.52      1440\n",
      "weighted avg       0.73      0.81      0.77      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.2869\n",
      "f1_macro (Test Decision Tree) = 0.2869\n",
      "[[1088    1   13]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.25      0.33      0.29      1440\n",
      "weighted avg       0.58      0.76      0.66      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2909\n",
      "f1_macro (Test SVM) = 0.2934\n",
      "[[1101    0    1]\n",
      " [ 189    0    0]\n",
      " [ 148    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.50      0.01      0.01       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.42      0.34      0.29      1440\n",
      "weighted avg       0.64      0.77      0.66      1440\n",
      "\n",
      "\n",
      "Number of principal components: 2\n",
      "---\n",
      "f1_macro (Validation KNN) = 0.6254\n",
      "f1_macro (Test KNN) = 0.6297\n",
      "[[1079   12   11]\n",
      " [  21  168    0]\n",
      " [ 143    1    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      1102\n",
      "           1       0.93      0.89      0.91       189\n",
      "           2       0.31      0.03      0.06       149\n",
      "\n",
      "    accuracy                           0.87      1440\n",
      "   macro avg       0.70      0.63      0.63      1440\n",
      "weighted avg       0.82      0.87      0.83      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.3299\n",
      "f1_macro (Test Decision Tree) = 0.3138\n",
      "[[1057    1   44]\n",
      " [ 185    3    1]\n",
      " [ 142    1    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85      1102\n",
      "           1       0.60      0.02      0.03       189\n",
      "           2       0.12      0.04      0.06       149\n",
      "\n",
      "    accuracy                           0.74      1440\n",
      "   macro avg       0.49      0.34      0.31      1440\n",
      "weighted avg       0.68      0.74      0.66      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2878\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "Number of principal components: 3\n",
      "---\n",
      "f1_macro (Validation KNN) = 0.5867\n",
      "f1_macro (Test KNN) = 0.6043\n",
      "[[1047   45   10]\n",
      " [  18  170    1]\n",
      " [ 130   12    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1102\n",
      "           1       0.75      0.90      0.82       189\n",
      "           2       0.39      0.05      0.08       149\n",
      "\n",
      "    accuracy                           0.85      1440\n",
      "   macro avg       0.67      0.63      0.60      1440\n",
      "weighted avg       0.81      0.85      0.81      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.4364\n",
      "f1_macro (Test Decision Tree) = 0.3983\n",
      "[[1040   12   50]\n",
      " [ 161   25    3]\n",
      " [ 136    0   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      1102\n",
      "           1       0.68      0.13      0.22       189\n",
      "           2       0.20      0.09      0.12       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.55      0.39      0.40      1440\n",
      "weighted avg       0.70      0.75      0.69      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num_pc in range(1, principalDf.shape[1]+1):\n",
    "    print(\"Number of principal components: {}\".format(num_pc))\n",
    "    print(\"---\")\n",
    "    \n",
    "    df_pca_train = pd.DataFrame(data = train_pca[:,:num_pc], columns = col_pca[:num_pc])\n",
    "    df_pca_test = pd.DataFrame(data = test_pca[:,:num_pc], columns = col_pca[:num_pc])\n",
    "  \n",
    "    train_and_evaluate(estimators, df_pca_train, df_pca_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate FA for the normalized features (both training and test, separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.729537e-06</td>\n",
       "      <td>1.096675e-07</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.479318e-07</td>\n",
       "      <td>3.603370e-05</td>\n",
       "      <td>1.208544e-07</td>\n",
       "      <td>7.572699e-07</td>\n",
       "      <td>2.383384e-06</td>\n",
       "      <td>1.417095e-07</td>\n",
       "      <td>1.969103e-07</td>\n",
       "      <td>6.244423e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.850639e-06</td>\n",
       "      <td>-2.720284e-08</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-2.374795e-08</td>\n",
       "      <td>-6.612498e-06</td>\n",
       "      <td>-2.539387e-08</td>\n",
       "      <td>-2.045319e-07</td>\n",
       "      <td>-5.409411e-07</td>\n",
       "      <td>-2.928681e-08</td>\n",
       "      <td>-3.355409e-08</td>\n",
       "      <td>-1.430328e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.488976e-07</td>\n",
       "      <td>-5.203757e-10</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.284545e-09</td>\n",
       "      <td>-3.603155e-07</td>\n",
       "      <td>-3.209692e-10</td>\n",
       "      <td>-4.269422e-09</td>\n",
       "      <td>2.429558e-10</td>\n",
       "      <td>8.931404e-10</td>\n",
       "      <td>5.979289e-11</td>\n",
       "      <td>-8.504671e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size_bytes         price  rating_count_tot  rating_count_ver  \\\n",
       "0  -1.729537e-06  1.096675e-07          0.000233          0.000008   \n",
       "1  -5.850639e-06 -2.720284e-08          0.000716          0.000014   \n",
       "2   2.488976e-07 -5.203757e-10         -0.000002          0.000011   \n",
       "3   0.000000e+00 -0.000000e+00          0.000000          0.000000   \n",
       "4   0.000000e+00  0.000000e+00          0.000000         -0.000000   \n",
       "5  -0.000000e+00  0.000000e+00         -0.000000          0.000000   \n",
       "6  -0.000000e+00  0.000000e+00         -0.000000          0.000000   \n",
       "7   0.000000e+00  0.000000e+00          0.000000         -0.000000   \n",
       "8  -0.000000e+00  0.000000e+00         -0.000000         -0.000000   \n",
       "9   0.000000e+00  0.000000e+00          0.000000          0.000000   \n",
       "10 -0.000000e+00  0.000000e+00          0.000000         -0.000000   \n",
       "11 -0.000000e+00  0.000000e+00         -0.000000         -0.000000   \n",
       "\n",
       "    user_rating_ver           ver   cont_rating   prime_genre  \\\n",
       "0      1.479318e-07  3.603370e-05  1.208544e-07  7.572699e-07   \n",
       "1     -2.374795e-08 -6.612498e-06 -2.539387e-08 -2.045319e-07   \n",
       "2      2.284545e-09 -3.603155e-07 -3.209692e-10 -4.269422e-09   \n",
       "3     -0.000000e+00  0.000000e+00 -0.000000e+00 -0.000000e+00   \n",
       "4      0.000000e+00 -0.000000e+00  0.000000e+00 -0.000000e+00   \n",
       "5      0.000000e+00  0.000000e+00  0.000000e+00 -0.000000e+00   \n",
       "6     -0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00   \n",
       "7     -0.000000e+00 -0.000000e+00  0.000000e+00 -0.000000e+00   \n",
       "8      0.000000e+00 -0.000000e+00 -0.000000e+00  0.000000e+00   \n",
       "9      0.000000e+00 -0.000000e+00  0.000000e+00 -0.000000e+00   \n",
       "10    -0.000000e+00  0.000000e+00 -0.000000e+00  0.000000e+00   \n",
       "11     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "    sup_devices.num  ipadSc_urls.num      lang.num       vpp_lic  \n",
       "0      2.383384e-06     1.417095e-07  1.969103e-07  6.244423e-08  \n",
       "1     -5.409411e-07    -2.928681e-08 -3.355409e-08 -1.430328e-08  \n",
       "2      2.429558e-10     8.931404e-10  5.979289e-11 -8.504671e-11  \n",
       "3     -0.000000e+00    -0.000000e+00 -0.000000e+00 -0.000000e+00  \n",
       "4      0.000000e+00     0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "5      0.000000e+00     0.000000e+00 -0.000000e+00  0.000000e+00  \n",
       "6     -0.000000e+00     0.000000e+00  0.000000e+00 -0.000000e+00  \n",
       "7     -0.000000e+00     0.000000e+00 -0.000000e+00  0.000000e+00  \n",
       "8     -0.000000e+00     0.000000e+00 -0.000000e+00  0.000000e+00  \n",
       "9     -0.000000e+00    -0.000000e+00  0.000000e+00 -0.000000e+00  \n",
       "10     0.000000e+00     0.000000e+00  0.000000e+00 -0.000000e+00  \n",
       "11     0.000000e+00     0.000000e+00  0.000000e+00 -0.000000e+00  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a FactorAnalysis object.\n",
    "factor = FactorAnalysis(n_components = None, random_state = 101).fit(x_train_norm)\n",
    "\n",
    "# Convert the factor loadings into a data frame\n",
    "factor_df = pd.DataFrame(factor.components_, columns = x_train.columns)\n",
    "factor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor 1</th>\n",
       "      <th>Factor 2</th>\n",
       "      <th>Factor 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.202359</td>\n",
       "      <td>-0.055045</td>\n",
       "      <td>-0.016727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.290771</td>\n",
       "      <td>-0.208415</td>\n",
       "      <td>-0.018769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.292407</td>\n",
       "      <td>-0.028512</td>\n",
       "      <td>-0.015958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.252034</td>\n",
       "      <td>-0.039544</td>\n",
       "      <td>-0.017033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243263</td>\n",
       "      <td>-0.141611</td>\n",
       "      <td>-0.019807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Factor 1  Factor 2  Factor 3\n",
       "0 -0.202359 -0.055045 -0.016727\n",
       "1  0.290771 -0.208415 -0.018769\n",
       "2 -0.292407 -0.028512 -0.015958\n",
       "3 -0.252034 -0.039544 -0.017033\n",
       "4  0.243263 -0.141611 -0.019807"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Factor 1', 'Factor 2', 'Factor 3']\n",
    "\n",
    "x_train_factor = factor.fit_transform(x_train_norm)\n",
    "x_test_factor = factor.fit_transform(x_test_norm)\n",
    "\n",
    "x_train_factor = pd.DataFrame(data = x_train_factor[:,:3], columns = columns)\n",
    "x_test_factor = pd.DataFrame(data = x_test_factor[:,:3], columns = columns)\n",
    "\n",
    "x_train_factor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate the model performance using first 3 factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation KNN) = 0.4289\n",
      "f1_macro (Test KNN) = 0.2213\n",
      "[[413 688   1]\n",
      " [104  85   0]\n",
      " [ 84  64   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.37      0.49      1102\n",
      "           1       0.10      0.45      0.17       189\n",
      "           2       0.50      0.01      0.01       149\n",
      "\n",
      "    accuracy                           0.35      1440\n",
      "   macro avg       0.43      0.28      0.22      1440\n",
      "weighted avg       0.59      0.35      0.39      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.4705\n",
      "f1_macro (Test Decision Tree) = 0.2071\n",
      "[[414   0 688]\n",
      " [109   0  80]\n",
      " [ 82   0  67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.38      0.49      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.08      0.45      0.14       149\n",
      "\n",
      "    accuracy                           0.33      1440\n",
      "   macro avg       0.25      0.28      0.21      1440\n",
      "weighted avg       0.53      0.33      0.39      1440\n",
      "\n",
      "\n",
      "f1_macro (Validation SVM) = 0.2881\n",
      "f1_macro (Test SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': {'f1_macro': 0.22132115495585844},\n",
       " 'Decision Tree': {'f1_macro': 0.20708012440405596},\n",
       " 'SVM': {'f1_macro': 0.2890112772095463}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate(estimators, x_train_factor, x_test_factor, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Set 2 Summary\n",
    "\n",
    "The best model from this experiment is the **Decision Tree** classifier with **the set of 10 best features** obtained using **Chi-squared**, i.e.:\n",
    "\n",
    "    Classifier: DecisionTreeClassifier(random_state=0)\n",
    "    \n",
    "    Feature subset: size_bytes, price, rating_count_tot, rating_count_ver, user_rating_ver, ver, prime_genre, sup_devices.num, ipadSc_urls.num, lang.num\n",
    "    \n",
    "    Test performance (macro average F1 score): 0.7881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set 3: Ensemble Learning\n",
    "\n",
    "In this experiment set, we compare the performance of different ensemble learning methods on test set for different machine learning algorithms.\n",
    "\n",
    "The list of ensemble learning methods used are:\n",
    "\n",
    "- Bagging: implemented using sklearn's `BaggingClassifier`\n",
    "- Boosting: implemented using sklearn's `AdaBoostClassifier`\n",
    "- Voting: implemented using sklearn's `VotingClassifier`\n",
    "\n",
    "The following are the machine learning algorithms specified as the base estimators for different ensemble learning methods:\n",
    "\n",
    "- K-Nearest Neighbors\n",
    "- Decision Tree: `random_state=0` (to control the output - to ensure that the result is always reproducible)\n",
    "- Linear SVM: `max_iter=400` (stopping criteria - to speed up the training and evaluation process)\n",
    "- Polynomial SVM: `max_iter=400`\n",
    "- RBF SVM: `max_iter=400`\n",
    "- Sigmoid SVM: `max_iter=400`\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Default Classifiers\n",
    "\n",
    "We start with a few selected classifiers with their respective default parameters without ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_clf_default = {\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(), \n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"Linear SVM\": SVC(kernel='linear', max_iter=400), \n",
    "    \"Polynomial SVM\": SVC(kernel='poly', max_iter=400), \n",
    "    \"RBF SVM\": SVC(kernel='rbf', max_iter=400), \n",
    "    \"Sigmoid SVM\": SVC(kernel='sigmoid', max_iter=400),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `clf_index` from 0 - 6, each corresponding to the default classifier defined in `dict_clf_default`. \n",
    "\n",
    "Helper function `train_and_evaluate()` is called to test the model test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Decision Tree) = 0.7764\n",
      "f1_macro (Test Decision Tree) = 0.7732\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'f1_macro': 0.7732013528151364}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify one classifier\n",
    "clf_index = 1\n",
    "\n",
    "estimator_name = list(dict_clf_default.keys())[clf_index]\n",
    "estimator = {estimator_name: dict_clf_default[estimator_name]}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the test performance of different models by using a `for` loop.\n",
    "\n",
    "First, initialize two list variables: `list_clf` and `list_score`. These two lists are used to store list of classifier names and model test performance respectively. These values are used to generate a CSV file and bar plot respectively.\n",
    "\n",
    "Then, a horizontal barplot is generated to visualize the test performance by using the function `matplotlib.pyplot.barh()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation K-Nearest Neighbors) = 0.3262\n",
      "f1_macro (Test K-Nearest Neighbors) = 0.3329\n",
      "[[1062   30   10]\n",
      " [ 176   11    2]\n",
      " [ 141    4    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.42      0.35      0.33      1440\n",
      "weighted avg       0.65      0.75      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.7764\n",
      "f1_macro (Test Decision Tree) = 0.7732\n",
      "[[1025   15   62]\n",
      " [   4  180    5]\n",
      " [  77    6   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.50      0.44      0.47       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.77      0.78      0.77      1440\n",
      "weighted avg       0.88      0.88      0.88      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Linear SVM) = 0.2238\n",
      "f1_macro (Test Linear SVM) = 0.2900\n",
      "[[1020   21   61]\n",
      " [ 184    1    4]\n",
      " [ 143    3    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.83      1102\n",
      "           1       0.04      0.01      0.01       189\n",
      "           2       0.04      0.02      0.03       149\n",
      "\n",
      "    accuracy                           0.71      1440\n",
      "   macro avg       0.28      0.32      0.29      1440\n",
      "weighted avg       0.59      0.71      0.64      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Polynomial SVM) = 0.1641\n",
      "f1_macro (Test Polynomial SVM) = 0.0770\n",
      "[[   0 1102    0]\n",
      " [   1  188    0]\n",
      " [   0  149    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1102\n",
      "           1       0.13      0.99      0.23       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.13      1440\n",
      "   macro avg       0.04      0.33      0.08      1440\n",
      "weighted avg       0.02      0.13      0.03      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation RBF SVM) = 0.1328\n",
      "f1_macro (Test RBF SVM) = 0.1285\n",
      "[[115  16 971]\n",
      " [  6   1 182]\n",
      " [  8   5 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.10      0.19      1102\n",
      "           1       0.05      0.01      0.01       189\n",
      "           2       0.11      0.91      0.19       149\n",
      "\n",
      "    accuracy                           0.17      1440\n",
      "   macro avg       0.35      0.34      0.13      1440\n",
      "weighted avg       0.70      0.17      0.16      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Sigmoid SVM) = 0.1841\n",
      "f1_macro (Test Sigmoid SVM) = 0.1902\n",
      "[[265   0 837]\n",
      " [ 24   0 165]\n",
      " [ 24   0 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.24      0.37      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.11      0.84      0.20       149\n",
      "\n",
      "    accuracy                           0.27      1440\n",
      "   macro avg       0.32      0.36      0.19      1440\n",
      "weighted avg       0.66      0.27      0.31      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Logistic Regression) = 0.2881\n",
      "f1_macro (Test Logistic Regression) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAGJCAYAAADv1AnGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdebgkVX3/8ffHAVGUVcBMcBkXXKLoqAOKccElBsEEjSgoKhgVjYrR/IziEkWNBuMuxgVccMUNwQUVFAUXRBlgYADFjUFRlB1EEFm+vz/qNPQ0997qO3Nn7mXu+/U897ndp05VfU9Vd/W3z6mqTlUhSZIkTeUWsx2AJEmS5j6TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJpnKeS7J2k2t89Jpi+49D0x87QOhe15e29CvMem+TYKaYfMhTvVH87rkYTBuvaP8mjx6y798j6/5Tk1CQvTrLe6sYytJ7bJPlkkvPbet49U8ueb5IcmOSrQ88XDe2/fSaof5u2XyvJf6/daFfdBK/N4b/HDtV7S5Kjk1y0qu/fm5Mkt05yXpKnzHYsAxPsqz8nWZHk8CRPTXKLkfoTHmuTvDrJb5Jcm2RZK/ubJF9JcnGb56VrsWljSbJpO+4+cJrzPT7J19px8Zokf2xtfdJQnf2TzMq9B9vn1oqRsnsl+U6Sy9v+eOJsxjhqxj60dLP1J+CZwH+NlD+rTdtorUe0at4EfHDo+XOB5wAPA64bKj9zBtb1euDNwHemMc9TgHOBjdvjA4GtgNfNQDwALwKeBvwr8HPgvBla7ryS5G7A84GHTjB58F45aKT8ycCcOKCvosFrc9jw+2RfYBnwNbrjwjqtqq5K8r/A/yQ5oqqume2Yhgz21QbAnYBdgEOBfZL8U1Vd1eqdB+wA/GowY5Lt6Y5bbwOOoHs9Q3cMeiSwd5tvxZpuxCrYlO64ey5w8jgzJHkH8B/AF4EXA38Abg/8E/D5JEuq6tQ1E+7Y3gS8Z6TsncBdgacClwJnAUuBb67d0CZm0qgvAc9I8rpqd3pPcmu6D8LD6A4kc15V/YqVD5A7tYc/rqprZyeqlSyrql+2x0cnuTvwUlYzaUyyQVVdDdwb+H1VfWI14xxd7nzzUuDUqlo6wbQvAc9KcpeqOnuo/FnMwntlBvfR8GtzIptU1fXtNXuzTBpXYVsdAhwAPAn4/BoJatWM7qtPJvkC8AXgf+kSfFpbTxiZ997t/wer6tcj5adW1eEzEeBcOHYkeQZdwvjyqnrHyOQvJHkPcMnaj2xl7XNr1L2B71XVcJJ4CTf9YrdKkqwPXFur+MsuDk/rk8Cd6XrkBp4ELKD7ILyJJM9oQ6x/SXJhGxZdOFJnwyTvb0NaVyT5CnCHSZb3yCTHtCG+Pyc5Ksl9Z6Z5K61nvSSvSvKzJFcn+X2SdyS51UidNyX51VD7fpDkYW364I32mqGhov1XIZwTgY2SbNWWe/82bHJJkquS/DDJw0fiPyTJuUl2SHJ8kquA/20x7Q3cMSPD8Enu2YawLm3LPWEooR4sd/82z33btr+C9kHZyv87yf9Lck7bP0cm2ar9fT7JZUl+m+SVI8vdMsmHkvw8yZWtzmeSbD3J+rdpy76iret1uemw25btdfXbtg9/215/GwzV6d2WE2nLeAbwmUmq/AD4daszmOcOwKOAmyTr47Z/KObD2/vlqiRnJXnV0PRj2+vwn5KckuRq4IVt2vZJvt2225/be2n7vvaOq6qun4nlJPn3JD9t7bskydIMDRO2Ok9q++uKdMNzP0nyz0PTN07yvvbevbptp5clyVCdwak1/5Lk4CQXAH8cmv68rHz8+kiSzUfafAlwFN2IxThtG+eYuCLJp5Ls0bbDn9s2eNhkyx1HVR0GfBl4XpIN27pWGp5Od2rPIW2WX7Vph6Q7duwIPDw3HjsWtXnukuTTSS5o23rZBPtrqmPHhknemuTsJH9t/18z/J4e2lf/3PbrhW19n0qy6aAtwOBL2sFDce49xWZ5NXD6BAnjYJudVFW/mWzmdKcP/SjdkP2l6Y6bu4zUmfKzotV5enu/XpHuOLk8yfOHpt8wPD3YFsAi4JmDdg5v5wnW3/d5NngdvDDJ/yb5PXA1sGm60xI+PvReOi/dUP5WU2xXk0ZxDvA9umG3gWcBhwNXjFZOd07XJ4GfAv8C7Af8I3BcktsOVf0Q3QH3na3eWUzwYdzeiMe0dT0DeDrdkPj3k9xxNds26lPAa1scuwD/QzeE/emhOq8EXga8l65dz27xDT5Udmj/D2mPdwA+vAqx3IVu2PyKdOfpHN/W8Ty6Xt6LgG8nedDIfJsAn6Ubknp8a8sOdB9wfxiK6eQkf0uX6NyfbnhmMNxxZJLHTxDTl4HjgH8G3jVU/kzg0XRJyr7Aw+mSpMOB01q8XwcOSLLz0HybA38BXgXsBPwnsA3ww+ED25DD6Yb8n0g3fPYGYK/BxCSbte20O93ramfgFcD6wC1bnelsy1EPoRsG+/4UdT7Fyu+VZ9D1ABw7Qd2x2p8uwfsRcDe6194urX2jX7LuQfe6PJDutXlMkvvR7bPN6L44PIvuFIjjkty/p70DC9oH0OBvwZjzjS3JnsA76F63OwN70g0bbj5UZ1+63tzz6fb7U+heE4va9FsAR9K9J99BN8z4Tbpt9eYJVnsgELr9tXdbxgHA+4Fv073O/5Nu33xjgnZ/D3jkJK/V4baNe0yE7r3z/+hOB9qd7sv51wYJ0mr4Ot2Q9ZJJpr+Q7nhHi3EHuuHeHejew6dw47HjvHbs/THdseNldNvqZOCwDCXxQ1Y6dqQ7X3uQdL+H7lj1Ybp2v22C+d9Dd4rH04E30r1vB8O257WYaW0YxHnkRA1tx717A1+daPqYFrV4n0K3n5bS7afh4+aUnxUtefwU3XZ5YlvWwXTHmImcTNeuC+j256Cdkxnn82zgNXTHj33oOoX+Qvea3YHuPfAPwEvojmUbTrFOqCr/5uEf3UG0gLvTnQd3CXArYCFwbXsR7djqPLbNs4DuG/t3R5b1sFbvJe35PekSov1G6n2g1dt7qOyXwDEj9TYGLgTePVR2LHDsNNq3f1vXeu35w9vzZ43U27OVL27PvwZ8qWfZBfz3NLfzPelOB9mM7py564AjWp1j6D5wbjk034JWdsRQ2SFtWbtOsJ5PAStGyt7e9uXdR5Z7FnDyBNvq3ydp688H27GVvbOVv3aobD26D/uPTbEtFgB3bPM+aYL1P3uk/nLg6KHnb2zb7QFTrGOsbTnJvK8Erh+et5UvavE9l+5cowIe0qadAbx5nNfFFO3/HvBbYMMp5j22xbZ4pPyLdF8ENh15/1w8xut48Noc/fvBJPXvzsj7dxrvx/cNv+YmmL4x3Tl2k8YMPGGi9dN9uF8NbNGe79jqHT7BfrwOeN1I+d+3+k8cKX9MK39ozz7tPSa2shV0x9nNhsqWtHpPH3Nf3X2S6f/Ypu8+8prde6jOc1vZopF5f8DIsRX4CF3ycruR8m/RDZFPeeygS9QLeMRI+WuAvwJbjeyrj0/wevkLkNH34BivtQe3us8f87W5P1BTTL8F3fHtaODLQ+VTflYALwcu7ln3Idz0uH0ucMhUMTL+59lgu5082JZDda8Yfn2O+2dPo6A7H2YDum/ue9L1WB0zQb170l28sdI3mar6AV2P5SNb0YPp3mij5wJ9dvhJkm3oelc+PdzTAVxJ1/PyiNVo06id6A5Wh42s6+g2fbCuE4Gdk7w5ycOS3HKG1v8z4Bq6D/P3023Df013/ugj6fbB9UNxha43ZHQbXEt3sBrHI4ATaugcqKq6jq63Z3GSjUfqT3ZO07dq5fNCf9b+HzW03GvpvgCs1Duc5N/SDdtd0WIfDAndc4L1jPYcnE53sv/A44ATq+qUiYJchW056m+By6vqr5NVqO5csB/SDR8tAf6OCYamh2Kasv3phhP/Hvh0VV3ZE9+Kqlo2UvYI4GtVdelQjJcDX+HG92OfJwHbDf09Z8z5puNEutfcgUke29o97KHAbbnpRUbDHkGXOB86Uv4pup7m0V6Z0dfzP9Adl0aPNz8GLuemr48L2v+/nSKmcY+JAz+qbuh7YHn7fydWz2B4vlZzOQM70fV2XTayrY4C7j/GsWMnuvYfP8Hxdn26Xv1ho+/95XSfSbefgbZMW5IHtaHaP9K9b6+he/0MH7f6PitOBDZLN9T+hBnoTR427ufZwBHVMsWR+P4z3Wkj2yY3nuIxFZNGUVV/ohsOfCbd8Nana+LzmAZDSRNdmfuHoemDc3n+OFJn9Png3ImP0L0ph/+eANxuzCaMYyu6D5YrRtZzfps+WNdb6IZt/plumPKiJB9LssVqrn/wwXwv4DZV9ayquphumy2gG7YZ3QYvpjvoDL9Pz2+J3zg2Z/J9Fbpez2GTXXE9esL4X6coHx523ZcbhwL/BdieGz8sJhryu3jk+dUj9W7H1CeDT3dbjrpVW2efT9ANWT0X+ElVnTVRpTHbvxndcXick9wn2j9T7ePR/TuZ06tq6dDfhO1ZTZ8A/o3uC+VRwMVJvpR2/hw3vv/69u/FddOLLP4wNH3Y6HYZHG9+yU1fHxtz0+PN4ErkW/fENNG6BnGNxrTSa3yoLVMOgY9h8GVtpu6asBXdZ8HodhoMLY9uq4m29Z0nmP8nk8w/0XsfVm27/Lb9v/MqzEsbmh8MM+9L94VmO7pTIYbjmfKzoqqOoxuSviNdUn1BunOP77cqcY0Y9/NsYKLXxe50Xy5fQXeKwu8ywXnko7x6WgOfoPu2dwu6W7dMZPDG/psJpv0N3XkfcOML9PZ0Fw4w9HzYRe3/q+g+WEdN2uOzCi6iG+6Y7IKI3wNUd3uNtwJvTfI3dMnrO+nO89h9NdZ/ek18heqldL0n/8ckPVYjCfx0ehIuZvJ9Vdz0QD1TvRQDe9CdevD/BgVJ7rIay7sQuMlFJEOmuy1HXcR4idbn6c63eh7deUCTGaf9l7SYp2rXwET7Z6p9PLp/Z03r5fgQ8KF2burj6M5L/BxdInlhq7o1XQ/zRC4GNk9yy5He4EH7LxqpP7q9BtMfx8RXzo7OP0j4LhytOBLTcAzDho+Ja9oudMe3k2ZoeRfRJUJvnWT670eeT7Stz6Y7j3oiK1Y5sh5V9fskP6UbOXv1KixiJ7pzx59aVTd8iRntHR/ns6Kqvgh8sZ3bumOr/80kd+g5FvUZ6/NsONzRClV1Pt2t2l6U5J505xG/ga6H/QOTrdikUQPfovswvLSqzpikzll0vYV70PUOApDkoXTf6gZXqv2Y7oPwqXS3rRjYY4LlrQDuU1UHsGZ9k+6ctU2qaqKh95uoqj8AH24Xdwxfzf1Xpu59GFtV/TnJ9+lOOD95NQ8ko44DXppkUVWtAGgn++8OnNJ6mNekDemG/YY9ezWWdzTw2iT3rwnurzYD2/JnwPrtgD5pj1dVXZrkf4AHMHLKxYje9lfVlUl+QHfbqzfWjffZG9dxwC5JNhrszyQb0X1gHjvNZa0VbXj2c0keTHd+L3QXL11Bd6L+UZPMehzdSftPYeXh4D3p3pOjt5gZ9S2649KdqupbY4Q6SPCn6nkd95i4xiT5F7rerveMcYrDuL5JN9x/xiq8JgfzPxm4oqp+1ld5DIOex3GPu2+hux3Rf1TVO0cnJnkAcFFNfAX1IDm8Zqj+PehOI5nwuDDFZ8Vg+hV0F9Lcle4L5+248fSHVTHtz7OptNGFVyd5ARPEP8ykUcAN57pN1sN4Q50kr6PrLfgU3blEW9NdufgL4GOt3llJPgO8sXV1n0h3PsjOI8urJC8CvtzOB/k83bf629MNCfxmojf8Krbv2CSH0n3reyfdMMn1dCcK7wy8sqp+nuTLwKl0Jw5fQpcY7ETXSzJwJt0H9Tdbnd9X1eg3u+n4D7qLIY5K8hG6ntotgAcCC6pqv1Vc7rvoTqD/VpLX0yUwL6S7im6XKeabKd8EXpnk1XTb+9HAbquxvHfRXV357XS/vLKcbjvtCrygJU2rsy2/1/5vT89wcVW9cYx4x23/y+kSoh+luyHxuXQX3Cyuqn171vEmuh6OY5K8la5H4ZV0H3zjxNgrySOBLbmxN21JO0dz0JMyzjIOorvQ5Ud0Q2j3oDsd5ui2nD+lu8XQgUkOo0sK/wQsBv5SVQcC36C7aOODSbakuwhpZ7rTBP6nqqbqEaSqftW20ftaz8pxdL01d6Q7Pn24qr47NMuDgd/Vyvc0HF3mWMfEGbS4DX/eku48yCfQJdHfohuxmSmvo3vNfi/J++i+3G9Gl1Dctar+tWf+T9OuJm6v6VNbzHejS3CfOM0E9490vWt7JDkN+DNwdlWN9g4DUFWfSncnhXck2YHus+UPdMO6u9C99pZw4znGw75Ndx7jJ1rsC+l64H7D0Cl9fZ8VSd5I91n2XbqevzvQjUwsq6rVSRjH/jybbP4km7R2fpobz7fflW4fHz3ZfIOV+zcP/+i5Gq/V2ZGhq6eHyp9B92a5mu6N/Elg4UidDem6uC+m60H4Cjdepbj3SN0d6C7uuITuIL6Crgdnh6E6x7IaV0+3slsA/95i/wtwWXv8v3Tf2KC7HcYJrV1X0fUk7A+sP7Scv6cbBvpLW8f+q7OdW717tzaf37bruW2b7TxU5xDg3Enmv8nV0638nnTnq17W4j0B2KlvWw1Nu8kVwZO1qe2jHww9v3V7DVxAlwB8ja73ZqVtNtn6mfjKwq3oLpY4j6536bfAx4ENprMtp9gPP2bkCnDGvHJzdFuN2/5W9wF0twi5tL3ufkZ34J9w247M+2C6D4Ar6D5MjwG2n4ljwNC6a6K/abwf92rLGeyTs+m+BGw8Um+3tg+uovuS82PgCUPTN6a7snaw/39Od9uTDNXZkQmOW0PTn0n3Pvhz22Y/bcu8w0i9nwNvH7N94xwTVwCfmuR1M+kxZGRfDf6uorvQ5HC6pHH0ytjBa3bvobKxr55u5XeguzL9d21bn0eXnD6j773bpt2qTf9Z2y4X03Ug7M+Nd7WYcF8NtXfRUNkT6b6wXzPatim22850p11d0Ob7I93tgf5ptA0j8z21xf0Xui8nezByPKLns4IuOT2qbber6Y5VHwH+dmgZKy2zlfVePd3Kxvk8G7wOnjsy7wZ0ye0ZdO+By9u+mfIq/qq64XJ2SZr30t0w+D10H/gzNdSnm5k2dH48cO+aosdGmm9MGiWpaed8Lgc+WlVvn+14NDuSHA5cUv3DsNK84jmNktRUd47av9KdA6kxtER7qnu8XV8ze4HXGpXuF2BOofv1DklD7GmUJK2ydL9rPNWNxD9eVXuvnWgkrUkmjZKkVdauRN5oiioXVrvlk6SbN5NGTWiLLbaoRYsWzXYYkiRpBpx00kkXVtWWq7MMz2nUhBYtWsTSpWvrxwwkSdKalOSc1V2Gvz0tSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXuvNdgCam5b/7jIW7XfkbIchrbYVB+wy2yFI0jrBnkZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1mvWkMckVM7CMJUneO8X0RUmePm79CeY/NslZSU5NcmKSxasb80xJ8s9J9pvtOCRJ0rptvdkOYCZU1VJg6RRVFgFPBz4zZv2J7FlVS5M8G3gb8A+rEOpKkiyoqutWZxlV9RXgK6sbiyRJ0lRmvadxIkkWJzkhyWlJDk+yWSvfrpX9KMnbkpzeyndM8rX2+JFJlrW/U5JsBBwAPLyVvWyk/m2TfCzJ8rbsJ/eE9yNg6zbvbZJ8tPU+npJk11a+YZLPt+V9LsmPkyxp065I8sYkPwZ2SPKMJD9psX0oyYL2d0iS01tcL2vzviTJmW25n21leyd5X3t85yTHtOnHJLlTKz8kyXuTHJ/k10l2m8HdJUmS5oE5mTQCnwBeWVX3A5YDr2/lHwNeUFU7AJP10L0ceFFVLQYeDlwF7Ad8v6oWV9W7Rur/F3BZVW3b1vednth2Ao5oj18DfKeqtgMeBbwtyW2AFwKXtOW9CXjQ0Py3AU6vqgcDFwG7A3/f4r0O2BNYDGxdVfetqm1bu2nteEBb7gsmiO19wCfa9E8Dw0PwC4GHAU+gS6IlSZLGNueSxiSbAJtW1XGt6OPAI5JsCmxUVce38s9MsogfAu9M8pK2nGt7VvlY4P8GT6rqkknqfTrJucArgQNb2eOA/ZIsA44FbgXciS45+2xb3unAaUPLuQ44rD1+DF1CeWJbxmOAuwK/Bu6a5MAkOwGXt/qntTieAUzUrh24cbt8ssUxcERVXV9VZwK3n6iBSfZJsjTJ0uuuvGySzSBJkuajOZc0TiHjVKqqA4DnArcGTkhyrzGWW2Msek/gLnRJ2SDJDPDk1oO5uKruVFU/7Yn1L0PnMQb4+ND896yq/Vvien+6RPRFwIdb/V3auh8EnJSk75zU4XZdPfR4wviq6qCqWlJVSxZsuEnPoiVJ0nwy55LGqroMuCTJw1vRM4HjWiL1pyQPaeV7TDR/krtV1fKqeivdxS73Av4EbDTJKo8GXjw0/2ZTxHYN8FrgIUnuDRwF7Jskbd4HtKo/AJ7ayv4O2HaSRR4D7JZkq1Z383Ze4hbALarqMLrh8wcmuQVwx6r6LvAKYFPgtiPLO54bt8ueLQ5JkqTVNheunt6wDfsOvBPYC/hgkg3phmqf3aY9Bzg4yZ/peuEmGkN9aZJH0Q0Dnwl8A7geuDbJqcAhwClD9f8b+L92Uc11wBuAL00WbFVdleQddOdOvhh4N3BaSxxX0J0z+H7g40lOa+s6baJYq+rMJK8Fjm5J4TV0PYtXAR9rZQCvAhYAn2rD9wHeVVWXtnx14CXAR5P8J3DB0HaTJElaLakaZ2R2bkhy26q6oj3eD1hYVf8+y2HdRJIFwPpV9Zckd6PrUbxHVf11lkMb2wYLt6mFe717tsOQVtuKA3aZ7RAkadYlOamqlqzOMuZCT+N07JLkVXRxnwPsPbvhTGpD4LtJ1qfrFfy3m1PCKEmSNOpmlTRW1eeAz812HH2q6k/AamXzkiRJc8mcuxBGkiRJc49JoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ63ax+RlBrz7Zbb8LSA3aZ7TAkSdIcYU+jJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZc399aElv/uMhbtd+Rsh6EZtsIbtkuSVpE9jZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSeo1r5PGJK9JckaS05IsS/LgVv7hJH+3htf99SSbTlC+f5KXT1B+zyTHtjh/muSgJLdJclGSTUbqHpHkqUn2TlJJHjM07UmtbLc10zJJkrQumrdJY5IdgCcAD6yq+wGPBX4LUFXPraoz1+T6q2rnqrp0GrO8F3hXVS2uqnsDB1bVn4GjgScOKrUE8mHA11rRcuBpQ8vZAzh1tYKXJEnzzrxNGoGFwIVVdTVAVV1YVb8HaD16S9rj5yT5eSs7OMn7WvkhST6Q5LtJfp3kkUk+2noBDxmsJMnTkixPcnqStw6Vr0iyRXv8miRnJfk2cM8p4j138KSqlreHh9IlggNPAr5ZVVe2598Htk+yfpLbAncHlq3SFpMkSfPWfE4ajwbu2BLC9yd55GiFJH8L/BfwEOAfgHuNVNkMeDTwMuCrwLuA+wDbJlnc5n9rq7MY2C7JE4cXkORBdEnfA4B/AbabJN53Ad9J8o0kLxsa2v4m8KAkt2vP96BLJAcK+Dbwj8CuwFcm2yBJ9kmyNMnS6668bLJqkiRpHpq3SWNVXQE8CNgHuAD4XJK9R6ptDxxXVRdX1TXAF0amf7Wqim4I+I9VtbyqrgfOABbRJYDHVtUFVXUt8GngESPLeDhweFVdWVWXM0lSV1UfA+7dYtgROCHJBlX11zbPbq3ncjFdQjzss3TJ5GhCObqOg6pqSVUtWbDhJpNVkyRJ89C8TRoBquq6qjq2ql4PvBh48kiV9Czi6vb/+qHHg+frjTH/DaGMVanq91X10araFbgWuG+bNBii3g34cktwh+f7Sau7RVX9fMyYJEmSbjBvk8Z2NfI2Q0WLgXNGqv0EeGSSzZKsx02Tyj4/bvNvkWQB3QUpx43U+R7wpCS3TrIR8E+TxLtTkvXb478Bbgf8rk3+LrAN8CIm70l8FfDqacYvSZIEdL1h89VtgQPbuYHXAr+kG6q+QVX9Lslb6JK/3wNnAmOf7FdV5yV5FV1SF+DrVfXlkTonJ/kc3cUp59BduDKRxwHvSfKX9vw/q+oPbRnXJzkMeApdEjpRLN8YN25JkqRR6U7J02SS3Laqrmg9jYcDH62qw2c7rjVtg4Xb1MK93j3bYWiGrThgl9kOQZI0C5KcVFVLVmcZ83Z4ehr2T7IMOB04GzhiluORJEla6+bz8PRYquomv84iSZI039jTKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnq5c8IakLbbr0JSw/YZbbDkCRJc4Q9jZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqRe3txbE1r+u8tYtN+Rsx3GzdYKb4wuSVrH2NMoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNkiRJ6mXSKEmSpF4mjZIkSepl0ihJkqReJo2SJEnqZdIoSZKkXiaNMyzJdUmWJTk9yVeTbNrKFyW5qk07NcnxSe7Zpu2Y5LI2bVmSb0+w3Nsn+Vqb98wkX2/lZw+WM11hszoAACAASURBVFT33Ule0ZZbSZ4zNO0Brezla3ZLSJKkdYlJ48y7qqoWV9V9gYuBFw1N+1Wbdn/g48Crh6Z9v01bXFWPnWC5bwS+VVX3r6q/A/Zr5Z8F9hhUSnILYDfgc61oObD70HL2AE5djfZJkqR5yKRxzfoRsPUk0zYGLpnGshYC5w6eVNVp7eGhDCWNwCOAFVV1Tnv+G+BWracywE7AN6axXkmSJNab7QDWVUkWAI8BPjJUfLcky4CNgA2BBw9Ne3ibBvCFqnrzyCL/D/hckhcD3wY+VlW/r6rTklyf5P5VdSpdAnnoyLxfBJ4CnAKcDFw9Scz7APsALNh4y+k1WJIkrdPsaZx5t27J30XA5sC3hqYNhqfvBrwUOGho2vDw9GjCSFUdBdwVOBi4F3BKkkFmdyiwR5L1gF2BL4zM/nm6pPFp3DShHF7HQVW1pKqWLNhwk2k0WZIkretMGmfeVVW1GLgzcEtWPqdx2FfohpLHVlUXV9VnquqZwIlD8x8KPBV4LHBaVZ0/Mt8fgGuAfwCOmc46JUmSwKRxjamqy4CXAC9Psv4EVR4G/Grc5SV5dJIN2+ONgLvRna9IVf2KrmfzACbvSXwd8Mqqum7sRkiSJDWe07gGVdUpSQbnGX6fG89pDPBX4LnTWNyDgPcluZYu2f9wVZ04NP1Q4H+AwyeJ5fhVaIIkSRIAqarZjkFz0AYLt6mFe717tsO42VpxwC6zHYIkSTdIclJVLVmdZTg8LUmSpF4mjZIkSepl0ihJkqReJo2SJEnqtVpJY5K7J7nVTAUjSZKkuWnspDHJW5Ls1R4nybeAnwPnJXnw1HNLkiTp5mw6PY17Ame1x48HFgMPAT5Bd1NpSZIkraOmc3Pv2wPntsc7A5+vqp8kuRhYOuORSZIkac6YTk/jRXS/pwzwOOA77fF6dL9wIkmSpHXUdHoaDwM+k+TnwObAN1v5YuCXMx2YJEmS5o7pJI3/Aayg6218RVX9uZUvBD4ww3FJkiRpDhnrt6eTrA+8Gfi/qjpnjUelWbdkyZJautRTVSVJWhestd+erqprgBfiuYuSJEnz0nQuhDkKePSaCkSSJElz13TOaTwGeEuS+wEnAX8enlhVX5rJwCRJkjR3TCdpfF/7/5IJphWwYPXDkSRJ0lw0dtJYVav1O9WSJEm6+TIRlCRJUq+xk8Z0XpjkjCRXJrlrK98vyVPXXIiSJEmabdPpafx34LXAQax8653fAS+eyaAkSZI0t0znQpgXAM+rqiOT/PdQ+cnAfWY2LM225b+7jEX7HTnbYayyFQfsMtshSJK0TplOT+OdgdMnKL8GuPXMhCNJkqS5aDpJ46+BB05QvjNw5syEI0mSpLloOsPTbwfel2RDunMad0jyTOAVwL+uieAkSZI0N0znPo0fS7Ie8BZgQ+CTdBfBvKSqPreG4pMkSdIcMJ2eRqrqYODgJFsAt6iq89dMWJIkSZpLppU0DlTVhTMdiCRJkuauKZPGJKcBj6yqS5Isp/uN6QlV1f1mOjhJkiTNDX09jYcBVw89njRplCRJ0rqrL2k8G7gOoKr2X+PRSJIkaU7qu0/jx4CNAZJcl2SrNR+SJEmS5pq+pPECYIf2ODg8LUmSNC/1DU9/EDgiSdEljH9IMmHFqloww7FJkiRpjpgyaayq/ZN8AdgG+BLwPODStRGYJEmS5o7e356uqjOq6gjgDcChVXXYRH9rPtTJtfMtlyU5PckX2k8dTlZ37yTvW5vxDa37jUke21PnkCS7TVD+kCQ/bu38aZL9kyxKcm6SW4zUXZZk+1anktx9aNrLWtmSmWuZJEla1/UmjQNV9YaqunJNBrMarqqqxVV1X+CvwAtmO6CJVNXrqurbqzj7x4F9qmoxcF/g81W1Avgt8PBBpST3Ajaqqp+0ouXAHkPL2Q04cxVjkCRJ89SUSWOS05Js1h4vb88n/Fs74Y7l+8Ddk2ye5IgW3wlJVrr5eJKNkpydZP32fOMkK5Ksn+TYJG9N8pMkP0/y8FbnVkk+1rbFKUke1cr3buv6alvmi5P8R6tzQpLNW70behGTvC7Jia139KBMdrLojbYCzgOoquuqapD4HcrKSeEerWzgCGDXts67ApfRXeAkSZI0tr6exuGbe3+xPZ/sb9YlWQ94PF3v2huAU9ov1bwa+MRw3ar6E3AssEsr2gM4rKquac/Xq6rtgZcCr29lL2rzbgs8Dfh4klu1afcFng5sD7wZuLKqHgD8CHjWBOG+r6q2a72jtwae0NO8dwFnJTk8yfOH1vt54Imt7QC7A58dmu9y4LdJ7tti/lzPeiRJkm6i70KYN0z0eA66dZJl7fH3gY8APwaeDFBV30lyuySbjMz3YeAVdL1xz6a70GfgS+3/ScCi9vhhwIFtmT9Lcg5wjzbtuy0R/VOSy4CvtvLlwEQ/sfioJK8ANgQ2B84YmucmquqNST4NPI4uOX0asGNV/SHJGcBjkvwRuKaqTh+Z/bN0SfE/Ao9pbb2JJPsA+wAs2HjLyUKRJEnzUN8td24wuNiiqq5vz/+GrnfszKo6fs2EN7ar2rl+N5hkuHel+0xW1Q/bxSSPBBaMJFuDHtbruHE7TTWEfPXQ4+uHnl/PyHZuvYTvB5ZU1W+T7A/cih5V9SvgA0kOBi5Icruquogbh6j/yMpD0wNfBd4GLK2qy6e4bdJBwEEAGyzcxntySpKkG4x9IQxwJLAvQJLbAkvpEpHjkkw0/DrbvgfsCZBkR+DCqrp8gnqfoEu0PjbNZd4DuBNw1irENkgQL2zb8iZXS49KsstQIrwNXTI7uP3RYcDO3HRoGoCqugp4Jd2wuSRJ0rRNJ2l8EPCd9vhf6M6V24puSPflMxzXTNgfWNIu0jkA2GuSep8GNmPiHrpR7wcWJFlOd27g3lV1dc88N1FVlwIH0w1dHwGcOMZsz6Q7p3EZ8Elgz6oa/C74pcAJwB+r6uxJ1vnZqjp5urFKkiQBpGq8UcgkVwH3aMOpnwLOqarXJLkT8NOqus2aDHRNaVcz71pVz5ztWOaSDRZuUwv3evdsh7HKVhywS38lSZLmiSQnVdVq3aN57HMagd8Af5/kq3QXVDyllW8OzNX7N04pyYF0V1vvPNuxSJIkzWXTSRrfSTcsegVwDt35fQCPoBtmvdmpqn1nOwZJkqSbg7GTxqr6UJKTgDsC3xpcRQ38CvivNRGcJEmS5obp9DRSVUvprpoGIMn6VXXkjEclSZKkOWXsq6eTvCTJk4eefwS4KslZSe65RqKTJEnSnDCdW+68hPabxUkeATyV7pdJlgHvmPnQJEmSNFdMZ3h6a2BFe/xPwBeq6vPtnoXfn+nAJEmSNHdMp6fxcmDwg8T/ABzTHl/DGD+BJ0mSpJuv6fQ0Hg0cnOQU4O7AN1r5fYAJf4VEkiRJ64bp9DS+CPghsAWwW1Vd3MofyHg/wSdJkqSbqencp/Fy4CY3w66q189oRJIkSZpzpnWfxoEkfwPccrisqn4zIxFJkiRpzhk7aUyyCfBeulvt3HKCKgtmKijNvm233oSlB+wy22FIkqQ5YjrnNL4duD/wROAvdPdo/E/gXGD3mQ9NkiRJc8V0hqcfDzytqr6f5DrgpKr6XJLzgOcDX1wjEUqSJGnWTaencVPgnPb4MuB27fGPgIfOZFCSJEmaW6aTNP4KuGt7/FNgjyQB/gW4eNK5JEmSdLM3naTxEOB+7fEBdEPSfwXeBrx1ZsOSJEnSXDKd+zS+a+jxd5LcC1gC/KKqlq+J4CRJkjQ3rNJ9GuGG+zJ6b0ZJkqR5YMqkMcl/jLugqnrn6ocjSZKkuShVNfnE5Owxl1NVddf+arq52GDhNrVwr3fPdhjSjFjhjeolzXNJTqqqJauzjCl7GqvqLquzcEmSJK0beq+eTvL4JCvazwiOTtukTXvcmglPkiRJc8E4t9zZF3hbVV02OqGVvRX495kOTJIkSXPHOEnjtsC3p5j+HbrfpJYkSdI6apykcUvg+immFzf+pKAkSZLWQeMkjedy4y/BTOR+wO9mJhxJkiTNReMkjUcCb0py69EJSTYE3tjqSJIkaR01zi/CvBnYDfhFkgOBn7XyewMvBgK8Zc2EJ0mSpLmgN2msqvOTPBT4AF1ymMEk4CjghVX1xzUXoiRJkmbbWL89XVXnADsn2Qy4O13i+IuqumRNBidJkqS5YaykcaAliSeuoVgkSZI0R41zIYwkSZLmOZNGSZIk9TJp7JHkignKXpDkWWs5jickOSXJqUnOTPL8JDsm+dFIvfWS/DHJwiSHJLkyyUZD09+TpJJssTbjlyRJN2/TOqdRnar64JpcfpIAqarr2/P1gYOA7avq3CQbAIuAXwB3SLKoqla02R8LnF5V53WL4ZfArsCnktwCeBTejF2SJE2TPY2rIMn+SV7eHh+b5K1JfpLk50ke3soXJHlbkhOTnJbk+a38tkmOSXJykuVJdm3li5L8NMn7gZOBOw6tciO6BP8igKq6uqrOaknlF4Ddh+ruARw69PzQoek7Aj8Erp3RDSJJktZ5Jo0zY72q2h54KfD6VvYc4LKq2g7YDnhekrsAfwGeVFUPpOv1e0frWQS4J/CJqnpAu80RAFV1MfAV4JwkhybZs/UaQpcU7gHQeiB3Bg4biu0XwJbtdklPAz47WSOS7JNkaZKl11152apvDUmStM4xaZwZX2r/T6IbNgZ4HPCsJMuAHwO3A7ah/YJOktOAbwNbA7dv85xTVSdMtIKqei7wGOAnwMuBj7byE4HbJrkn8HjghAnun/klusTywcD3J2tEVR1UVUuqasmCDTcZs+mSJGk+8JzGmXF1+38dN27TAPtW1VHDFZPsDWwJPKiqrkmyArhVm/znqVZSVcuB5Uk+CZwN7N0mfZYuKbw3Kw9NMzT9ZODjVXX9jR2bkiRJ47Gncc05Cvi3dhELSe6R5DbAJsD5LWF8FHDnvgW18yB3HCpaDJwz9PxQ4BnAo+mGsVdSVb8BXgO8fxXbIkmS5jl7GvttmOTcoefvHHO+D9MNVZ/czlm8AHgi8Gngq0mWAsuAn42xrACvSPIh4Cq6Hsm9BxOr6swkVwInVdWEvZVV9aEx45YkSbqJVNVsx6A5aIOF29TCvd4922FIM2LFAbvMdgiSNKuSnFRVS1ZnGQ5PS5IkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSeq032wFobtp2601YesAusx2GJEmaI+xplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi/v06gJLf/dZSza78jZDkOSpHlhxc3g3sj2NEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKnXvE0ak1yXZFmSM5KcmuQ/kqzS9kjyxiSPnWL6C5I8a9WjhSTbtniXJbk4ydnt8bdXZ7mSJEnjWG+2A5hFV1XVYoAkWwGfATYBXj/dBVXV63qmf3CVIlx5GcuBQbyHAF+rqi8O10myXlVdu7rrkiRJGjVvexqHVdX5wD7Ai9NZkORtSU5MclqS5w/qJnlFkuWtd/KAVnZIkt3a4wOSnNnme3sr2z/Jy9vjxUlOaNMPT7JZKz82yVuT/CTJz5M8fJzY23xvSXIc8O9JHpTkuCQnJTkqycJW725JvtnKv5/kXjO4CSVJ0jpuPvc0rqSqft2Gp7cCdgUuq6rtkmwA/DDJ0cC9gCcCD66qK5NsPryM9vxJwL2qqpJsOsGqPgHsW1XHJXkjXc/mS9u09apq+yQ7t/JJh7xHbFpVj0yyPnAcsGtVXZBkd+DNwL8CBwEvqKpfJHkw8H7g0WMuX5IkzXMmjStL+/844H6D3kO6Yett6JK4j1XVlQBVdfHI/JcDfwE+nORI4GsrLTzZhC7BO64VfRz4wlCVL7X/JwGLphH359r/ewL3Bb6VBGABcF6S2wIPBb7QygE2GF1Ikn3oelxZsPGW01i9JEla15k0NknuClwHnE+XPO5bVUeN1NkJqMmWUVXXJtkeeAywB/Biptebd3X7fx3T2zd/HoQInFFVOwxPTLIxcOngHM7JVNVBdD2SbLBwm0nbKUmS5h/PaQSSbAl8EHhfVRVwFPBvbbiXJPdIchvgaOBfk2zYykeHp28LbFJVX6cbcl4pSauqy4BLhs5XfCbdcPJMOQvYMskOLZ71k9ynqi4Hzk7ylFaeJPefwfVKkqR13Hzuabx1kmXA+sC1wCeBd7ZpH6YbHj453XjuBcATq+qbSRYDS5P8Ffg68OqhZW4EfDnJreh6/V42wXr3Aj7YEs9fA8+eqQZV1V/bkPp721D4esC7gTOAPYEPJHlta/NngVNnat2SJGndlq5jTVrZBgu3qYV7vXu2w5AkaV5YccAua3T5SU6qqiWrswyHpyVJktTLpFGSJEm9TBolSZLUy6RRkiRJvUwaJUmS1MukUZIkSb1MGiVJktTLpFGSJEm9TBolSZLUy6RRkiRJvUwaJUmS1MukUZIkSb3Wm+0ANDdtu/UmLF3DP54uSZJuPuxplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPXy5t6a0PLfXcai/Y6c7TCkm5UV3hBf0jrMnkZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1MmmUJElSL5NGSZIk9TJplCRJUi+TRkmSJPUyaZQkSVIvk0ZJkiT1WmtJY5Irhh7vnOQXSe40UmdFksOGnu+W5JC1FeNILK+eYtq040yyJMl7e+osSnL6JNOOTbKkJ2xJkqQ1Yq33NCZ5DHAgsFNV/WaCKkuS3GeG17lgFWabNGlsphVnVS2tqpesQhyrLcl6s7FeSZK07lirSWOShwMHA7tU1a8mqfZ2JkjYktwmyUeTnJjklCS7tvJFSb6f5OT299BWvmOS7yb5DLA8yYIkb2vzn5bk+a3ewiTfS7IsyelJHp7kAODWrezTMxTnjkm+1h5vmeRbLd4PJTknyRZtEQuSHJzkjCRHJ7n10OKfkeT4Fuf2bVmbJzmitemEJPdr5fsnOSjJ0cAnktwnyU9am05Lss2kO0qSJGnE2kwaNwC+DDyxqn42Rb3PAw9McveR8tcA36mq7YBHAW9LchvgfOAfquqBwO7A8BDw9sBrqurvgOcAl7X5twOel+QuwNOBo6pqMXB/YFlV7QdcVVWLq2rPGYpz2OtbnQcChwPDw/TbAP9XVfcBLgWePDTtNlX1UOCFwEdb2RuAU6rqfnRJ7CeG6j8I2LWqng68AHhPa+cS4NzRBiXZJ8nSJEuvu/KySZotSZLmo7WZNF4DHE+XvE3lOuBtwKtGyh8H7JdkGXAscCu6ZGt94OAky4EvAH83NM9Pqursofmf1eb/MXA7ugTtRODZSfYHtq2qP43ZnunGOexhwGcBquqbwCVD086uqmXt8UnAoqFph7Z5vgdsnGTTtqxPtvLvALdLskmr/5Wquqo9/hHw6iSvBO48VH6DqjqoqpZU1ZIFG24yOlmSJM1jazNpvB54KrBdkle34eJl7e+NI3U/CTyClZOtAE9uvX+Lq+pOVfVT4GXAH+l6CZcAtxya588j8+87NP9dquroloA9Avgd8Mkkz5pGm6YTJyN1JnP10OPrgOHzEWukbk2yrEG9G9pfVZ8B/hm4CjgqyaOniEGSJGkla/Wcxqq6EngCsCew91Bi9bqRetcA7wJeOlR8FLBvkgAkeUAr3wQ4r6quB54JTHbRy1HAvyVZv81/j3b+4Z2B86vqYOAjwANb/WsGdadoz3TiHPYDugSaJI8DNptqPUN2b/M8jG6o/TLge3TbkyQ7AhdW1eWjMya5K/Drqnov8BXgfmOuU5Ikae1fPV1VFwM7Aa8dXCQyiY+wci/bm+iGok9rt6V5Uyt/P7BXkhOAe7By7+KwDwNnAie3+T/Ulr8jsCzJKXTnD76n1T+orWuyC2GmG+ewNwCPS3Iy8HjgPGCcYfFLkhwPfJAbh/n3p7uS+zTgAGCvSebdHTi9DZvfi5XPfZQkSZpSqkZHPLWmJdkAuK6qrk2yA/CBdoHKnLHBwm1q4V7vnu0wpJuVFQfsMtshSNKEkpxUVat1v2fv3zc77gR8PsktgL8Cz5vleCRJkqZk0jgLquoXwETnOkqSJM1J/va0JEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXPyOoCW279SYsPWCX2Q5DkiTNEfY0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqZNEqSJKmXSaMkSZJ6mTRKkiSpl0mjJEmSepk0SpIkqZdJoyRJknqlqmY7Bs1BSf4EnDXbccyCLYALZzuIWWC755f52O752Gaw3fPNVO2+c1VtuToLX291ZtY67ayqWjLbQaxtSZba7vnDds8f87HNYLtnO461bU232+FpSZIk9TJplCRJUi+TRk3moNkOYJbY7vnFds8f87HNYLvnmzXabi+EkSRJUi97GiVJktTLpHGeS7JTkrOS/DLJfhNMT5L3tumnJXngbMQ508Zo972S/CjJ1UlePhsxrgljtHvPtp9PS3J8kvvPRpwzaYw279rauyzJ0iQPm404Z1pfu4fqbZfkuiS7rc341pQx9veOSS5r+3tZktfNRpwzbZz93dq+LMkZSY5b2zGuCWPs7/8c2tent9f65rMR60wao92bJPlqklPb/n72jKy4qvybp3/AAuBXwF2BWwKnAn83Umdn4BtAgIcAP57tuNdSu7cCtgPeDLx8tmNei+1+KLBZe/z4m/v+HrPNt+XGU3XuB/xstuNeG+0eqvcd4OvAbrMd91ra3zsCX5vtWGeh3ZsCZwJ3as+3mu2410a7R+r/E/Cd2Y57Le3vVwNvbY+3BC4Gbrm667ancX7bHvhlVf26qv4KfBbYdaTOrsAnqnMCsGmShWs70BnW2+6qOr+qTgSumY0A15Bx2n18VV3Snp4A3GEtxzjTxmnzFdWOrMBtgHXhRO9x3tsA+wKHAeevzeDWoHHbva4Zp91PB75UVb+B7hi3lmNcE6a7v58GHLpWIluzxml3ARslCd0X44uBa1d3xSaN89vWwG+Hnp/byqZb5+ZmXWzTOKbb7ufQ9TLfnI3V5v/f3rnHW1Vcd/z7Q+ATo9HaUquSIERQkKighNhGHvURH+hHiCRKfBNLfFaltKYmMVatUSGJDzQmQSRRQ60WETGaGBSN1kcUFBVSQhQVsEax8gY1rP6x5jTb3fPYl8O5l3tY389nf+45M7PXrDUz5+511syckTRC0m+B+4HRraRbI6lpt6SuwAjg5lbUq9EUHeN/nabtHpDUt3VUayhF7N4T2EnSbEnPSTql1bRrHIX/p0n6OHAE/iWpvVPE7olAH2AZ8CJwvpltrLfiOBFm60Zl0vJRliJl2hvNaFMRCtst6W9xp7G9r+8rZLOZ3QPcI2kwcDlwaKMVazBF7L4WuMjM/ujBiKagiN1z8OPUVks6CpgO9Gq4Zo2liN0dgQOAQ4BtgSclPWVmCxutXANpyf/yY4AnzOzdBurTWhSx+3DgeeBgYA/gIUm/NrOV9VQckcatmyXApzLvP4l/K2lpmfZGM9pUhEJ2S9oXmAQca2bLW0m3RtGivjazx4A9JHVptGINpojdA4B/k7QYGAncJGl466jXMGrabWYrzWx1ev1zoNNW0t9LgAfNbI2ZvQM8BrT3jW4t+XyfQHNMTUMxu0/HlyOYmS0CXgV611txOI1bN78BeknqIakz/qGakSszAzgl7aI+EFhhZm+2tqKbmSJ2NyM17ZbUDZgGnNzOIxAlitjcM637If06QGegvTvLNe02sx5m1t3MugN3A2eb2fTWV3WzUqS/d8n090D8Odj0/Q3cCwyS1DFN1X4OWNDKem5uCv0vl7QjMARvg2agiN2v41FlJP0VsBfwSr0Vx/T0VoyZfSjpXOAX+G6syWb2sqQzU/7N+K7Ko4BFwFr820u7pojdknYBngV2ADZKugDfnVZXaL8tKdjflwB/gUedAD40swFtpXO9FLT5OPyL0QfAOuD4zMaYdklBu5uOgnaPBM6S9CHe3ydsDf1tZgskPQjMAzYCk8zspbbTun5aMM5HAL80szVtpOpmpaDdlwNTJL2IT2dflCLMdREnwgRBEARBEAQ1ienpIAiCIAiCoCbhNAZBEARBEAQ1CacxCIIgCIIgqEk4jUEQBEEQBEFNwmkMgiAIgiAIahJOYxAEQRAEQVCTcBqDIKiJpC6STNLQFtxzqaR2/Ttw9SBpjKTXJW2UdGlb67MlIamTpIXp2MagHSLpbklj21qPoHUJpzEI2jmSpiSHblKZvGtS3sy20K0Skk5LelW7htYhf7GkcQXKzc7UtyE5MhdL2mZT605ydwJuBMYDXYEJ9chrQsYAS9OxjQBk+uEj551L2kbSspQ3stU1rYGk7hXG7/RMmeskPStpvfzYxmbgX4BvptNWgq2EcBqDoDl4Azhe0nalBEkdgZPx46S2NO4Eds1cvwL+PZf2n62ky62pvr2A64ErgJoOZyUkdQJ2x0/cmmlmb5bOOt4EWZ03VY8tnPOAW8qkvwF8NZd2JPBhoxXaDG19BB8dv6dl8joAPwF+WmcdDadoO5jZi/ixdCc1VqNgSyKcxiBoDuYBvwO+nEkbBqwHZmcLSuog6VuS3kjRtRclHZsr81lJz6XIyFz8nFpyZfaWdL+kVZL+IGlqOn6xJma2zsz+u3QBKzIVnAAACaJJREFUG4B1mffvApdLWiJpjaTfSDo8U3cnSdenCNSGZMtVKW827rSNL0V9aqizNtW72MwmArOA4UlWZ0lXV9FjaKrjKEnPSHof+BowNxV5JeV3T+W/JmmRpPfT37/LtalJOkfSNElrgCtL0/ySTk0R1NWSbk26nZ1sXy7pe5I6ZGSdlPQt9c9dkrqW0f0QSU9LWpuiYfvndDpQ0sPJ/hWSZknaLeVJ0j9J+r2kdWksVXUiJA0A9gTKRb+nAF+StH0m7au4Y5+XM1bSvKTXUkmTJP1ZC3SfLekHkiZIeht4IqUPTu2xXtJbkr5f0JFanh3TZvZeKcPMzjOzG4AWn+cuaUdJt6U+XC/pFfmxpqX8HZIdb6b8BZKOz+R/MfVL6XPyDcnPCE35i9MYmyzpPeCOlP43kh5N42JpqmOHnHozgFEttSlov4TTGATNwy3A6Mz70fjDNu80nQ/8I3ARsA9wDzBNUj8AebTyfjyKMAD4OrnpVUm7Ao8BLwEDgUOB7YEZWcelDm4FhgBfSTr+BLhP0n4p/+/x82RPAHoBxwP/lfK+CCwBLuNPUZ+WsA7oVFCPElcD3wR6A/fiUSfwttkVeEPSCGAicC3wGeA6/IzvY3Kyvo2f+b4PPsUN0B04FjgaPyv7S6mezwJfAM7Ao3cjMnI6J1n7pfu6AFPL2PsdvI/3B5YDd5ScimTnI/jZ858HDsQjwh3TvVfgTt05wN5J1g8lDStTT4lBwKKsU5VhHrAA708k7QwcRRmnET8/+QKgL94/A4EbSpkFdAePkinpdEpyqh/Anf7+ybZRya624gp8LByNj6/RwFJwpx3XdwhwOt4HY4H3U/4BwF3AtCTj68A/A+fm6hgL/Bb/vF8saR/gl7hTuB/+meoHTM7d9wwwUNK2m83aYMvGzOKKK652fOHRmZnATrjD0wvYBY/edSvlZ8ovBS7JyZgN3J5ejwHeA7bP5J+EO59D0/vLgFk5GTulMgPT+0uBlwraMBOYkl7vgTsE3XJlpgM3pdfX4xFBVZC3GBhXoN7ZwMT0ugPu7G3AncAiegxNNh+XKzMgpXfPpD0BTC7Td49n3htwQ67Mpalfd8yk3Q28DXQuZ0sFW3sn+Z/M6X54psznc2XuAJ6qIG+7pNegXPq1wM+r6HEt8GiZdANGAmcBT6S0ccCvsvlV5Jb6rkMt3TPtNS+X9q+4k9khk3ZakvvxCnK6J93WAqsz16AyZccBi4t8JjL3zABurZB3WBqjfSrk3wE8XGY8Lcl9Vu7LlfkpcEsurV+yc+dM2r4pbY+W2BRX+70i0hgETYKZ/Q8eNRwNnArMNrOPrGdM00u7kabiMjyORykA+uAP0+w6vCdz5Q8ABqep0tWSVuPr0cCdrXrYH4/+zM/JH5aRPQV/iC2UdKOkYXVEOMck+evxB/Tt+CL/InqUeLZAPX2o3u7VZL1uZisy798CFprZ+7m0nUtvJO0v6V5Jr0lalZHbLSd7Xub1svS3JKc/7pyXY2/gY8CDufY5i+pjYFu8rSvxM6C/pL3wsVxu7SOSDpb0kHzpwCo8mtYZ/8JUS/cSz+Xe9wGeNLONmbTHk9yeNWR9BR+TpavImCjCD4AvS3ohTaUPyeT1B940swUV7q005rrmpprzuh4AnJTr15KcbN+uS38j0riV0LF2kSAI2hGT8SnU1cAlVcqVW+dXSlOZvDwd8CnschtG3ipwfy3Zhk+9fpDLWwdgZnPk6wSPAA7GbX5B0mG5B34R7sSdxA3AMjP7I/jaz1p6ZFhTsK5q7V5NVr5+q5C2DfzfEoNf4BuMTgb+gE9P/xp3gCrJLulScsCrjYVSmWP4/5ut8rpleQd3dspiZiskTQNuxqf278mXkbQ7Pv5+jI/z5biTP5U/2VdkHOfbWpTvI6qkl1hiZosK1NkizOyBZO+RwCHA/ZLuMrPTqW1jUXvy7dABmAR8v8x9SzOv/zz9fbuGHkGTEE5jEDQXs/D1TF3wadSPYGYrJS0DDgIezmQdBMxPr+cDp0razsxKD5MDc6Lm4JtuXjOzag7CpjAXf9jtYmaPVCpkZqvw9Vp3SZoCPIVHgxbibVD0Z3NWVHjYF9KjBSzA2zm7Lizb7puT3vgYuNjMXgXfELEJcubgTnk55uOO9u5m9nCFMuWYC5wrqUMVB/8WfHzeaGblopIDcOfwwoyTf3QLdK/EfDyql9XtIHw8/b6FsjYbZvYOcBtwm6QHgKmSzsRt3FVSnwrRxvm4/lkOwh3cVVWqnAP0LeAEfwb/olXvF8WgnRDT00HQRJiZ4euMepjZhgrFxgPjJI2StKeky/CNAN9N+T/Df+JksqS+kg4DvpGTcSOwI3CnpM9J+rSkQyX9SNIn6rRhIb4Wa4qkkUn2AEnjSo6PfOfsKEl9JPXEpwZX4htgwNdpDZLUVVKXRunRQsYDJ8t3R/eSdB5wInDNpuhXg9dxh+7cpPcw4PJNkDMenyr+kaT9JO0l6QxJ3ZLTMQGYIGm0pJ6S+kk6U9KYKjIfwae1961UIDnpfwn8Q4Uiv8OfXxdI6iFpFL4pppDuVXS7CV++cVMaW8OAq/C1omur3FeVUtsk2Z1TO/VTgV3Zki6TNDyNmT74ppRX0ud7FvA08B+SDk9tcZik4en27wJD5Luj95R0It6mtcbc1fgGl5sl9U/6Hy3ph7lyg4AHCzdE0O4JpzEImgwzW2VmK6sUuR5/oF6D734egW/keD7dvxrfqdkLjzhMwHdaZ+tYhm+a2Ig/NF7GHckN6aqX0/Eds9fguzpnAoOB11L+KnwH+DNJx37AkZkH+yXAp/DoUD1TZ7X0KIyZTcd3OF+IR4DOB842s/vq0K9SXW/j61qHp7q+je+Qbamc5/Gd8b3xSO7T+I71UnT5W/jGinH4GHgI3939ahWZy/H1hyfWqPudSl98zGwe3n5jcfvOILdUooDu5eQuxaeB+wPP41HhqcDF1XQtwCQ8wnohPuU+N127Fbh3A75B5wV8XeEn8CUBpGjokSn9djyafR1pit7M5uA77Y/DP+tXpWtitQpT+w7GN/k8mur+DpmlJ5I+hv/v+HEBG4ImQR6YCIIgCILWQVJfPOLYs8YXnGALRdI5wLFm9oW21iVoPSLSGARBELQqZvYyHhns0da6BJvMB3jkPNiKiEhjEARBELQRaWPLoArZV5rZla2pTxBUI5zGIAiCIGgj5KfQVPqdw3fN7N3W1CcIqhFOYxAEQRAEQVCTWNMYBEEQBEEQ1CScxiAIgiAIgqAm4TQGQRAEQRAENQmnMQiCIAiCIKjJ/wLDnuarS7C+4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline - ompare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "# Generating results\n",
    "# ---\n",
    "# Iterate through all classifiers\n",
    "for clf in dict_clf_default:\n",
    "    estimator = { clf: dict_clf_default[clf] }\n",
    "    try:\n",
    "        score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "\n",
    "    \n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file (optional)\n",
    "# df_performance.to_csv(r'final_project_performance_default.csv', index = False, header = True)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# ---\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"{} on Different Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save plot into PNG (optional) \n",
    "# plt.savefig(\"final_project_performance_default.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3328694504027031, 0.7732013528151364, 0.28999620745631893, 0.076986076986077, 0.12849007997851544, 0.190161022925736, 0.2890112772095463]\n"
     ]
    }
   ],
   "source": [
    "print(list_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bagging\n",
    "\n",
    "Recall the definition of `dict_clf_default` from the [earlier section](#3.0-Default-Classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - K-Nearest Neighbors\n",
      "Index: 1 - Decision Tree\n",
      "Index: 2 - Linear SVM\n",
      "Index: 3 - Polynomial SVM\n",
      "Index: 4 - RBF SVM\n",
      "Index: 5 - Sigmoid SVM\n",
      "Index: 6 - Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "_ = [print(\"Index: {} - {}\".format(i, clf)) for i, clf in enumerate(dict_clf_default.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `clf_index` from 0 - 6 as a base classifier in bagging approach, each corresponding to the classifier defined in `dict_clf_default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Bagging - Decision Tree) = 0.8152\n",
      "f1_macro (Test Bagging - Decision Tree) = 0.8090\n",
      "[[1075    2   25]\n",
      " [   4  182    3]\n",
      " [  88    1   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1102\n",
      "           1       0.98      0.96      0.97       189\n",
      "           2       0.68      0.40      0.51       149\n",
      "\n",
      "    accuracy                           0.91      1440\n",
      "   macro avg       0.86      0.78      0.81      1440\n",
      "weighted avg       0.90      0.91      0.91      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bagging - Decision Tree': {'f1_macro': 0.8090483781836065}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify classifier\n",
    "clf_index = 1    # Accepts value from 0 - 6\n",
    "\n",
    "# Define parameter values for BaggingClassifier object\n",
    "base = list(dict_clf_default.values())[clf_index]\n",
    "bagging_param = dict(base_estimator=base,\n",
    "                     n_estimators=100,    # create 100 different models using the same `base_estimator`\n",
    "                     random_state=0)\n",
    "\n",
    "# Define BaggingClassifier object\n",
    "model_bagging = BaggingClassifier(**bagging_param)\n",
    "\n",
    "estimator_name = \"Bagging - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_bagging}\n",
    "\n",
    "# Train and evaluate the performance of the bagging classifier\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test performance result for all the classifiers as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation K-Nearest Neighbors) = 0.3358\n",
      "f1_macro (Test K-Nearest Neighbors) = 0.3292\n",
      "[[1059   34    9]\n",
      " [ 176   10    3]\n",
      " [ 139    6    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1102\n",
      "           1       0.20      0.05      0.08       189\n",
      "           2       0.25      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.41      0.35      0.33      1440\n",
      "weighted avg       0.64      0.75      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.8152\n",
      "f1_macro (Test Decision Tree) = 0.8090\n",
      "[[1075    2   25]\n",
      " [   4  182    3]\n",
      " [  88    1   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1102\n",
      "           1       0.98      0.96      0.97       189\n",
      "           2       0.68      0.40      0.51       149\n",
      "\n",
      "    accuracy                           0.91      1440\n",
      "   macro avg       0.86      0.78      0.81      1440\n",
      "weighted avg       0.90      0.91      0.91      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Linear SVM) = 0.2703\n",
      "f1_macro (Test Linear SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Polynomial SVM) = 0.1860\n",
      "f1_macro (Test Polynomial SVM) = 0.0770\n",
      "[[   0 1102    0]\n",
      " [   1  188    0]\n",
      " [   0  149    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1102\n",
      "           1       0.13      0.99      0.23       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.13      1440\n",
      "   macro avg       0.04      0.33      0.08      1440\n",
      "weighted avg       0.02      0.13      0.03      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation RBF SVM) = 0.2881\n",
      "f1_macro (Test RBF SVM) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Sigmoid SVM) = 0.2709\n",
      "f1_macro (Test Sigmoid SVM) = 0.2639\n",
      "[[566   0 536]\n",
      " [ 97   0  92]\n",
      " [ 74   0  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.51      0.62      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.11      0.50      0.18       149\n",
      "\n",
      "    accuracy                           0.45      1440\n",
      "   macro avg       0.29      0.34      0.26      1440\n",
      "weighted avg       0.60      0.45      0.49      1440\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Logistic Regression) = 0.2881\n",
      "f1_macro (Test Logistic Regression) = 0.2890\n",
      "[[1102    0    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.77      0.66      1440\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bagging - compare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "bagging_param = dict(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "# Generate results\n",
    "# ---\n",
    "# Iterate through all classifiers\n",
    "for i, clf in enumerate(dict_clf_default):\n",
    "    base = dict_clf_default[clf]\n",
    "    \n",
    "    params = bagging_param.copy()\n",
    "    params[\"base_estimator\"] = base\n",
    "\n",
    "    model_bagging = BaggingClassifier(**params)\n",
    "    \n",
    "    estimator = { clf: model_bagging }\n",
    "    \n",
    "    try:\n",
    "        score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "\n",
    "    \n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file (optional)\n",
    "# df_performance.to_csv(r'final_project_performance_bagging.csv', index = False, header = True)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# ---\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"Bagging: {} on Different Base Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Base Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save plot into PNG (optional) \n",
    "# plt.savefig(\"final_project_performance_bagging.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Boosting\n",
    "\n",
    "Recall the definition of `dict_clf_default` from the [earlier section](#3.0-Default-Classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - K-Nearest Neighbors\n",
      "Index: 1 - Decision Tree\n",
      "Index: 2 - Linear SVM\n",
      "Index: 3 - Polynomial SVM\n",
      "Index: 4 - RBF SVM\n",
      "Index: 5 - Sigmoid SVM\n",
      "Index: 6 - Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "_ = [print(\"Index: {} - {}\".format(i, clf)) for i, clf in enumerate(dict_clf_default)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the `clf_index` from 0 - 6 as a base classifier in AdaBoost approach, each corresponding to the classifier defined in `dict_clf_default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Boosting - Decision Tree) = 0.7783\n",
      "f1_macro (Test Boosting - Decision Tree) = 0.7786\n",
      "[[1035   18   49]\n",
      " [   4  180    5]\n",
      " [  79    5   65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1102\n",
      "           1       0.89      0.95      0.92       189\n",
      "           2       0.55      0.44      0.49       149\n",
      "\n",
      "    accuracy                           0.89      1440\n",
      "   macro avg       0.79      0.78      0.78      1440\n",
      "weighted avg       0.88      0.89      0.88      1440\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Boosting - Decision Tree': {'f1_macro': 0.7786248020789598}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify one classifier\n",
    "clf_index = 1    # Accepts value from 0 - 6\n",
    "\n",
    "# Define parameter values for AdaBoostClassifier object\n",
    "base = list(dict_clf_default.values())[clf_index]\n",
    "boosting_param = dict(base_estimator=base,\n",
    "                     n_estimators=100,\n",
    "                     random_state=0)\n",
    "\n",
    "# Define AdaBoostClassifier object\n",
    "model_boosting = AdaBoostClassifier(**boosting_param)\n",
    "\n",
    "estimator_name = \"Boosting - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_boosting}\n",
    "\n",
    "# Train and evaluate the performance of the AdaBoost classifier\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test performance result for all classifiers as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- K-Nearest Neighbors\n",
      "f1_macro (Validation K-Nearest Neighbors) = nan\n",
      "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
      "\n",
      "- Decision Tree\n",
      "f1_macro (Validation Decision Tree) = 0.7783\n",
      "f1_macro (Test Decision Tree) = 0.7786\n",
      "[[1035   18   49]\n",
      " [   4  180    5]\n",
      " [  79    5   65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1102\n",
      "           1       0.89      0.95      0.92       189\n",
      "           2       0.55      0.44      0.49       149\n",
      "\n",
      "    accuracy                           0.89      1440\n",
      "   macro avg       0.79      0.78      0.78      1440\n",
      "weighted avg       0.88      0.89      0.88      1440\n",
      "\n",
      "\n",
      "\n",
      "- Linear SVM\n",
      "f1_macro (Validation Linear SVM) = nan\n",
      "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
      "Please change the base estimator or set algorithm='SAMME' instead.\n",
      "\n",
      "- Polynomial SVM\n",
      "f1_macro (Validation Polynomial SVM) = nan\n",
      "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
      "Please change the base estimator or set algorithm='SAMME' instead.\n",
      "\n",
      "- RBF SVM\n",
      "f1_macro (Validation RBF SVM) = nan\n",
      "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
      "Please change the base estimator or set algorithm='SAMME' instead.\n",
      "\n",
      "- Sigmoid SVM\n",
      "f1_macro (Validation Sigmoid SVM) = nan\n",
      "TypeError: AdaBoostClassifier with algorithm='SAMME.R' requires that the weak learner supports the calculation of class probabilities with a predict_proba method.\n",
      "Please change the base estimator or set algorithm='SAMME' instead.\n",
      "\n",
      "- Logistic Regression\n",
      "f1_macro (Validation Logistic Regression) = 0.3013\n",
      "f1_macro (Test Logistic Regression) = 0.2889\n",
      "[[1101    0    1]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.76      0.66      1440\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "feature_train = x_train\n",
    "feature_test = x_test\n",
    "\n",
    "# Initialize parameter values of boosting classifier\n",
    "boosting_param = dict(n_estimators=100, random_state=0)\n",
    "\n",
    "# Loop through all classifiers\n",
    "# ---\n",
    "for i, clf in enumerate(dict_clf_default):\n",
    "    print(\"- {}\".format(clf))\n",
    "    base = dict_clf_default[clf]\n",
    "    \n",
    "    params = boosting_param.copy()\n",
    "    params[\"base_estimator\"] = base\n",
    "    \n",
    "    model_boosting = AdaBoostClassifier(**params)\n",
    "    \n",
    "    estimator = { clf: model_boosting }\n",
    "    \n",
    "    try:\n",
    "        score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "    \n",
    "    \n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file\n",
    "# df_performance.to_csv(r'final_project_performance_boosting.csv', index = False, header = True)\n",
    "\n",
    "# Plotting\n",
    "# ---\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"Boosting: {} on Different Base Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Base Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Save plot into PNG (optional) \n",
    "# plt.savefig(\"final_project_performance_boosting.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The comparison for Boosting method is done only between Decision Tree and Logistic Regression because KNN and default SVM classifiers cannot be specified as the base estimator for sklearn's `AdaBoostClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Voting \n",
    "\n",
    "Voting is a method involving different machine learning algorithms.\n",
    "\n",
    "To implement voting method, specify `num_base_clf`, the number of base classifiers when defining an object of `VotingClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('K-Nearest Neighbors', 'Decision Tree', 'Linear SVM')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4003\n",
      "f1_macro (Test Voting Classifier) = 0.3423\n",
      "[[1093    3    6]\n",
      " [ 178   11    0]\n",
      " [ 145    0    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      1102\n",
      "           1       0.79      0.06      0.11       189\n",
      "           2       0.40      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.65      0.36      0.34      1440\n",
      "weighted avg       0.74      0.77      0.68      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Decision Tree', 'Polynomial SVM')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4770\n",
      "f1_macro (Test Voting Classifier) = 0.6034\n",
      "[[1058   43    1]\n",
      " [   9  180    0]\n",
      " [ 136   10    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1102\n",
      "           1       0.77      0.95      0.85       189\n",
      "           2       0.75      0.02      0.04       149\n",
      "\n",
      "    accuracy                           0.86      1440\n",
      "   macro avg       0.80      0.64      0.60      1440\n",
      "weighted avg       0.85      0.86      0.82      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Decision Tree', 'RBF SVM')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4717\n",
      "f1_macro (Test Voting Classifier) = 0.4692\n",
      "[[1039    2   61]\n",
      " [ 171   11    7]\n",
      " [  89    0   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87      1102\n",
      "           1       0.85      0.06      0.11       189\n",
      "           2       0.47      0.40      0.43       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.70      0.47      0.47      1440\n",
      "weighted avg       0.77      0.77      0.72      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Decision Tree', 'Sigmoid SVM')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4575\n",
      "f1_macro (Test Voting Classifier) = 0.4612\n",
      "[[1041    2   59]\n",
      " [ 172   10    7]\n",
      " [  92    0   57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      1102\n",
      "           1       0.83      0.05      0.10       189\n",
      "           2       0.46      0.38      0.42       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.70      0.46      0.46      1440\n",
      "weighted avg       0.77      0.77      0.72      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Decision Tree', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.3358\n",
      "f1_macro (Test Voting Classifier) = 0.3363\n",
      "[[1099    2    1]\n",
      " [ 179   10    0]\n",
      " [ 146    0    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.83      0.05      0.10       189\n",
      "           2       0.75      0.02      0.04       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.79      0.36      0.34      1440\n",
      "weighted avg       0.78      0.77      0.68      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Linear SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.2897\n",
      "f1_macro (Test Voting Classifier) = 0.2889\n",
      "[[1101    1    0]\n",
      " [ 189    0    0]\n",
      " [ 149    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.26      0.33      0.29      1440\n",
      "weighted avg       0.59      0.76      0.66      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Polynomial SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.3044\n",
      "f1_macro (Test Voting Classifier) = 0.3175\n",
      "[[1072   30    0]\n",
      " [ 178   11    0]\n",
      " [ 145    4    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86      1102\n",
      "           1       0.24      0.06      0.09       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.75      1440\n",
      "   macro avg       0.34      0.34      0.32      1440\n",
      "weighted avg       0.62      0.75      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'RBF SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.2961\n",
      "f1_macro (Test Voting Classifier) = 0.3046\n",
      "[[1093    0    9]\n",
      " [ 187    0    2]\n",
      " [ 145    0    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.27      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.34      0.34      0.30      1440\n",
      "weighted avg       0.61      0.76      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "('K-Nearest Neighbors', 'Sigmoid SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.2962\n",
      "f1_macro (Test Voting Classifier) = 0.3046\n",
      "[[1093    0    9]\n",
      " [ 187    0    2]\n",
      " [ 145    0    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.27      0.03      0.05       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.34      0.34      0.30      1440\n",
      "weighted avg       0.61      0.76      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "('Decision Tree', 'Linear SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.3573\n",
      "f1_macro (Test Voting Classifier) = 0.2963\n",
      "[[1097    0    5]\n",
      " [ 188    1    0]\n",
      " [ 148    0    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1102\n",
      "           1       1.00      0.01      0.01       189\n",
      "           2       0.17      0.01      0.01       149\n",
      "\n",
      "    accuracy                           0.76      1440\n",
      "   macro avg       0.64      0.34      0.30      1440\n",
      "weighted avg       0.73      0.76      0.67      1440\n",
      "\n",
      "\n",
      "\n",
      "('Decision Tree', 'Polynomial SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4749\n",
      "f1_macro (Test Voting Classifier) = 0.6162\n",
      "[[1087   15    0]\n",
      " [  10  179    0]\n",
      " [ 143    6    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      1102\n",
      "           1       0.90      0.95      0.92       189\n",
      "           2       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.88      1440\n",
      "   macro avg       0.59      0.64      0.62      1440\n",
      "weighted avg       0.79      0.88      0.83      1440\n",
      "\n",
      "\n",
      "\n",
      "('Decision Tree', 'RBF SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4340\n",
      "f1_macro (Test Voting Classifier) = 0.4399\n",
      "[[1049    0   53]\n",
      " [ 183    1    5]\n",
      " [  90    0   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.87      1102\n",
      "           1       1.00      0.01      0.01       189\n",
      "           2       0.50      0.40      0.44       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.77      0.45      0.44      1440\n",
      "weighted avg       0.79      0.77      0.71      1440\n",
      "\n",
      "\n",
      "\n",
      "('Decision Tree', 'Sigmoid SVM', 'Logistic Regression')\n",
      "---\n",
      "f1_macro (Validation Voting Classifier) = 0.4185\n",
      "f1_macro (Test Voting Classifier) = 0.4314\n",
      "[[1051    0   51]\n",
      " [ 184    0    5]\n",
      " [  93    0   56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.87      1102\n",
      "           1       0.00      0.00      0.00       189\n",
      "           2       0.50      0.38      0.43       149\n",
      "\n",
      "    accuracy                           0.77      1440\n",
      "   macro avg       0.43      0.44      0.43      1440\n",
      "weighted avg       0.66      0.77      0.71      1440\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_0</th>\n",
       "      <th>classifier_1</th>\n",
       "      <th>classifier_2</th>\n",
       "      <th>test_performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.342279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>0.603434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.469199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>0.461199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.336290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.288863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.317549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.304613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.304613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.296304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.616192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.439882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.431380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           classifier_0    classifier_1         classifier_2  test_performance\n",
       "0   K-Nearest Neighbors   Decision Tree           Linear SVM          0.342279\n",
       "1   K-Nearest Neighbors   Decision Tree       Polynomial SVM          0.603434\n",
       "2   K-Nearest Neighbors   Decision Tree              RBF SVM          0.469199\n",
       "3   K-Nearest Neighbors   Decision Tree          Sigmoid SVM          0.461199\n",
       "4   K-Nearest Neighbors   Decision Tree  Logistic Regression          0.336290\n",
       "5   K-Nearest Neighbors      Linear SVM  Logistic Regression          0.288863\n",
       "6   K-Nearest Neighbors  Polynomial SVM  Logistic Regression          0.317549\n",
       "7   K-Nearest Neighbors         RBF SVM  Logistic Regression          0.304613\n",
       "8   K-Nearest Neighbors     Sigmoid SVM  Logistic Regression          0.304613\n",
       "9         Decision Tree      Linear SVM  Logistic Regression          0.296304\n",
       "10        Decision Tree  Polynomial SVM  Logistic Regression          0.616192\n",
       "11        Decision Tree         RBF SVM  Logistic Regression          0.439882\n",
       "12        Decision Tree     Sigmoid SVM  Logistic Regression          0.431380"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "# specify number of base classifiers\n",
    "num_base_clf = 3                                # Accepts values from 2 - 4 (number of base classifiers)\n",
    "list_clf = [[] for i in range(num_base_clf)]    # 2-dimensional list, to store list of classifiers in\n",
    "                                                # each voting classifier\n",
    "list_score = []\n",
    "\n",
    "# Generate all possible combinations of base classifiers with # of classifiers = num_base_clf\n",
    "# ---\n",
    "# For example: if num_base_clf = 3, \n",
    "# [A, B, C, D] -> [A, B, C], [A, B, D], [A, C, D] and [B, C, D]\n",
    "combinations_base_clf = itertools.combinations(dict_clf_default, num_base_clf)\n",
    "\n",
    "# Iterate through all generated lists\n",
    "for comb in combinations_base_clf:\n",
    "    list_base_clf = []\n",
    "    \n",
    "    # Return number of SVM classifiers in a list\n",
    "    count_svm = sum(\"SVM\" in clf for clf in comb)    \n",
    "    \n",
    "    # At most one SVM classifier in the list.\n",
    "    # - skip all the lists with >1 classifiers - speed up iteration\n",
    "    # - ensure variation in machine learning algorithms in the voting classifier\n",
    "    if count_svm <= 1:\n",
    "        for i, clf in enumerate(comb):\n",
    "            list_base_clf.append((clf, dict_clf_default[clf]))\n",
    "            list_clf[i].append(clf)\n",
    "    \n",
    "        print(comb)\n",
    "        print(\"---\")\n",
    "        \n",
    "        try:\n",
    "            model_voting = VotingClassifier(estimators=list_base_clf)\n",
    "            \n",
    "            estimator_name = \"Voting Classifier\"\n",
    "            estimator = { estimator_name : model_voting }\n",
    "            score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "            \n",
    "            list_score = list_score + list(score[estimator_name].values())\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_class_name = e.__class__.__name__\n",
    "            print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "            continue\n",
    "        \n",
    "        print()\n",
    "\n",
    "        \n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict()\n",
    "for i, base_clf in enumerate(list_clf):\n",
    "    clf_key = \"classifier_{}\".format(i)\n",
    "    data[clf_key] = base_clf\n",
    "\n",
    "data[\"test_performance\"] = list_score\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# Save and export df_performance to CSV file (optional)\n",
    "df_performance.to_csv(r'final_project_performance_voting_{}clf.csv'.format(num_base_clf), index = False, header = True)\n",
    "\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Set 3 Summary\n",
    "\n",
    "The best model from this experiment is obtained using **BaggingClassifier** with default **decision tree** (`random_state=0`) as the base estimator.\n",
    "\n",
    "    Base estimator (base): DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "    Ensemble learning method: BaggingClassifier(base_estimator=base, n_estimators=100, random_state=0)\n",
    "    \n",
    "    Test performance (macro average F1 score): 0.8090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Set 4: Vary Training Sample Size\n",
    "\n",
    "In this experiment set, we identify the best performing model from the previous experiment sets, namely:\n",
    "\n",
    "- Experiment Set 1: Decision tree classifier with the best parameter\n",
    "- Experiment Set 2: Decision tree trained using set of 10 features obtained using chi-squared\n",
    "- Experiment Set 3: Bagging classifier with decision tree as the base estimator\n",
    "\n",
    "Then, we generate 10 subsamples from the original training set to test the effect of varying training sample size to each of the best models from the list above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 9+1 subsamples from the original training set.\n",
    "num_subsamples = 10\n",
    "\n",
    "# Define lists to store subsamples from original training set (features and target)\n",
    "x_train_subs = []\n",
    "y_train_subs = []\n",
    "\n",
    "# Iterate through 9 (=10-1) times to generate 9 smaller training sets\n",
    "# - `train_size` must be float values between 0 and 1 (exclusive)\n",
    "# - `random_state=0`: to control the split, so that the smaller subsample is always a subset of \n",
    "#   the larger subsample\n",
    "for k in range(num_subsamples - 1):\n",
    "    x_train_sub, _, y_train_sub, _ = train_test_split(x_train, y_train, \n",
    "                                                      train_size=((k+1) / 10),    # 0.1, 0.2, ..., 0.9\n",
    "                                                      random_state=0)\n",
    "    \n",
    "    # Append subsamples into lists of subsamples\n",
    "    x_train_subs.append(x_train_sub)\n",
    "    y_train_subs.append(y_train_sub)\n",
    "    \n",
    "# Append full training sample into list of subsamples \n",
    "x_train_subs.append(x_train)\n",
    "y_train_subs.append(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper function to train and evaluate model performance using **a list of training samples**, instead of one set of training sample as specified in helper function \\#1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #8\n",
    "def train_and_evaluate_vary_size(estimator, x_train_list, x_test, y_train_list, y_test):\n",
    "    # Train and evaluate\n",
    "    # ---\n",
    "    # Initialize 3 empty lists to store the values of k, validation and test score \n",
    "    # Initialize 1 empty dictionary (scores) to store the k: validation_score / test_score (key:value) pairs\n",
    "    K = [] \n",
    "    validationf1macro = []\n",
    "    testf1macro = []\n",
    "    scores = {}\n",
    "    \n",
    "    for k, (x_train, y_train) in enumerate(zip(x_train_list, y_train_list)):\n",
    "        # 10-fold Cross-Validation\n",
    "        # ---\n",
    "        # Compute the validation score for the model using 10-fold cross validation \n",
    "        scores_val = cross_val_score(estimator, x_train, y_train, cv = 10, scoring = 'f1_macro')\n",
    "\n",
    "        # Compute the mean validation score\n",
    "        score_val_mean = scores_val.mean()\n",
    "        \n",
    "        \n",
    "        # Training and testing\n",
    "        # ---\n",
    "        # Fit and train the model to the subsample training data.\n",
    "        estimator.fit(x_train, y_train)\n",
    "\n",
    "        # Compute the test score by compare the actual and prediction outcome.\n",
    "        test_predict = estimator.predict(x_test)\n",
    "\n",
    "        # Compute the test score by compare the actual and prediction outcome.\n",
    "        score_test = metrics.f1_score(y_test, test_predict, average='macro')\n",
    "        \n",
    "        \n",
    "        # Update lists\n",
    "        # ---\n",
    "        key = k + 1\n",
    "        K.append(key)\n",
    "\n",
    "        validationf1macro.append(score_val_mean)\n",
    "        testf1macro.append(score_test)\n",
    "\n",
    "        # A dictionary holds key: value pairs and Store the validation score for each value of k\n",
    "        scores[key] = (score_val_mean, score_test)\n",
    "\n",
    "\n",
    "    # Print result\n",
    "    print(\"Subsample (%): Macro F1 score (Validation | Test)\")\n",
    "\n",
    "    for key_score in scores:\n",
    "        score_val = scores[key_score][0]\n",
    "        score_test = scores[key_score][1]\n",
    "        print(\"{:.1f}%: ({:.4f} | {:.4f})\".format(key_score*10, score_val, score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Best Model from Experiment Set 1\n",
    "\n",
    "Decision tree classifier with the best parameter ([summary](#Experiment-Set-1-Summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample (%): Macro F1 score (Validation | Test)\n",
      "10.0%: (0.7223 | 0.7347)\n",
      "20.0%: (0.7465 | 0.7508)\n",
      "30.0%: (0.7658 | 0.7499)\n",
      "40.0%: (0.7678 | 0.7449)\n",
      "50.0%: (0.7430 | 0.7449)\n",
      "60.0%: (0.7744 | 0.7692)\n",
      "70.0%: (0.7776 | 0.7757)\n",
      "80.0%: (0.7815 | 0.7700)\n",
      "90.0%: (0.7771 | 0.7692)\n",
      "100.0%: (0.7764 | 0.7732)\n"
     ]
    }
   ],
   "source": [
    "# Define Decision Tree classifier\n",
    "dtree = DecisionTreeClassifier(criterion = 'gini',splitter = 'best', random_state = 0)\n",
    "\n",
    "train_and_evaluate_vary_size(dtree, x_train_subs, x_test, y_train_subs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Best Model from Experiment Set 2\n",
    "\n",
    "Decision tree trained using set of 10 features obtained using chi-squared  ([summary](#Experiment-Set-2-Summary))\n",
    "\n",
    "**Note**: Use helper function `get_chi2_features()` to get the best set of features before generating 10 subsamples from the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = get_chi2_features(x_train, y_train, num_k=10)\n",
    "\n",
    "x_train_chi2 = x_train[cols]\n",
    "x_test_chi2 = x_test[cols]\n",
    "\n",
    "x_train_sub_chi2 = []\n",
    "for k in range(num_subsamples - 1):\n",
    "    x_train_sub, _, _, _ = train_test_split(x_train_chi2, y_train,           \n",
    "                                            train_size=((k+1) / 10),\n",
    "                                            random_state=0)\n",
    "    x_train_sub_chi2.append(x_train_sub)\n",
    "#     y_train_subs.append(y_train_sub)\n",
    "    \n",
    "x_train_sub_chi2.append(x_train_chi2)\n",
    "# y_train_subs.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample (%): Macro F1 score (Validation | Test)\n",
      "10.0%: (0.7135 | 0.7364)\n",
      "20.0%: (0.7405 | 0.7683)\n",
      "30.0%: (0.7774 | 0.7508)\n",
      "40.0%: (0.7534 | 0.7686)\n",
      "50.0%: (0.7401 | 0.7508)\n",
      "60.0%: (0.7683 | 0.7861)\n",
      "70.0%: (0.7803 | 0.7797)\n",
      "80.0%: (0.7852 | 0.7694)\n",
      "90.0%: (0.7789 | 0.7753)\n",
      "100.0%: (0.7763 | 0.7881)\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating using top 10 features - chi2\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "train_and_evaluate_vary_size(dtree, x_train_sub_chi2, x_test_chi2, y_train_subs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3: Best Model from Experiment Set 3\n",
    "\n",
    "Bagging classifier with decision tree as the base estimator ([summary](#Experiment-Set-3-Summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample (%): Macro F1 score (Validation | Test)\n",
      "10.0%: (0.7515 | 0.7899)\n",
      "20.0%: (0.7898 | 0.8064)\n",
      "30.0%: (0.8087 | 0.7952)\n",
      "40.0%: (0.8044 | 0.8088)\n",
      "50.0%: (0.8097 | 0.8167)\n",
      "60.0%: (0.8079 | 0.8135)\n",
      "70.0%: (0.8095 | 0.8132)\n",
      "80.0%: (0.8119 | 0.8179)\n",
      "90.0%: (0.8144 | 0.8031)\n",
      "100.0%: (0.8152 | 0.8090)\n"
     ]
    }
   ],
   "source": [
    "# #Import the package for Bagging Classifier\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model_bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=0), \n",
    "                                  n_estimators=100, random_state=0)\n",
    "\n",
    "train_and_evaluate_vary_size(model_bagging, x_train_subs, x_test, y_train_subs, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Set 4 summary\n",
    "\n",
    "The overall best model throughout the experiment is the Bagging model obtained from **Experiment Set 3**.\n",
    "\n",
    "    Base estimator (base): DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "    Ensemble learning method: BaggingClassifier(base_estimator=base, n_estimators=100, random_state=0)\n",
    "    \n",
    "    Test performance (macro average F1 score): 0.8090\n",
    "\n",
    "In general, a larger training size yields a better test performance. This can be observed from the test performance of all models in this experiment set. Notably, the test performance does not follow a non-decreasing trend.\n",
    "\n",
    "**Other findings**\n",
    "\n",
    "There is a drop for decision tree and decision tree (chi-squared features selection) classifier when come to 50% subsample size.\n",
    "- Some outliers exists in the 50% subsample which causing the drop of the performance of macro F1.\n",
    "- Bagging classifier able to overcome this issue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
